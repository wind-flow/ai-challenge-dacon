#!/usr/bin/env python3
"""
ë°ì´í„° ì¦ê°• ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
2025 ê¸ˆìœµ AI Challenge Track1ì„ ìœ„í•œ ë°ì´í„° ì¦ê°•
"""

import sys
import os
import argparse
import logging
import json
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from src.data_augmentation import FSKUAugmentationPipeline


def setup_logging(log_level: str = 'INFO'):
    """ë¡œê¹… ì„¤ì •"""
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setLevel(getattr(logging, log_level))
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬
    log_file = f"logs/augmentation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    os.makedirs('logs', exist_ok=True)
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    
    # ë¡œê±° ì„¤ì •
    logging.basicConfig(
        level=logging.DEBUG,
        format=log_format,
        handlers=[console_handler, file_handler]
    )
    
    return log_file


def parse_arguments():
    """ëª…ë ¹ì¤„ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description='FSKU ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸ ì‹¤í–‰'
    )
    
    # ë°ì´í„° ê´€ë ¨
    parser.add_argument(
        '--external_data_dir',
        type=str,
        default='./data/external',
        help='ì™¸ë¶€ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ'
    )
    
    parser.add_argument(
        '--output_dir',
        type=str,
        default='./data/augmented',
        help='ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ'
    )
    
    # ìƒì„± ê´€ë ¨
    parser.add_argument(
        '--target_count',
        type=int,
        default=5000,
        help='ëª©í‘œ ë¬¸ì œ ìˆ˜ (ê¸°ë³¸ê°’: 5000)'
    )
    
    parser.add_argument(
        '--mc_ratio',
        type=float,
        default=0.7,
        help='ê°ê´€ì‹ ë¬¸ì œ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.7)'
    )
    
    # ëª¨ë¸ ê´€ë ¨
    parser.add_argument(
        '--model_name',
        type=str,
        default='beomi/SOLAR-10.7B-v1.0',
        help='ì‚¬ìš©í•  LLM ëª¨ë¸ ì´ë¦„'
    )
    
    parser.add_argument(
        '--use_quantization',
        action='store_true',
        default=True,
        help='4bit ì–‘ìí™” ì‚¬ìš© ì—¬ë¶€'
    )
    
    parser.add_argument(
        '--no_quantization',
        action='store_false',
        dest='use_quantization',
        help='ì–‘ìí™” ì‚¬ìš© ì•ˆí•¨'
    )
    
    # í’ˆì§ˆ ê´€ë ¨
    parser.add_argument(
        '--similarity_threshold',
        type=float,
        default=0.85,
        help='ì¤‘ë³µ íŒë‹¨ ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.85)'
    )
    
    # ê¸°íƒ€
    parser.add_argument(
        '--batch_size',
        type=int,
        default=32,
        help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 32)'
    )
    
    parser.add_argument(
        '--seed',
        type=int,
        default=42,
        help='ëœë¤ ì‹œë“œ (ê¸°ë³¸ê°’: 42)'
    )
    
    parser.add_argument(
        '--log_level',
        type=str,
        default='INFO',
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        help='ë¡œê·¸ ë ˆë²¨'
    )
    
    parser.add_argument(
        '--dry_run',
        action='store_true',
        help='í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (10ê°œë§Œ ìƒì„±)'
    )
    
    parser.add_argument(
        '--config_file',
        type=str,
        help='ì„¤ì • íŒŒì¼ ê²½ë¡œ (JSON)'
    )
    
    return parser.parse_args()


def load_config(args):
    """ì„¤ì • ë¡œë“œ"""
    config = {
        'data_dir': args.external_data_dir,
        'output_dir': args.output_dir,
        'model_name': args.model_name,
        'use_quantization': args.use_quantization,
        'similarity_threshold': args.similarity_threshold,
        'multiple_choice_ratio': args.mc_ratio,
        'batch_size': args.batch_size,
        'seed': args.seed
    }
    
    # ì„¤ì • íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ
    if args.config_file and Path(args.config_file).exists():
        with open(args.config_file, 'r', encoding='utf-8') as f:
            file_config = json.load(f)
            config.update(file_config)
    
    return config


def validate_environment():
    """ì‹¤í–‰ í™˜ê²½ ê²€ì¦"""
    import torch
    
    print("\n=== í™˜ê²½ ê²€ì¦ ===")
    print(f"Python ë²„ì „: {sys.version}")
    print(f"PyTorch ë²„ì „: {torch.__version__}")
    print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # í•„ìˆ˜ ë””ë ‰í† ë¦¬ í™•ì¸
    required_dirs = ['data/external', 'data/processed', 'data/augmented']
    for dir_path in required_dirs:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    print("\ní™˜ê²½ ê²€ì¦ ì™„ë£Œ!")
    return True


def print_banner():
    """ë°°ë„ˆ ì¶œë ¥"""
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                               â•‘
    â•‘     2025 ê¸ˆìœµ AI Challenge Track1 - ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ       â•‘
    â•‘                                                               â•‘
    â•‘     FSKU (Financial Semantic Korean Understanding)           â•‘
    â•‘                                                               â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ë°°ë„ˆ ì¶œë ¥
    print_banner()
    
    # ì¸ìˆ˜ íŒŒì‹±
    args = parse_arguments()
    
    # ë¡œê¹… ì„¤ì •
    log_file = setup_logging(args.log_level)
    logger = logging.getLogger(__name__)
    
    logger.info("=" * 60)
    logger.info("ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    logger.info(f"ë¡œê·¸ íŒŒì¼: {log_file}")
    logger.info("=" * 60)
    
    # í™˜ê²½ ê²€ì¦
    if not validate_environment():
        logger.error("í™˜ê²½ ê²€ì¦ ì‹¤íŒ¨")
        return 1
    
    # ì„¤ì • ë¡œë“œ
    config = load_config(args)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ì¸ ê²½ìš°
    if args.dry_run:
        logger.info("í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ëª¨ë“œ (10ê°œë§Œ ìƒì„±)")
        target_count = 10
    else:
        target_count = args.target_count
    
    logger.info(f"ì„¤ì •:")
    logger.info(f"- ì™¸ë¶€ ë°ì´í„°: {config['data_dir']}")
    logger.info(f"- ì¶œë ¥ ë””ë ‰í† ë¦¬: {config['output_dir']}")
    logger.info(f"- ëª©í‘œ ë¬¸ì œ ìˆ˜: {target_count}")
    logger.info(f"- ëª¨ë¸: {config['model_name']}")
    logger.info(f"- ì–‘ìí™”: {config['use_quantization']}")
    logger.info(f"- ê°ê´€ì‹ ë¹„ìœ¨: {config['multiple_choice_ratio']}")
    
    try:
        # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        logger.info("\níŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...")
        pipeline = FSKUAugmentationPipeline(config)
        
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        logger.info("\níŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
        result = pipeline.run(target_count=target_count)
        
        # ê²°ê³¼ ì¶œë ¥
        logger.info("\n" + "=" * 60)
        logger.info("íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
        logger.info("=" * 60)
        
        stats = result['statistics']
        metadata = result['metadata']
        
        logger.info(f"í†µê³„:")
        logger.info(f"- ì²˜ë¦¬ëœ ë¬¸ì„œ: {stats['documents_processed']}ê°œ")
        logger.info(f"- ì¶”ì¶œëœ ê°œë…: {stats['concepts_extracted']}ê°œ")
        logger.info(f"- ìƒì„±ëœ ë¬¸ì œ: {stats['questions_generated']}ê°œ")
        logger.info(f"- ê²€ì¦ í†µê³¼: {stats['questions_validated']}ê°œ")
        logger.info(f"- ì†Œìš” ì‹œê°„: {stats['time_elapsed']:.2f}ì´ˆ")
        logger.info(f"- ìµœì¢… ë¬¸ì œ ìˆ˜: {metadata['actual_count']}ê°œ")
        
        # ê²°ê³¼ ì €ì¥
        logger.info(f"\nê²°ê³¼ ì €ì¥ ì¤‘...")
        pipeline.save_results(config['output_dir'])
        
        # ìƒ˜í”Œ ì¶œë ¥
        samples = pipeline.get_sample_output(5)
        
        print("\n" + "=" * 60)
        print("ìƒì„±ëœ ë¬¸ì œ ìƒ˜í”Œ")
        print("=" * 60)
        
        for i, sample in enumerate(samples, 1):
            print(f"\n[ë¬¸ì œ {i}]")
            print(f"ìœ í˜•: {sample.get('type', 'N/A')}")
            print(f"ì§ˆë¬¸: {sample.get('question', 'N/A')}")
            
            if 'options' in sample:
                print("ì„ íƒì§€:")
                for j, opt in enumerate(sample['options'], 1):
                    if j == sample.get('answer', 0):
                        print(f"  {j}. {opt} âœ“")
                    else:
                        print(f"  {j}. {opt}")
            elif 'answer' in sample:
                answer_preview = sample['answer'][:100] + "..." if len(sample['answer']) > 100 else sample['answer']
                print(f"ë‹µë³€: {answer_preview}")
            
            if 'keywords' in sample:
                print(f"í•µì‹¬ í‚¤ì›Œë“œ: {', '.join(sample['keywords'])}")
        
        # í’ˆì§ˆ ë³´ê³ ì„œ
        quality_report = pipeline.checker.generate_quality_report(result['data'])
        
        print("\n" + "=" * 60)
        print("í’ˆì§ˆ ë³´ê³ ì„œ")
        print("=" * 60)
        print(f"ì´ ë¬¸ì œ ìˆ˜: {quality_report['total_questions']}")
        print(f"íƒ€ì…ë³„ ë¶„í¬: {quality_report['type_distribution']}")
        print(f"ë‚œì´ë„ ë¶„í¬: {quality_report['difficulty_distribution']}")
        print(f"í‰ê·  ì§ˆë¬¸ ê¸¸ì´: {quality_report['avg_question_length']:.1f}ì")
        print(f"í‰ê·  ë‹µë³€ ê¸¸ì´: {quality_report['avg_answer_length']:.1f}ì")
        print(f"í’ˆì§ˆ ì ìˆ˜: {quality_report['quality_score']:.1f}%")
        
        print("\n" + "=" * 60)
        print("âœ… ë°ì´í„° ì¦ê°• ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {config['output_dir']}")
        print("=" * 60)
        
        return 0
        
    except Exception as e:
        logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    import random
    import numpy as np
    import torch
    
    # ì‹œë“œ ê³ ì •
    random.seed(42)
    np.random.seed(42)
    torch.manual_seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(42)
    
    # ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
    sys.exit(main())