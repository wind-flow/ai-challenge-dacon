#!/usr/bin/env python3
"""
ê¸°ì¡´ ìƒì„±ëœ ë°ì´í„°ì—ì„œ ì§ˆë¬¸ê³¼ ë‹µë§Œ ì¶”ì¶œí•˜ëŠ” í…ŒìŠ¤íŠ¸
"""

import json
import re
from pathlib import Path

def extract_answer(generated_text: str) -> str:
    """ìƒì„±ëœ í…ìŠ¤íŠ¸ì—ì„œ ë‹µë³€ ì¶”ì¶œ"""
    # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ë‹µë³€ ì°¾ê¸°
    patterns = [
        r'\[ë‹µ\]([\s\S]*?)\[', 
        r'\[ë‹µë³€\]([\s\S]*?)\[',
        r'\[ANSWER\]([\s\S]*?)\[',
        r'ì •ë‹µ[:ï¼š]\s*([^\n]+)',
        r'ë‹µ[:ï¼š]\s*([^\n]+)',
        r'\[ì •ë‹µ\]\s*([1-5])\)',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, generated_text, re.MULTILINE)
        if match:
            return match.group(1).strip()
    
    # ê°ê´€ì‹ íŒ¨í„´ (1ë²ˆ, 2ë²ˆ ë“±)
    if any(num in generated_text for num in ['1)', '2)', '3)', '4)', '5)']):
        answer_match = re.search(r'ì •ë‹µ.*?([1-5])\s*\)', generated_text)
        if answer_match:
            return answer_match.group(1) + "ë²ˆ"
    
    return "ë‹µë³€ ì¶”ì¶œ ì‹¤íŒ¨"

def clean_question(generated_text: str) -> str:
    """ìƒì„±ëœ í…ìŠ¤íŠ¸ì—ì„œ ì§ˆë¬¸ë§Œ ì¶”ì¶œ"""
    # ì§ˆë¬¸ íŒ¨í„´
    patterns = [
        r'\[ë¬¸ì œ\]([\s\S]*?)\[',
        r'\[QUESTION\]([\s\S]*?)\[',
        r'ë¬¸ì œ[:ï¼š]\s*([^\n]+[?])',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, generated_text, re.MULTILINE)
        if match:
            return match.group(1).strip()
    
    # ì²˜ìŒë¶€í„° ë¬¼ìŒí‘œê¹Œì§€ ì°¾ê¸°
    question_end = generated_text.find('?')
    if question_end > 0:
        return generated_text[:question_end+1].strip()
    
    # ì²« ì¤„ë§Œ ë°˜í™˜
    lines = generated_text.split('\n')
    if lines:
        return lines[0].strip()
    
    return generated_text[:200].strip()

# ê¸°ì¡´ íŒŒì¼ ì½ê¸°
input_file = "data/augmented/train_data_20250805_004816.jsonl"
output_file = "data/augmented/train_data_clean.jsonl"
metadata_file = "data/augmented/metadata_clean.json"

print(f"ğŸ“– ì…ë ¥ íŒŒì¼: {input_file}")
print("-" * 60)

clean_data = []
metadata_list = []

with open(input_file, 'r', encoding='utf-8') as f:
    for i, line in enumerate(f, 1):
        data = json.loads(line)
        
        # ì§ˆë¬¸ê³¼ ë‹µ ì¶”ì¶œ
        question_text = data.get('question', '')
        answer = extract_answer(question_text)
        clean_q = clean_question(question_text)
        
        # ê¹”ë”í•œ ë°ì´í„°
        clean_entry = {
            'id': data.get('id'),
            'question': clean_q,
            'answer': answer
        }
        clean_data.append(clean_entry)
        
        # ë©”íƒ€ë°ì´í„°
        metadata = {
            'id': data.get('id'),
            'concept': data.get('concept'),
            'quality_score': data.get('quality_score'),
            'context_used': data.get('context_used'),
            'timestamp': data.get('timestamp'),
            'model': data.get('model'),
            'original_length': len(question_text)
        }
        metadata_list.append(metadata)
        
        # ìƒ˜í”Œ ì¶œë ¥
        if i <= 3:
            print(f"\n[{i}] ì›ë³¸ ê¸¸ì´: {len(question_text)}ì")
            print(f"ì§ˆë¬¸: {clean_q[:80]}...")
            print(f"ë‹µë³€: {answer}")

# ì €ì¥
with open(output_file, 'w', encoding='utf-8') as f:
    for entry in clean_data:
        f.write(json.dumps(entry, ensure_ascii=False) + '\n')

with open(metadata_file, 'w', encoding='utf-8') as f:
    json.dump({
        'source_file': input_file,
        'total_entries': len(clean_data),
        'metadata': metadata_list
    }, f, ensure_ascii=False, indent=2)

print(f"\n\nâœ… ë³€í™˜ ì™„ë£Œ!")
print(f"ğŸ“„ ê¹”ë”í•œ ë°ì´í„°: {output_file}")
print(f"ğŸ“Š ë©”íƒ€ë°ì´í„°: {metadata_file}")
print(f"ğŸ“ˆ ì´ {len(clean_data)}ê°œ í•­ëª© ì²˜ë¦¬")