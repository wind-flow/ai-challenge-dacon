# π“ λ¨λΈ μ„ μ • κ°€μ΄λ“ (κµ¬λ²„μ „)

> **μ°Έκ³ **: μµμ‹  μ •λ³΄λ” [models_comparison.md](./models_comparison.md)λ¥Ό ν™•μΈν•μ„Έμ”.

# λ¨λΈ μ„ μ • λ° RAG κµ¬μ¶• κ°€μ΄λ“

## π” RTX 4090 24GBμ—μ„ μ‹¤ν–‰ κ°€λ¥ν• ν•κµ­μ–΄ κΈμµ/λ²•λ¥  λ¨λΈ

### νλΌλ―Έν„° μμ© ν•κ³„
- **4bit μ–‘μν™”**: μµλ€ ~65B νλΌλ―Έν„°
- **8bit μ–‘μν™”**: μµλ€ ~30B νλΌλ―Έν„°
- **16bit (FP16)**: μµλ€ ~13B νλΌλ―Έν„°

## β… λ€ν μ‚¬μ© κ°€λ¥ λ¨λΈ (μ¤ν”μ†μ¤ + ν•κµ­μ–΄ νΉν™”)

### 1. **LG EXAONE 3.0** β­ μµμ°μ„  μ¶”μ²
- **κ³µκ° μ—¬λ¶€**: β… μ¤ν”μ†μ¤ (2024λ…„ 8μ›” κ³µκ°)
- **λΌμ΄μ„ μ¤**: λΉ„μƒμ—…μ  μ—°κµ¬μ© Apache 2.0
- **λ¨λΈ ν¬κΈ°**: 7.8B (RTX 4090μ—μ„ μ¶©λ¶„ν μ‹¤ν–‰ κ°€λ¥)
- **ν•κµ­μ–΄ νΉν™”**:
  - 8μ΅° ν† ν° μ¤‘ ν•κµ­μ–΄ λ°μ΄ν„° 60% μ΄μƒ
  - ν•κµ­ κΈμµκ°λ…μ›, κΈμµμ„μ›ν λ¬Έμ„ ν¬ν•¨
  - ν•κµ­ λ²•λ Ή, νλ΅€ λ°μ΄ν„° ν•™μµ
- **μ„±λ¥**: KMMLU 64.9%, Ko-CommonGen v2 73.0%
- **Hugging Face**: `LG-AI-EXAONE/EXAONE-3.0-7.8B-Instruct`

### 2. **beomi/SOLAR-10.7B** β­ κ°•λ ¥ μ¶”μ²
- **κ³µκ° μ—¬λ¶€**: β… μ™„μ „ μ¤ν”μ†μ¤
- **λΌμ΄μ„ μ¤**: Apache 2.0
- **λ¨λΈ ν¬κΈ°**: 10.7B (4bit μ–‘μν™”λ΅ RTX 4090 μ‹¤ν–‰ κ°€λ¥)
- **ν•κµ­μ–΄ νΉν™”**:
  - Upstageμ—μ„ ν•κµ­μ–΄ λ°μ΄ν„°λ΅ μ¶”κ°€ ν•™μµ
  - ν•κµ­μ–΄ λ²¤μΉλ§ν¬ μµμƒμ„κ¶
  - κΈμµ/λ²•λ¥  μ©μ–΄ μ΄ν•΄λ„ λ†’μ
- **μ„±λ¥**: ν•κµ­μ–΄ νƒμ¤ν¬μ—μ„ GPT-3.5 μμ¤€

### 3. **maywell/EXAONE-3.0-7.8B-Instruct-Llamafied**
- **κ³µκ° μ—¬λ¶€**: β… μ»¤λ®¤λ‹ν‹° λ³€ν™ λ²„μ „
- **λ¨λΈ ν¬κΈ°**: 7.8B
- **νΉμ§•**: EXAONEμ„ Llama ν•μ‹μΌλ΅ λ³€ν™ (λ” λ§μ€ λ„κµ¬ μ§€μ›)

### 4. **Qwen2.5 μ‹λ¦¬μ¦** (ν•κµ­μ–΄ μ§€μ›)
- **κ³µκ° μ—¬λ¶€**: β… μ¤ν”μ†μ¤
- **λΌμ΄μ„ μ¤**: Apache 2.0
- **μ¶”μ² λ¨λΈ**:
  - `Qwen/Qwen2.5-14B-Instruct` (4bit μ–‘μν™” ν•„μ”)
  - `Qwen/Qwen2.5-7B-Instruct` (μ—¬μ μκ² μ‹¤ν–‰)
- **ν•κµ­μ–΄ μ„±λ¥**: μ°μ (λ‹¤κµ­μ–΄ ν•™μµ)

## β μ‚¬μ© λ¶κ°€ λ¨λΈ (λΉ„κ³µκ°/μƒμ—…μ©)
1. **HyperCLOVA X**: λ„¤μ΄λ²„ λ…μ , APIλ§ μ κ³µ
2. **KoGPT**: μΉ΄μΉ΄μ¤ μƒμ—…μ©, μΌλ¶€ κµ¬λ²„μ „λ§ κ³µκ°
3. **BloombergGPT**: μ™„μ „ λΉ„κ³µκ°
4. **Claude/GPT κ³„μ—΄**: API μ‚¬μ© κΈμ§€

## π“ μ¦κ°•μ© vs μ¶”λ΅ μ© λ¨λΈ μ „λµ

### μ¦κ°•μ© (ν’μ§ μ°μ„ )
```python
# λ΅μ»¬ GPUμ—μ„ κ°€λ¥ν• μµλ€ λ¨λΈ μ‚¬μ©
augmentation_model = "LG-AI-EXAONE/EXAONE-3.0-7.8B-Instruct"
# λλ”
augmentation_model = "beomi/SOLAR-10.7B-v1.0"
```

### μ¶”λ΅ μ© (μ†λ„ μ°μ„ )
```python
# 4bit μ–‘μν™”λ΅ λΉ λ¥Έ μ¶”λ΅ 
from transformers import AutoModelForCausalLM, BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4"
)

model = AutoModelForCausalLM.from_pretrained(
    "LG-AI-EXAONE/EXAONE-3.0-7.8B-Instruct",
    quantization_config=quantization_config,
    device_map="auto"
)
```

## π― κΈμµ/λ²•λ¥  νΉν™”λ¥Ό μ„ν• ν•κµ­μ–΄ RAG κµ¬μ„±

### ν•κµ­μ–΄ νΉν™” μ„λ² λ”© λ¨λΈ
```python
# 1. ν•κµ­μ–΄ κΈμµ νΉν™” (μ¶”μ²)
"upskyy/bge-m3-korean"  # ν•κµ­μ–΄ μµμ ν™”
"snunlp/KR-SBERT-V40K-klueNLI-augSTS"  # μ„μΈλ€ κ°λ°

# 2. λ‹¤κµ­μ–΄ (ν•κµ­μ–΄ ν¬ν•¨)
"BAAI/bge-m3"  # κ°•λ ¥ν• ν•κµ­μ–΄ μ§€μ›
"intfloat/multilingual-e5-large"  # ν•κµ­μ–΄ μ„±λ¥ μ°μ
```

### ν•κµ­ κΈμµ λ°μ΄ν„°λ΅ νμΈνλ‹
```python
# EXAONEμΌλ΅ κΈμµ λ°μ΄ν„° νμΈνλ‹ μμ‹
from peft import LoraConfig, get_peft_model

lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    lora_dropout=0.1,
    task_type="CAUSAL_LM"
)

# μμ§‘ν• ν•κµ­ κΈμµ λ°μ΄ν„°λ΅ ν•™μµ
model = get_peft_model(base_model, lora_config)
```

## π’΅ μ‹¤μ „ κµ¬ν„ κ¶μ¥μ‚¬ν•­
1. **μ¦κ°• λ‹¨κ³„**: EXAONE 3.0 λλ” SOLAR-10.7B μ‚¬μ©
2. **μ¶”λ΅  λ‹¨κ³„**: λ™μΌ λ¨λΈμ„ 4bit μ–‘μν™”ν•μ—¬ μ‚¬μ©
3. **ν•κµ­μ–΄ RAG**: BGE-M3 ν•κµ­μ–΄ λ²„μ „ + Weaviate
4. **λ©”λ¨λ¦¬ κ΄€λ¦¬**: gradient checkpointing ν™μ©

## π€ RAG μ‹μ¤ν… κµ¬μ„± μ„Έλ¶€μ‚¬ν•­

### ν•µμ‹¬ μ»΄ν¬λ„νΈ
- **λ²΅ν„°DB**: Weaviate (ν•κµ­μ–΄ ν•μ΄λΈλ¦¬λ“ κ²€μƒ‰)
- **μ„λ² λ”©**: upskyy/bge-m3-korean λλ” BAAI/bge-m3
- **μ²­ν‚Ή**: 512-1024 ν† ν° (λ¬Έμ„ μ ν•λ³„ μ°¨λ³„ν™”)
- **κ²€μƒ‰**: ν•μ΄λΈλ¦¬λ“(μλ―Έ+ν‚¤μ›λ“) + λ¦¬λ­ν‚Ή

### κµ¬ν„ μ½”λ“
```python
# ν•μ΄λΈλ¦¬λ“ κ²€μƒ‰ μ„¤μ •
class HybridRetriever:
    def __init__(self, alpha=0.7):  # μλ―Έ:ν‚¤μ›λ“ = 7:3
        self.vectorstore = Weaviate(...)
        self.bm25 = BM25Okapi(...)
    
    def retrieve(self, query, k=10):
        # 1μ°¨: ν•μ΄λΈλ¦¬λ“ κ²€μƒ‰ (μƒμ„ 25κ°)
        candidates = self._hybrid_search(query, 25)
        # 2μ°¨: λ¦¬λ­ν‚Ή (μµμΆ… 3κ°)
        return self._rerank(query, candidates, 3)
```

## π“ μ¦κ°• μ „λµ μ„Έλ¶€μ‚¬ν•­

### λ‹¨κ³„λ³„ μ ‘κ·Ό
- **μ¦κ°•μ©**: EXAONE 3.0 λλ” SOLAR-10.7B (ν’μ§ μ°μ„ )
- **μ¶”λ΅ μ©**: λ™μΌ λ¨λΈ 4bit μ–‘μν™” (μ†λ„ μ°μ„ )

### λ©”λ¨λ¦¬ μµμ ν™”
- Gradient checkpointing μ‚¬μ©
- λ°°μΉ ν¬κΈ° λ™μ  μ΅°μ •
- λ¶ν•„μ”ν• ν…μ„ μ¦‰μ‹ μ‚­μ 

## β οΈ μ£Όμμ‚¬ν•­
- β API λ¨λΈ μ‚¬μ© κΈμ§€ (OpenAI, Claude λ“±)
- β 2025.07.31 μ΄ν›„ κ³µκ° λ¨λΈ μ‚¬μ© λ¶κ°€
- β… 270λ¶„ λ‚΄ 515λ¬Έν•­ μ²λ¦¬ ν•„μ
- β… μ¤ν”„λΌμΈ ν™κ²½ μ‹¤ν–‰ κ°€λ¥