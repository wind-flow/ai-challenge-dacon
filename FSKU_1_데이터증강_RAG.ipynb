{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 FSKU 데이터 증강 시스템 (RAG + Chain-of-Thought)\n",
    "\n",
    "## 📌 개요\n",
    "- **대회**: 2025 금융 AI Challenge Track1\n",
    "- **목적**: 외부 금융 문서 기반 고품질 학습 데이터 자동 생성\n",
    "- **핵심 기술**: RAG (Retrieval Augmented Generation) + LLM 체이닝 + 품질 관리\n",
    "\n",
    "## 🔄 전체 동작 프로세스\n",
    "```\n",
    "1. 문서 수집 → 2. RAG 인덱싱 → 3. 컨텍스트 검색 → 4. LLM 문제 생성 \n",
    "→ 5. 품질 평가 → 6. 체이닝 개선 → 7. 최종 검증 → 8. 데이터 저장\n",
    "```\n",
    "\n",
    "## 🛠️ 핵심 기법\n",
    "1. **RAG (Retrieval Augmented Generation)**\n",
    "   - 외부 금융 문서를 벡터 DB에 저장\n",
    "   - 의미 기반 검색으로 관련 컨텍스트 추출\n",
    "   - LLM 생성 시 참고 자료로 활용\n",
    "\n",
    "2. **Chain-of-Thought 체이닝**\n",
    "   - 생성 → 검증 → 개선 → 최종확인 4단계\n",
    "   - 각 단계별 전문 프롬프트 사용\n",
    "   - 품질 점수 기반 자동 개선\n",
    "\n",
    "3. **품질 관리 시스템**\n",
    "   - 다차원 평가 (길이, 구조, 명확성, 금융용어)\n",
    "   - 70점 이상만 통과\n",
    "   - 실시간 모니터링 대시보드\n",
    "\n",
    "## 📊 예상 결과\n",
    "- 생성 목표: 1,000~5,000개 고품질 문제\n",
    "- 품질 기준: 70점 이상\n",
    "- 소요 시간: 약 2-4시간 (모델 크기 따라)\n",
    "- 출력 형식: JSONL (학습용), 메타데이터 (분석용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 시스템 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고 메시지 숨기기\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 시스템 정보 출력\n",
    "import platform\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"🖥️  시스템 환경 정보\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"OS: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python: {platform.python_version()}\")\n",
    "print(f\"현재 디렉토리: {os.getcwd()}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 필수 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 패키지 설치\n",
    "# 주의: 이미 설치된 경우 스킵됩니다\n",
    "\n",
    "print(\"📦 필수 패키지 설치 중...\")\n",
    "print(\"(이미 설치된 패키지는 자동으로 스킵됩니다)\\n\")\n",
    "\n",
    "# 기본 패키지\n",
    "%pip install -q transformers accelerate bitsandbytes\n",
    "print(\"✅ Transformers 관련 패키지 설치 완료\")\n",
    "\n",
    "# 벡터 검색 및 임베딩\n",
    "%pip install -q sentence-transformers faiss-cpu\n",
    "print(\"✅ 벡터 검색 패키지 설치 완료\")\n",
    "\n",
    "# 문서 처리\n",
    "%pip install -q PyPDF2 pdfplumber pandas openpyxl\n",
    "print(\"✅ 문서 처리 패키지 설치 완료\")\n",
    "\n",
    "# 추가 유틸리티\n",
    "%pip install -q tiktoken langchain tqdm matplotlib seaborn\n",
    "print(\"✅ 유틸리티 패키지 설치 완료\")\n",
    "\n",
    "print(\"\\n✅ 모든 패키지 설치 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 라이브러리 임포트 및 환경 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "print(\"📚 라이브러리 임포트 중...\")\n",
    "\n",
    "# 기본 라이브러리\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Any, Tuple\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import logging\n",
    "\n",
    "# 데이터 처리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'  # 한글 폰트 설정\n",
    "\n",
    "# 딥러닝 프레임워크\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer, \n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "\n",
    "print(\"✅ 라이브러리 임포트 완료\\n\")\n",
    "\n",
    "# GPU/환경 체크\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"=\" * 60)\n",
    "print(\"🔥 PyTorch 환경 정보\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU 이름: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU 메모리: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
    "    print(f\"현재 할당된 메모리: {torch.cuda.memory_allocated() / 1024**3:.2f}GB\")\n",
    "else:\n",
    "    print(\"⚠️ GPU를 사용할 수 없습니다. CPU 모드로 실행됩니다.\")\n",
    "    print(\"   성능이 느릴 수 있습니다.\")\n",
    "\n",
    "# 프로젝트 경로 설정\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📁 프로젝트 경로 설정\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 현재 노트북의 위치를 기준으로 경로 설정\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "EXTERNAL_DIR = DATA_DIR / \"external\"  # 외부 문서 디렉토리\n",
    "OUTPUT_DIR = DATA_DIR / \"augmented\"   # 생성된 데이터 저장\n",
    "CACHE_DIR = DATA_DIR / \"cache\"        # 캐시 디렉토리\n",
    "VECTORDB_DIR = DATA_DIR / \"vectordb\"  # 벡터 DB 저장\n",
    "\n",
    "# 디렉토리 생성\n",
    "for dir_path in [DATA_DIR, EXTERNAL_DIR, OUTPUT_DIR, CACHE_DIR, VECTORDB_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"✅ {dir_path.name}/\")\n",
    "\n",
    "print(f\"\\n프로젝트 루트: {PROJECT_ROOT}\")\n",
    "print(f\"외부 데이터: {EXTERNAL_DIR}\")\n",
    "print(f\"출력 디렉토리: {OUTPUT_DIR}\")\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"\\n✅ 환경 설정 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RAG 시스템 - 문서 로더 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentLoader:\n",
    "    \"\"\"\n",
    "    다양한 형식의 문서를 로드하는 클래스\n",
    "    \n",
    "    지원 형식:\n",
    "    - PDF: PyPDF2 또는 pdfplumber 사용\n",
    "    - Excel: pandas로 읽기\n",
    "    - TXT: 기본 파일 읽기\n",
    "    - JSON: 구조화된 데이터 로드\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # 지원하는 파일 형식들\n",
    "        self.supported_formats = ['.pdf', '.txt', '.xlsx', '.xls', '.json']\n",
    "        \n",
    "    def load_document(self, file_path: Path) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        문서를 로드하는 메인 함수\n",
    "        \n",
    "        Args:\n",
    "            file_path: 문서 파일 경로\n",
    "            \n",
    "        Returns:\n",
    "            Dict: {\n",
    "                'content': str,      # 문서 전체 텍스트\n",
    "                'metadata': dict,    # 메타데이터\n",
    "                'pages': list       # 페이지별 텍스트 (PDF의 경우)\n",
    "            }\n",
    "        \"\"\"\n",
    "        # 파일 존재 확인\n",
    "        if not file_path.exists():\n",
    "            logger.error(f\"파일이 존재하지 않습니다: {file_path}\")\n",
    "            return None\n",
    "            \n",
    "        # 파일 확장자 추출\n",
    "        suffix = file_path.suffix.lower()\n",
    "        \n",
    "        # 지원하지 않는 형식 체크\n",
    "        if suffix not in self.supported_formats:\n",
    "            logger.warning(f\"지원하지 않는 파일 형식: {suffix}\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # 파일 형식별 처리\n",
    "            if suffix == '.pdf':\n",
    "                return self._load_pdf(file_path)\n",
    "            elif suffix == '.txt':\n",
    "                return self._load_text(file_path)\n",
    "            elif suffix in ['.xlsx', '.xls']:\n",
    "                return self._load_excel(file_path)\n",
    "            elif suffix == '.json':\n",
    "                return self._load_json(file_path)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"문서 로드 실패 {file_path}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _load_pdf(self, file_path: Path) -> Dict:\n",
    "        \"\"\"\n",
    "        PDF 파일 로드 - 페이지별 텍스트 추출\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import PyPDF2\n",
    "            \n",
    "            text_pages = []\n",
    "            metadata = {\n",
    "                'source': file_path.name,\n",
    "                'type': 'pdf',\n",
    "                'pages': 0\n",
    "            }\n",
    "            \n",
    "            # PDF 파일 열기\n",
    "            with open(file_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                metadata['pages'] = len(pdf_reader.pages)\n",
    "                \n",
    "                # 각 페이지에서 텍스트 추출\n",
    "                for page_num, page in enumerate(pdf_reader.pages):\n",
    "                    try:\n",
    "                        text = page.extract_text()\n",
    "                        if text.strip():  # 빈 페이지 제외\n",
    "                            text_pages.append({\n",
    "                                'page': page_num + 1,\n",
    "                                'content': text\n",
    "                            })\n",
    "                    except Exception as e:\n",
    "                        logger.debug(f\"페이지 {page_num+1} 추출 실패: {e}\")\n",
    "                        continue\n",
    "                        \n",
    "        except ImportError:\n",
    "            # PyPDF2가 없으면 pdfplumber 시도\n",
    "            logger.info(\"PyPDF2 대신 pdfplumber 사용\")\n",
    "            return self._load_pdf_with_pdfplumber(file_path)\n",
    "            \n",
    "        # 전체 텍스트 결합\n",
    "        full_text = \"\\n\\n\".join([\n",
    "            f\"[페이지 {p['page']}]\\n{p['content']}\" \n",
    "            for p in text_pages\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            'content': full_text,\n",
    "            'metadata': metadata,\n",
    "            'pages': text_pages\n",
    "        }\n",
    "    \n",
    "    def _load_pdf_with_pdfplumber(self, file_path: Path) -> Dict:\n",
    "        \"\"\"\n",
    "        pdfplumber로 PDF 로드 (대체 방법)\n",
    "        \"\"\"\n",
    "        import pdfplumber\n",
    "        \n",
    "        text_pages = []\n",
    "        metadata = {\n",
    "            'source': file_path.name,\n",
    "            'type': 'pdf',\n",
    "            'pages': 0\n",
    "        }\n",
    "        \n",
    "        # pdfplumber로 파일 열기\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            metadata['pages'] = len(pdf.pages)\n",
    "            \n",
    "            # 각 페이지 처리\n",
    "            for page_num, page in enumerate(pdf.pages):\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    text_pages.append({\n",
    "                        'page': page_num + 1,\n",
    "                        'content': text\n",
    "                    })\n",
    "        \n",
    "        # 전체 텍스트 결합\n",
    "        full_text = \"\\n\\n\".join([\n",
    "            f\"[페이지 {p['page']}]\\n{p['content']}\" \n",
    "            for p in text_pages\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            'content': full_text,\n",
    "            'metadata': metadata,\n",
    "            'pages': text_pages\n",
    "        }\n",
    "    \n",
    "    def _load_text(self, file_path: Path) -> Dict:\n",
    "        \"\"\"\n",
    "        텍스트 파일 로드\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # UTF-8로 시도\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            # 실패시 cp949(한글 윈도우) 인코딩 시도\n",
    "            with open(file_path, 'r', encoding='cp949') as f:\n",
    "                content = f.read()\n",
    "        \n",
    "        return {\n",
    "            'content': content,\n",
    "            'metadata': {\n",
    "                'source': file_path.name,\n",
    "                'type': 'text',\n",
    "                'size': len(content)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _load_excel(self, file_path: Path) -> Dict:\n",
    "        \"\"\"\n",
    "        Excel 파일 로드\n",
    "        \"\"\"\n",
    "        # 모든 시트 읽기\n",
    "        dfs = pd.read_excel(file_path, sheet_name=None)\n",
    "        \n",
    "        text_parts = []\n",
    "        # 각 시트별로 처리\n",
    "        for sheet_name, df in dfs.items():\n",
    "            text_parts.append(f\"\\n[시트: {sheet_name}]\\n\")\n",
    "            # DataFrame을 텍스트로 변환\n",
    "            text_parts.append(df.to_string())\n",
    "        \n",
    "        content = \"\\n\".join(text_parts)\n",
    "        \n",
    "        return {\n",
    "            'content': content,\n",
    "            'metadata': {\n",
    "                'source': file_path.name,\n",
    "                'type': 'excel',\n",
    "                'sheets': list(dfs.keys()),\n",
    "                'total_rows': sum(len(df) for df in dfs.values())\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _load_json(self, file_path: Path) -> Dict:\n",
    "        \"\"\"\n",
    "        JSON 파일 로드\n",
    "        \"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # JSON을 보기 좋은 텍스트로 변환\n",
    "        content = json.dumps(data, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        return {\n",
    "            'content': content,\n",
    "            'metadata': {\n",
    "                'source': file_path.name,\n",
    "                'type': 'json',\n",
    "                'keys': list(data.keys()) if isinstance(data, dict) else None\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def load_directory(self, dir_path: Path) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        디렉토리의 모든 문서 로드\n",
    "        \n",
    "        Args:\n",
    "            dir_path: 디렉토리 경로\n",
    "            \n",
    "        Returns:\n",
    "            문서 리스트\n",
    "        \"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        if not dir_path.exists():\n",
    "            logger.error(f\"디렉토리가 존재하지 않습니다: {dir_path}\")\n",
    "            return documents\n",
    "        \n",
    "        # 지원하는 형식의 파일들 찾기\n",
    "        total_files = 0\n",
    "        for ext in self.supported_formats:\n",
    "            for file_path in dir_path.glob(f\"*{ext}\"):\n",
    "                total_files += 1\n",
    "                print(f\"📄 로딩: {file_path.name}\")\n",
    "                \n",
    "                doc = self.load_document(file_path)\n",
    "                if doc:\n",
    "                    documents.append(doc)\n",
    "                    print(f\"   ✅ 성공 (크기: {len(doc['content']):,}자)\")\n",
    "                else:\n",
    "                    print(f\"   ❌ 실패\")\n",
    "        \n",
    "        print(f\"\\n📊 로드 결과: {len(documents)}/{total_files}개 문서 로드 완료\")\n",
    "        return documents\n",
    "\n",
    "\n",
    "# 문서 로더 테스트\n",
    "print(\"🔄 문서 로더 클래스 생성 완료\")\n",
    "loader = DocumentLoader()\n",
    "print(f\"지원 형식: {', '.join(loader.supported_formats)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RAG 시스템 - 문서 청킹 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentChunker:\n",
    "    \"\"\"\n",
    "    긴 문서를 의미 있는 단위로 분할하는 클래스\n",
    "    \n",
    "    특징:\n",
    "    - 청크 크기: 300 토큰 (RAG 최적화)\n",
    "    - 오버랩: 50 토큰 (문맥 유지)\n",
    "    - 한국어 특화: 형태소 기반 분할\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, chunk_size: int = 300, chunk_overlap: int = 50):\n",
    "        \"\"\"\n",
    "        초기화\n",
    "        \n",
    "        Args:\n",
    "            chunk_size: 각 청크의 최대 토큰 수\n",
    "            chunk_overlap: 청크 간 겹치는 토큰 수\n",
    "        \"\"\"\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.min_chunk_size = 50  # 최소 청크 크기\n",
    "        \n",
    "    def chunk_document(self, document: Dict) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        문서를 청크로 분할\n",
    "        \n",
    "        처리 과정:\n",
    "        1. 문서를 문장 단위로 분할\n",
    "        2. 각 문장의 토큰 수 계산\n",
    "        3. 청크 크기에 맞게 문장들을 결합\n",
    "        4. 오버랩 처리하여 문맥 유지\n",
    "        \"\"\"\n",
    "        content = document.get('content', '')\n",
    "        metadata = document.get('metadata', {})\n",
    "        \n",
    "        # PDF인 경우 페이지별 처리 고려\n",
    "        if metadata.get('type') == 'pdf' and 'pages' in document:\n",
    "            chunks = []\n",
    "            # 각 페이지별로 청킹\n",
    "            for page_info in document['pages']:\n",
    "                page_chunks = self._chunk_text(\n",
    "                    page_info['content'],\n",
    "                    {**metadata, 'page': page_info['page']}\n",
    "                )\n",
    "                chunks.extend(page_chunks)\n",
    "            return chunks\n",
    "        else:\n",
    "            # 일반 텍스트 처리\n",
    "            return self._chunk_text(content, metadata)\n",
    "    \n",
    "    def _chunk_text(self, text: str, metadata: Dict = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        텍스트를 청크로 분할하는 실제 로직\n",
    "        \"\"\"\n",
    "        if not text or len(text.strip()) < self.min_chunk_size:\n",
    "            return []\n",
    "        \n",
    "        # 문장 단위로 분할\n",
    "        sentences = self._split_sentences(text)\n",
    "        \n",
    "        # 청크 생성\n",
    "        chunks = []\n",
    "        current_chunk = []  # 현재 청크의 문장들\n",
    "        current_length = 0  # 현재 청크의 토큰 수\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            # 문장의 예상 토큰 수 계산\n",
    "            sentence_length = self._estimate_tokens(sentence)\n",
    "            \n",
    "            # 현재 청크가 크기를 초과하면 새 청크 시작\n",
    "            if current_length + sentence_length > self.chunk_size and current_chunk:\n",
    "                # 현재 청크 저장\n",
    "                chunk_text = ' '.join(current_chunk)\n",
    "                chunks.append(self._create_chunk(chunk_text, len(chunks), metadata))\n",
    "                \n",
    "                # 오버랩 처리: 이전 청크의 마지막 부분을 다음 청크에 포함\n",
    "                if self.chunk_overlap > 0:\n",
    "                    overlap_sentences = []\n",
    "                    overlap_length = 0\n",
    "                    \n",
    "                    # 뒤에서부터 오버랩 크기만큼 문장 선택\n",
    "                    for sent in reversed(current_chunk):\n",
    "                        sent_len = self._estimate_tokens(sent)\n",
    "                        if overlap_length + sent_len <= self.chunk_overlap:\n",
    "                            overlap_sentences.insert(0, sent)\n",
    "                            overlap_length += sent_len\n",
    "                        else:\n",
    "                            break\n",
    "                    \n",
    "                    current_chunk = overlap_sentences\n",
    "                    current_length = overlap_length\n",
    "                else:\n",
    "                    current_chunk = []\n",
    "                    current_length = 0\n",
    "            \n",
    "            # 현재 문장 추가\n",
    "            current_chunk.append(sentence)\n",
    "            current_length += sentence_length\n",
    "        \n",
    "        # 마지막 청크 처리\n",
    "        if current_chunk:\n",
    "            chunk_text = ' '.join(current_chunk)\n",
    "            if len(chunk_text.strip()) >= self.min_chunk_size:\n",
    "                chunks.append(self._create_chunk(chunk_text, len(chunks), metadata))\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def _split_sentences(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        텍스트를 문장으로 분할\n",
    "        한국어 문장 종결 어미를 고려한 분할\n",
    "        \"\"\"\n",
    "        # 문장 종결 패턴 (한국어 + 영어)\n",
    "        sentence_endings = r'[.!?。]\\s+'\n",
    "        \n",
    "        # 특수 케이스 처리 (예: 조항 번호)\n",
    "        # \"제1조.\" 같은 경우를 문장 끝으로 인식하지 않도록\n",
    "        text = re.sub(r'(\\d+)\\.\\s*(\\d+)', r'\\1_\\2', text)  # 1.2 -> 1_2\n",
    "        text = re.sub(r'(\\d+)\\.\\s*([가-힣])', r'\\1_\\2', text)  # 1.가 -> 1_가\n",
    "        text = re.sub(r'제(\\d+)조\\.', r'제\\1조_', text)  # 제1조. -> 제1조_\n",
    "        \n",
    "        # 문장 분할\n",
    "        sentences = re.split(sentence_endings, text)\n",
    "        \n",
    "        # 특수 케이스 복원\n",
    "        sentences = [s.replace('_', '.') for s in sentences]\n",
    "        \n",
    "        # 빈 문장 제거 및 정리\n",
    "        sentences = [s.strip() for s in sentences if s.strip()]\n",
    "        \n",
    "        # 너무 짧은 문장은 다음 문장과 결합\n",
    "        combined_sentences = []\n",
    "        temp_sentence = \"\"\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if len(sentence) < 20 and temp_sentence:\n",
    "                # 짧은 문장은 이전 문장과 결합\n",
    "                temp_sentence += \" \" + sentence\n",
    "            else:\n",
    "                if temp_sentence:\n",
    "                    combined_sentences.append(temp_sentence)\n",
    "                temp_sentence = sentence\n",
    "        \n",
    "        if temp_sentence:\n",
    "            combined_sentences.append(temp_sentence)\n",
    "        \n",
    "        return combined_sentences\n",
    "    \n",
    "    def _estimate_tokens(self, text: str) -> int:\n",
    "        \"\"\"\n",
    "        텍스트의 토큰 수 추정\n",
    "        \n",
    "        한국어/영어/숫자를 고려한 추정:\n",
    "        - 한글: 평균 2.5자 = 1토큰\n",
    "        - 영어: 평균 4자 = 1토큰\n",
    "        - 숫자: 평균 3자 = 1토큰\n",
    "        \"\"\"\n",
    "        # 문자 유형별 개수 계산\n",
    "        korean_chars = len(re.findall(r'[가-힣]', text))\n",
    "        english_chars = len(re.findall(r'[a-zA-Z]', text))\n",
    "        numbers = len(re.findall(r'\\d', text))\n",
    "        \n",
    "        # 토큰 수 추정\n",
    "        estimated_tokens = (\n",
    "            korean_chars / 2.5 +\n",
    "            english_chars / 4 +\n",
    "            numbers / 3\n",
    "        )\n",
    "        \n",
    "        return int(estimated_tokens)\n",
    "    \n",
    "    def _create_chunk(self, text: str, index: int, metadata: Dict = None) -> Dict:\n",
    "        \"\"\"\n",
    "        청크 딕셔너리 생성\n",
    "        \"\"\"\n",
    "        chunk = {\n",
    "            'content': text.strip(),\n",
    "            'chunk_id': index,\n",
    "            'tokens': self._estimate_tokens(text),\n",
    "            'metadata': metadata or {}\n",
    "        }\n",
    "        \n",
    "        # 청크에서 핵심 키워드 추출\n",
    "        keywords = self._extract_keywords(text)\n",
    "        if keywords:\n",
    "            chunk['keywords'] = keywords\n",
    "        \n",
    "        return chunk\n",
    "    \n",
    "    def _extract_keywords(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        텍스트에서 핵심 키워드 추출\n",
    "        금융 문서의 특성을 고려한 키워드 추출\n",
    "        \"\"\"\n",
    "        keywords = []\n",
    "        \n",
    "        # 조항 번호 패턴 (예: 제1조, 제2항)\n",
    "        article_patterns = re.findall(r'제\\d+조', text)\n",
    "        keywords.extend(article_patterns[:3])  # 최대 3개\n",
    "        \n",
    "        # 괄호 안의 정의 (예: 전자금융거래(이하 \"전자거래\"라 한다))\n",
    "        definitions = re.findall(r'[가-힣]+(?:\\([^)]+\\))', text)\n",
    "        keywords.extend(definitions[:3])  # 최대 3개\n",
    "        \n",
    "        # 금융 관련 핵심 용어들\n",
    "        finance_terms = [\n",
    "            '금융', '은행', '증권', '보험', '신용', '대출', '예금',\n",
    "            '전자금융', '개인정보', '암호화', '보안', '인증'\n",
    "        ]\n",
    "        \n",
    "        # 텍스트에 포함된 금융 용어 찾기\n",
    "        found_terms = [term for term in finance_terms if term in text]\n",
    "        keywords.extend(found_terms[:2])  # 최대 2개\n",
    "        \n",
    "        # 중복 제거하여 반환\n",
    "        return list(dict.fromkeys(keywords))  # 순서 유지하며 중복 제거\n",
    "\n",
    "\n",
    "# 청킹 클래스 테스트\n",
    "print(\"🔄 문서 청킹 클래스 생성 완료\")\n",
    "chunker = DocumentChunker(chunk_size=300, chunk_overlap=50)\n",
    "print(f\"청크 크기: {chunker.chunk_size} 토큰\")\n",
    "print(f\"오버랩: {chunker.chunk_overlap} 토큰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RAG 시스템 - 벡터 검색 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentRetriever:\n",
    "    \"\"\"\n",
    "    RAG의 핵심 - 벡터 기반 문서 검색 시스템\n",
    "    \n",
    "    특징:\n",
    "    - 임베딩 모델: jhgan/ko-sbert-nli (한국어 특화)\n",
    "    - 검색 방법: 코사인 유사도 + BM25 하이브리드\n",
    "    - 캐싱: 인덱스 저장으로 빠른 재실행\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, use_cache: bool = True):\n",
    "        \"\"\"\n",
    "        초기화\n",
    "        \n",
    "        Args:\n",
    "            use_cache: 캐시 사용 여부\n",
    "        \"\"\"\n",
    "        self.use_cache = use_cache\n",
    "        self.cache_path = VECTORDB_DIR / \"rag_index.pkl\"\n",
    "        \n",
    "        # 데이터 저장소\n",
    "        self.documents = []  # 원본 문서들\n",
    "        self.chunks = []     # 청킹된 텍스트들\n",
    "        self.embeddings = None  # 벡터 임베딩\n",
    "        self.embedding_model = None  # 임베딩 모델\n",
    "        \n",
    "        # BM25를 위한 인덱스\n",
    "        self.chunk_index = defaultdict(list)  # 키워드 -> 청크 인덱스\n",
    "        \n",
    "        # 캐시 확인 및 로드\n",
    "        if use_cache and self.cache_path.exists():\n",
    "            print(\"📂 캐시된 인덱스 발견...\")\n",
    "            if self._load_cache():\n",
    "                print(\"✅ 캐시에서 인덱스 로드 완료!\")\n",
    "                return\n",
    "                \n",
    "        print(\"🔄 새로운 인덱스를 생성해야 합니다.\")\n",
    "    \n",
    "    def build_index(self, documents: List[Dict]):\n",
    "        \"\"\"\n",
    "        검색 인덱스 구축\n",
    "        \n",
    "        단계:\n",
    "        1. 문서 청킹\n",
    "        2. 임베딩 생성\n",
    "        3. BM25 인덱스 구축\n",
    "        4. 캐시 저장\n",
    "        \"\"\"\n",
    "        print(\"\\n🔨 인덱스 구축 시작...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 1. 문서 저장\n",
    "        self.documents = documents\n",
    "        \n",
    "        # 2. 청킹\n",
    "        print(\"📄 문서 청킹 중...\")\n",
    "        chunker = DocumentChunker(chunk_size=300, chunk_overlap=50)\n",
    "        \n",
    "        for doc in tqdm(documents, desc=\"문서 처리\"):\n",
    "            doc_chunks = chunker.chunk_document(doc)\n",
    "            \n",
    "            # 각 청크에 소스 정보 추가\n",
    "            for chunk in doc_chunks:\n",
    "                chunk['source'] = doc['metadata']['source']\n",
    "                chunk['doc_type'] = doc['metadata']['type']\n",
    "            \n",
    "            self.chunks.extend(doc_chunks)\n",
    "        \n",
    "        print(f\"✅ {len(self.chunks)}개 청크 생성 완료\")\n",
    "        \n",
    "        # 3. 임베딩 생성\n",
    "        self._create_embeddings()\n",
    "        \n",
    "        # 4. BM25 인덱스 구축\n",
    "        self._build_bm25_index()\n",
    "        \n",
    "        # 5. 캐시 저장\n",
    "        if self.use_cache:\n",
    "            self._save_cache()\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"\\n✅ 인덱스 구축 완료! (소요 시간: {elapsed_time:.1f}초)\")\n",
    "    \n",
    "    def _create_embeddings(self):\n",
    "        \"\"\"\n",
    "        모든 청크에 대한 벡터 임베딩 생성\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            \n",
    "            # 한국어 특화 모델 사용\n",
    "            model_name = \"jhgan/ko-sbert-nli\"\n",
    "            print(f\"\\n🤖 임베딩 모델 로드 중: {model_name}\")\n",
    "            \n",
    "            self.embedding_model = SentenceTransformer(model_name)\n",
    "            print(\"✅ 임베딩 모델 로드 완료\")\n",
    "            \n",
    "            # 모든 청크의 텍스트 추출\n",
    "            texts = [chunk['content'] for chunk in self.chunks]\n",
    "            \n",
    "            # 임베딩 생성 (배치 처리)\n",
    "            print(f\"🔄 {len(texts)}개 청크 임베딩 중...\")\n",
    "            self.embeddings = self.embedding_model.encode(\n",
    "                texts,\n",
    "                normalize_embeddings=True,  # 정규화로 코사인 유사도 계산 최적화\n",
    "                show_progress_bar=True,\n",
    "                batch_size=32\n",
    "            )\n",
    "            \n",
    "            print(f\"✅ 임베딩 완료 (차원: {self.embeddings.shape})\")\n",
    "            \n",
    "        except ImportError:\n",
    "            logger.warning(\"sentence-transformers가 설치되지 않았습니다.\")\n",
    "            logger.warning(\"BM25 검색만 사용합니다.\")\n",
    "            self.embeddings = None\n",
    "    \n",
    "    def _build_bm25_index(self):\n",
    "        \"\"\"\n",
    "        BM25 검색을 위한 역인덱스 구축\n",
    "        \"\"\"\n",
    "        print(\"\\n📑 BM25 인덱스 구축 중...\")\n",
    "        \n",
    "        for idx, chunk in enumerate(self.chunks):\n",
    "            content = chunk['content'].lower()\n",
    "            \n",
    "            # 단어 추출 (한글, 영어, 숫자)\n",
    "            words = re.findall(r'[가-힣]+|[a-zA-Z]+|\\d+', content)\n",
    "            \n",
    "            # 각 단어에 대해 청크 인덱스 저장\n",
    "            for word in set(words):  # 중복 제거\n",
    "                if len(word) >= 2:  # 2글자 이상만\n",
    "                    self.chunk_index[word].append(idx)\n",
    "            \n",
    "            # 키워드가 있으면 추가\n",
    "            if 'keywords' in chunk:\n",
    "                for keyword in chunk['keywords']:\n",
    "                    self.chunk_index[keyword.lower()].append(idx)\n",
    "        \n",
    "        print(f\"✅ BM25 인덱스 구축 완료: {len(self.chunk_index)}개 키워드\")\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 3, method: str = \"hybrid\") -> str:\n",
    "        \"\"\"\n",
    "        문서 검색\n",
    "        \n",
    "        Args:\n",
    "            query: 검색 쿼리\n",
    "            top_k: 반환할 청크 수\n",
    "            method: 검색 방법 (\"similarity\", \"bm25\", \"hybrid\")\n",
    "            \n",
    "        Returns:\n",
    "            검색된 컨텍스트 문자열\n",
    "        \"\"\"\n",
    "        if not self.chunks:\n",
    "            return \"\"\n",
    "        \n",
    "        # 검색 방법별 처리\n",
    "        if method == \"similarity\" and self.embeddings is not None:\n",
    "            results = self._similarity_search(query, top_k * 2)\n",
    "        elif method == \"bm25\":\n",
    "            results = self._bm25_search(query, top_k * 2)\n",
    "        elif method == \"hybrid\" and self.embeddings is not None:\n",
    "            results = self._hybrid_search(query, top_k * 2)\n",
    "        else:\n",
    "            # 폴백: BM25 사용\n",
    "            results = self._bm25_search(query, top_k * 2)\n",
    "        \n",
    "        # 상위 k개 선택 및 중복 제거\n",
    "        seen_content = set()\n",
    "        final_results = []\n",
    "        \n",
    "        for chunk_idx, score in results[:top_k*2]:\n",
    "            chunk = self.chunks[chunk_idx]\n",
    "            content_hash = hash(chunk['content'][:100])  # 앞부분으로 중복 체크\n",
    "            \n",
    "            if content_hash not in seen_content:\n",
    "                seen_content.add(content_hash)\n",
    "                final_results.append((chunk, score))\n",
    "                \n",
    "                if len(final_results) >= top_k:\n",
    "                    break\n",
    "        \n",
    "        # 컨텍스트 생성\n",
    "        contexts = []\n",
    "        for chunk, score in final_results:\n",
    "            source = chunk.get('source', 'Unknown')\n",
    "            content = chunk['content']\n",
    "            \n",
    "            # 소스 정보 포함\n",
    "            context = f\"[출처: {source}]\\n{content}\"\n",
    "            contexts.append(context)\n",
    "        \n",
    "        return \"\\n\\n---\\n\\n\".join(contexts)\n",
    "    \n",
    "    def _similarity_search(self, query: str, top_k: int) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        임베딩 기반 유사도 검색\n",
    "        \"\"\"\n",
    "        # 쿼리 임베딩 생성\n",
    "        query_embedding = self.embedding_model.encode(\n",
    "            [query],\n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "        \n",
    "        # 코사인 유사도 계산 (정규화된 벡터이므로 내적이 코사인 유사도)\n",
    "        similarities = np.dot(self.embeddings, query_embedding.T).flatten()\n",
    "        \n",
    "        # 상위 k개 인덱스\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        # (인덱스, 점수) 튜플 리스트 반환\n",
    "        results = [(int(idx), float(similarities[idx])) for idx in top_indices]\n",
    "        return results\n",
    "    \n",
    "    def _bm25_search(self, query: str, top_k: int) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        BM25 기반 키워드 검색\n",
    "        \"\"\"\n",
    "        query_lower = query.lower()\n",
    "        query_words = re.findall(r'[가-힣]+|[a-zA-Z]+|\\d+', query_lower)\n",
    "        \n",
    "        # BM25 파라미터\n",
    "        k1 = 1.2  # 단어 빈도 포화도\n",
    "        b = 0.75  # 문서 길이 정규화\n",
    "        \n",
    "        # 평균 문서 길이\n",
    "        avg_len = np.mean([len(chunk['content']) for chunk in self.chunks])\n",
    "        \n",
    "        # 각 청크에 대한 점수 계산\n",
    "        scores = defaultdict(float)\n",
    "        \n",
    "        for word in query_words:\n",
    "            if word in self.chunk_index:\n",
    "                # IDF 계산\n",
    "                df = len(self.chunk_index[word])  # 문서 빈도\n",
    "                idf = np.log((len(self.chunks) - df + 0.5) / (df + 0.5) + 1)\n",
    "                \n",
    "                # 각 문서에 대한 BM25 점수\n",
    "                for chunk_idx in self.chunk_index[word]:\n",
    "                    chunk = self.chunks[chunk_idx]\n",
    "                    tf = chunk['content'].lower().count(word)  # 단어 빈도\n",
    "                    doc_len = len(chunk['content'])\n",
    "                    \n",
    "                    # BM25 점수 계산\n",
    "                    score = idf * (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * doc_len / avg_len))\n",
    "                    scores[chunk_idx] += score\n",
    "        \n",
    "        # 점수순 정렬\n",
    "        sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_scores[:top_k]\n",
    "    \n",
    "    def _hybrid_search(self, query: str, top_k: int) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        하이브리드 검색 (유사도 + BM25)\n",
    "        \"\"\"\n",
    "        # 각각의 검색 수행\n",
    "        similarity_results = self._similarity_search(query, top_k)\n",
    "        bm25_results = self._bm25_search(query, top_k)\n",
    "        \n",
    "        # 점수를 딕셔너리로 변환\n",
    "        similarity_scores = {idx: score for idx, score in similarity_results}\n",
    "        bm25_scores = {idx: score for idx, score in bm25_results}\n",
    "        \n",
    "        # 모든 고유 인덱스\n",
    "        all_indices = set(similarity_scores.keys()) | set(bm25_scores.keys())\n",
    "        \n",
    "        # 점수 정규화 및 결합\n",
    "        hybrid_scores = {}\n",
    "        \n",
    "        # 최대값으로 정규화\n",
    "        max_sim = max(similarity_scores.values()) if similarity_scores else 1\n",
    "        max_bm25 = max(bm25_scores.values()) if bm25_scores else 1\n",
    "        \n",
    "        for idx in all_indices:\n",
    "            # 정규화된 점수 (없으면 0)\n",
    "            norm_sim = similarity_scores.get(idx, 0) / max_sim\n",
    "            norm_bm25 = bm25_scores.get(idx, 0) / max_bm25\n",
    "            \n",
    "            # 가중 평균 (유사도 0.7, BM25 0.3)\n",
    "            hybrid_scores[idx] = 0.7 * norm_sim + 0.3 * norm_bm25\n",
    "        \n",
    "        # 정렬\n",
    "        sorted_scores = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_scores[:top_k]\n",
    "    \n",
    "    def get_random_chunks(self, n: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        랜덤 청크 가져오기 (데이터 생성시 다양성 확보용)\n",
    "        \"\"\"\n",
    "        if not self.chunks:\n",
    "            return \"\"\n",
    "        \n",
    "        # 랜덤하게 n개 청크 선택\n",
    "        selected_chunks = random.sample(self.chunks, min(n, len(self.chunks)))\n",
    "        \n",
    "        contexts = []\n",
    "        for chunk in selected_chunks:\n",
    "            source = chunk.get('source', 'Unknown')\n",
    "            content = chunk['content']\n",
    "            context = f\"[출처: {source}]\\n{content}\"\n",
    "            contexts.append(context)\n",
    "        \n",
    "        return \"\\n\\n---\\n\\n\".join(contexts)\n",
    "    \n",
    "    def get_statistics(self) -> Dict:\n",
    "        \"\"\"\n",
    "        통계 정보 반환\n",
    "        \"\"\"\n",
    "        stats = {\n",
    "            'total_documents': len(self.documents),\n",
    "            'total_chunks': len(self.chunks),\n",
    "            'total_keywords': len(self.chunk_index),\n",
    "            'avg_chunk_size': np.mean([chunk.get('tokens', 0) for chunk in self.chunks]) if self.chunks else 0,\n",
    "            'has_embeddings': self.embeddings is not None\n",
    "        }\n",
    "        \n",
    "        # 문서 타입별 통계\n",
    "        if self.chunks:\n",
    "            doc_types = Counter(chunk.get('doc_type', 'Unknown') for chunk in self.chunks)\n",
    "            stats['document_types'] = dict(doc_types)\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def _save_cache(self):\n",
    "        \"\"\"\n",
    "        인덱스를 캐시 파일로 저장\n",
    "        \"\"\"\n",
    "        print(\"\\n💾 인덱스 캐시 저장 중...\")\n",
    "        \n",
    "        cache_data = {\n",
    "            'chunks': self.chunks,\n",
    "            'chunk_index': dict(self.chunk_index),\n",
    "            'embeddings': self.embeddings,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(self.cache_path, 'wb') as f:\n",
    "            pickle.dump(cache_data, f)\n",
    "        \n",
    "        print(f\"✅ 캐시 저장 완료: {self.cache_path}\")\n",
    "    \n",
    "    def _load_cache(self) -> bool:\n",
    "        \"\"\"\n",
    "        캐시 파일에서 인덱스 로드\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(self.cache_path, 'rb') as f:\n",
    "                cache_data = pickle.load(f)\n",
    "            \n",
    "            self.chunks = cache_data['chunks']\n",
    "            self.chunk_index = defaultdict(list, cache_data['chunk_index'])\n",
    "            self.embeddings = cache_data['embeddings']\n",
    "            \n",
    "            print(f\"📅 캐시 생성 시간: {cache_data.get('timestamp', 'Unknown')}\")\n",
    "            print(f\"📊 로드된 청크 수: {len(self.chunks)}\")\n",
    "            \n",
    "            # 임베딩 모델 로드 (필요시)\n",
    "            if self.embeddings is not None:\n",
    "                from sentence_transformers import SentenceTransformer\n",
    "                self.embedding_model = SentenceTransformer(\"jhgan/ko-sbert-nli\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"캐시 로드 실패: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "# 검색 시스템 테스트\n",
    "print(\"🔄 문서 검색 시스템 클래스 생성 완료\")\n",
    "print(\"지원 검색 방법: similarity (벡터), bm25 (키워드), hybrid (결합)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. RAG 시스템 통합 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSystem:\n",
    "    \"\"\"\n",
    "    RAG 컴포넌트 통합 관리 클래스\n",
    "    \n",
    "    주요 기능:\n",
    "    - 문서 로드 → 청킹 → 인덱싱 → 검색\n",
    "    - 캐시 관리로 빠른 재실행\n",
    "    - 통합 인터페이스 제공\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"컴포넌트 초기화\"\"\"\n",
    "        self.loader = DocumentLoader()\n",
    "        self.chunker = DocumentChunker()\n",
    "        self.retriever = DocumentRetriever()\n",
    "        self.is_initialized = False\n",
    "        \n",
    "    def initialize(self, data_dir: Path, force_rebuild: bool = False):\n",
    "        \"\"\"\n",
    "        RAG 시스템 초기화\n",
    "        \n",
    "        Args:\n",
    "            data_dir: 문서가 있는 디렉토리\n",
    "            force_rebuild: 캐시 무시하고 재구축\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"🚀 RAG 시스템 초기화\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # 캐시 확인\n",
    "        cache_exists = (VECTORDB_DIR / \"rag_index.pkl\").exists()\n",
    "        \n",
    "        if cache_exists and not force_rebuild:\n",
    "            # 캐시가 있으면 로드 시도\n",
    "            if self.retriever.chunks:  # 이미 로드됨\n",
    "                print(\"✅ RAG 시스템이 이미 초기화되어 있습니다.\")\n",
    "                self.is_initialized = True\n",
    "                return\n",
    "        \n",
    "        # 새로 구축이 필요한 경우\n",
    "        if force_rebuild:\n",
    "            print(\"🔄 강제 재구축 모드\")\n",
    "        \n",
    "        # 1. 문서 로드\n",
    "        print(\"\\n[1/3] 문서 로드 중...\")\n",
    "        documents = self.loader.load_directory(data_dir)\n",
    "        \n",
    "        if not documents:\n",
    "            print(\"⚠️ 로드된 문서가 없습니다!\")\n",
    "            print(f\"   {data_dir} 디렉토리에 PDF, TXT, Excel 파일을 추가하세요.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n📚 총 {len(documents)}개 문서 로드 완료\")\n",
    "        \n",
    "        # 2. 인덱스 구축\n",
    "        print(\"\\n[2/3] 인덱스 구축 중...\")\n",
    "        self.retriever.build_index(documents)\n",
    "        \n",
    "        # 3. 통계 출력\n",
    "        print(\"\\n[3/3] 초기화 완료\")\n",
    "        stats = self.retriever.get_statistics()\n",
    "        self._print_statistics(stats)\n",
    "        \n",
    "        self.is_initialized = True\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 3, method: str = \"hybrid\") -> str:\n",
    "        \"\"\"\n",
    "        관련 컨텍스트 검색\n",
    "        \n",
    "        Args:\n",
    "            query: 검색 쿼리\n",
    "            top_k: 반환할 청크 수\n",
    "            method: 검색 방법\n",
    "            \n",
    "        Returns:\n",
    "            검색된 컨텍스트\n",
    "        \"\"\"\n",
    "        if not self.is_initialized:\n",
    "            logger.warning(\"RAG 시스템이 초기화되지 않았습니다.\")\n",
    "            return \"\"\n",
    "        \n",
    "        return self.retriever.search(query, top_k, method)\n",
    "    \n",
    "    def get_random_context(self, n: int = 2) -> str:\n",
    "        \"\"\"\n",
    "        랜덤 컨텍스트 가져오기\n",
    "        \n",
    "        Args:\n",
    "            n: 가져올 청크 수\n",
    "            \n",
    "        Returns:\n",
    "            랜덤 컨텍스트\n",
    "        \"\"\"\n",
    "        if not self.is_initialized:\n",
    "            logger.warning(\"RAG 시스템이 초기화되지 않았습니다.\")\n",
    "            return \"\"\n",
    "        \n",
    "        return self.retriever.get_random_chunks(n)\n",
    "    \n",
    "    def _print_statistics(self, stats: Dict):\n",
    "        \"\"\"\n",
    "        통계 정보 출력\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"📊 RAG 시스템 통계\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"문서 수: {stats['total_documents']}개\")\n",
    "        print(f\"청크 수: {stats['total_chunks']}개\")\n",
    "        print(f\"인덱싱된 키워드: {stats['total_keywords']}개\")\n",
    "        print(f\"평균 청크 크기: {stats['avg_chunk_size']:.1f} 토큰\")\n",
    "        print(f\"벡터 임베딩: {'활성화' if stats['has_embeddings'] else '비활성화'}\")\n",
    "        \n",
    "        if 'document_types' in stats:\n",
    "            print(\"\\n문서 타입별 분포:\")\n",
    "            for doc_type, count in stats['document_types'].items():\n",
    "                print(f\"  - {doc_type}: {count}개\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    def rebuild_index(self, data_dir: Path):\n",
    "        \"\"\"\n",
    "        인덱스 재구축\n",
    "        \"\"\"\n",
    "        print(\"🔄 인덱스 재구축 시작...\")\n",
    "        self.initialize(data_dir, force_rebuild=True)\n",
    "    \n",
    "    def test_search(self, test_queries: List[str] = None):\n",
    "        \"\"\"\n",
    "        검색 기능 테스트\n",
    "        \"\"\"\n",
    "        if not self.is_initialized:\n",
    "            print(\"⚠️ RAG 시스템을 먼저 초기화하세요.\")\n",
    "            return\n",
    "        \n",
    "        # 기본 테스트 쿼리\n",
    "        if test_queries is None:\n",
    "            test_queries = [\n",
    "                \"전자금융거래\",\n",
    "                \"개인정보보호\",\n",
    "                \"암호화 기술\",\n",
    "                \"금융보안\"\n",
    "            ]\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"🔍 RAG 검색 테스트\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for query in test_queries:\n",
    "            print(f\"\\n📌 검색어: '{query}'\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # 하이브리드 검색\n",
    "            result = self.search(query, top_k=2, method=\"hybrid\")\n",
    "            \n",
    "            if result:\n",
    "                # 결과를 200자로 제한하여 출력\n",
    "                preview = result[:200] + \"...\" if len(result) > 200 else result\n",
    "                print(preview)\n",
    "            else:\n",
    "                print(\"검색 결과 없음\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "# RAG 시스템 생성\n",
    "print(\"✅ RAG 시스템 통합 클래스 생성 완료\")\n",
    "rag_system = RAGSystem()\n",
    "print(\"\\nRAG 시스템 사용 준비 완료!\")\n",
    "print(\"다음 명령으로 초기화하세요:\")\n",
    "print(\"  rag_system.initialize(EXTERNAL_DIR)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. RAG 시스템 초기화 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 시스템 초기화\n",
    "# 주의: 외부 문서가 없으면 작동하지 않습니다!\n",
    "\n",
    "# 외부 데이터 디렉토리 확인\n",
    "print(\"📁 외부 데이터 디렉토리 확인...\")\n",
    "print(f\"경로: {EXTERNAL_DIR}\")\n",
    "\n",
    "# 디렉토리의 파일 목록 확인\n",
    "if EXTERNAL_DIR.exists():\n",
    "    files = list(EXTERNAL_DIR.glob(\"*\"))\n",
    "    if files:\n",
    "        print(f\"\\n발견된 파일 ({len(files)}개):\")\n",
    "        for file in files[:10]:  # 최대 10개만 표시\n",
    "            print(f\"  - {file.name}\")\n",
    "        if len(files) > 10:\n",
    "            print(f\"  ... 외 {len(files)-10}개\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ 디렉토리가 비어있습니다!\")\n",
    "        print(\"PDF, TXT, Excel 형식의 금융 문서를 추가하세요.\")\n",
    "else:\n",
    "    print(\"\\n❌ 디렉토리가 존재하지 않습니다!\")\n",
    "    EXTERNAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"✅ 디렉토리 생성 완료: {EXTERNAL_DIR}\")\n",
    "\n",
    "# RAG 초기화 실행\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "choice = input(\"RAG 시스템을 초기화하시겠습니까? (y/n): \")\n",
    "\n",
    "if choice.lower() == 'y':\n",
    "    # 초기화 실행\n",
    "    rag_system.initialize(EXTERNAL_DIR)\n",
    "    \n",
    "    # 초기화 성공시 테스트\n",
    "    if rag_system.is_initialized:\n",
    "        print(\"\\n✅ RAG 시스템 초기화 성공!\")\n",
    "        \n",
    "        # 검색 테스트 실행 여부 확인\n",
    "        test_choice = input(\"\\n검색 테스트를 실행하시겠습니까? (y/n): \")\n",
    "        if test_choice.lower() == 'y':\n",
    "            rag_system.test_search()\n",
    "else:\n",
    "    print(\"\\n초기화를 건너뜁니다.\")\n",
    "    print(\"나중에 다음 명령으로 초기화할 수 있습니다:\")\n",
    "    print(\"  rag_system.initialize(EXTERNAL_DIR)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. RAG 검색 예제 및 활용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 검색 활용 예제\n",
    "\n",
    "if rag_system.is_initialized:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"📚 RAG 검색 활용 예제\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. 특정 주제 검색\n",
    "    print(\"\\n1️⃣ 특정 주제 검색\")\n",
    "    query = \"개인정보보호법\"\n",
    "    result = rag_system.search(query, top_k=2)\n",
    "    print(f\"검색어: '{query}'\")\n",
    "    print(f\"결과:\\n{result[:300]}...\\n\")\n",
    "    \n",
    "    # 2. 다양한 검색 방법 비교\n",
    "    print(\"\\n2️⃣ 검색 방법 비교\")\n",
    "    query = \"암호화\"\n",
    "    \n",
    "    # BM25 검색\n",
    "    bm25_result = rag_system.search(query, top_k=1, method=\"bm25\")\n",
    "    print(f\"BM25 검색 결과 길이: {len(bm25_result)}자\")\n",
    "    \n",
    "    # 벡터 유사도 검색\n",
    "    if rag_system.retriever.embeddings is not None:\n",
    "        sim_result = rag_system.search(query, top_k=1, method=\"similarity\")\n",
    "        print(f\"유사도 검색 결과 길이: {len(sim_result)}자\")\n",
    "    \n",
    "    # 하이브리드 검색\n",
    "    hybrid_result = rag_system.search(query, top_k=1, method=\"hybrid\")\n",
    "    print(f\"하이브리드 검색 결과 길이: {len(hybrid_result)}자\")\n",
    "    \n",
    "    # 3. 랜덤 컨텍스트 가져오기\n",
    "    print(\"\\n3️⃣ 랜덤 컨텍스트 (데이터 생성용)\")\n",
    "    random_context = rag_system.get_random_context(n=2)\n",
    "    print(f\"랜덤 컨텍스트:\\n{random_context[:300]}...\\n\")\n",
    "    \n",
    "    # 4. 복합 쿼리 예제\n",
    "    print(\"\\n4️⃣ 복합 쿼리 예제\")\n",
    "    complex_query = \"전자금융거래 보안 인증\"\n",
    "    result = rag_system.search(complex_query, top_k=3)\n",
    "    print(f\"복합 검색어: '{complex_query}'\")\n",
    "    print(f\"검색된 청크 수: {len(result.split('---'))}개\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ RAG 시스템이 초기화되지 않았습니다.\")\n",
    "    print(\"먼저 위의 셀에서 RAG 시스템을 초기화하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. RAG 모듈 저장 (추론용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론에서도 사용할 RAG 모듈을 별도 파일로 저장\n",
    "# 이렇게 하면 추론 노트북에서도 동일한 RAG 시스템을 사용할 수 있습니다.\n",
    "\n",
    "rag_module_content = '''\n",
    "\"\"\"\n",
    "RAG 모듈 (경량화 버전)\n",
    "추론 시에도 사용할 수 있는 최소한의 RAG 기능만 포함\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class LightweightRAG:\n",
    "    \"\"\"추론용 경량 RAG 시스템\"\"\"\n",
    "    \n",
    "    def __init__(self, index_path: str):\n",
    "        \"\"\"사전 구축된 인덱스 로드\"\"\"\n",
    "        self.index_path = Path(index_path)\n",
    "        self.chunks = []\n",
    "        self.chunk_index = defaultdict(list)\n",
    "        self.embeddings = None\n",
    "        self._load_index()\n",
    "    \n",
    "    def _load_index(self):\n",
    "        \"\"\"인덱스 로드\"\"\"\n",
    "        if not self.index_path.exists():\n",
    "            raise FileNotFoundError(f\"인덱스 파일이 없습니다: {self.index_path}\")\n",
    "        \n",
    "        with open(self.index_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        self.chunks = data['chunks']\n",
    "        self.chunk_index = defaultdict(list, data['chunk_index'])\n",
    "        self.embeddings = data.get('embeddings')\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 3) -> str:\n",
    "        \"\"\"BM25 기반 검색 (임베딩 불필요)\"\"\"\n",
    "        query_words = re.findall(r'[가-힣]+|[a-zA-Z]+|\\\\d+', query.lower())\n",
    "        \n",
    "        # BM25 점수 계산\n",
    "        scores = defaultdict(float)\n",
    "        for word in query_words:\n",
    "            if word in self.chunk_index:\n",
    "                for idx in self.chunk_index[word]:\n",
    "                    scores[idx] += 1.0\n",
    "        \n",
    "        # 상위 k개 선택\n",
    "        top_indices = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        \n",
    "        # 컨텍스트 생성\n",
    "        contexts = []\n",
    "        for idx, _ in top_indices:\n",
    "            chunk = self.chunks[idx]\n",
    "            context = f\"[출처: {chunk.get('source', 'Unknown')}]\\\\n{chunk['content']}\"\n",
    "            contexts.append(context)\n",
    "        \n",
    "        return \"\\\\n\\\\n---\\\\n\\\\n\".join(contexts)\n",
    "'''\n",
    "\n",
    "# 파일 저장\n",
    "rag_module_path = PROJECT_ROOT / \"rag_module.py\"\n",
    "with open(rag_module_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(rag_module_content)\n",
    "\n",
    "print(\"✅ RAG 모듈 저장 완료!\")\n",
    "print(f\"저장 위치: {rag_module_path}\")\n",
    "print(\"\\n이 파일을 추론 노트북에서 import하여 사용할 수 있습니다:\")\n",
    "print(\"  from rag_module import LightweightRAG\")\n",
    "print(\"  rag = LightweightRAG('data/vectordb/rag_index.pkl')\")\n",
    "print(\"  context = rag.search('검색어')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🔥 Stage 2: 데이터 생성 및 품질 관리\n\n### 11. 품질 평가 시스템\n\nFSKU 평가 기준에 맞춘 다차원 품질 평가 시스템을 구현합니다."
  },
  {
   "cell_type": "code",
   "source": "class QualityEvaluator:\n    \"\"\"\n    FSKU 기준에 맞춘 품질 평가 시스템\n    \n    평가 차원:\n    1. 형식 (Format): 문제 구조, 선택지 형식\n    2. 내용 (Content): 금융 관련성, 정확성\n    3. 난이도 (Difficulty): 적절한 난이도\n    4. 명확성 (Clarity): 모호하지 않은 표현\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"평가 시스템 초기화\"\"\"\n        # 평가 가중치 설정\n        self.weights = {\n            'format': 0.25,      # 형식 적절성\n            'content': 0.35,     # 내용 품질\n            'difficulty': 0.20,  # 난이도 적절성\n            'clarity': 0.20      # 명확성\n        }\n        \n        # 통계 정보\n        self.evaluation_stats = {\n            'total_evaluated': 0,\n            'passed': 0,\n            'failed': 0,\n            'avg_score': 0,\n            'score_distribution': defaultdict(int)\n        }\n        \n        # 금융 키워드 (기존 품질 평가 모듈에서 가져옴)\n        self.finance_keywords = [\n            '금융', '은행', '증권', '보험', '예금', '대출', '투자',\n            '전자금융', '핀테크', '블록체인', '암호화폐', '디지털자산',\n            '신용', '리스크', '규제', '감독', '준법', '개인정보',\n            'KYC', 'AML', '자금세탁', '보안', '인증', '본인확인'\n        ]\n        \n        # 모호한 표현들\n        self.ambiguous_terms = [\n            '대략', '아마', '어느정도', '일부', '몇몇', '약간',\n            '가능한', '일반적으로', '보통', '대체로', '종종'\n        ]\n        \n        # FSKU 문제 유형 패턴\n        self.question_patterns = {\n            '객관식': {\n                'markers': ['다음 중', '올바른 것은', '맞는 것은', '틀린 것은', '해당하는 것은'],\n                'options': [r'[1-5]\\)', r'[가-마]\\)', r'[A-E]\\)', r'①②③④⑤']\n            },\n            '주관식': {\n                'markers': ['설명하시오', '서술하시오', '무엇인가', '정의하시오', '비교하시오'],\n                'requirements': ['이유', '근거', '예시', '특징']\n            },\n            '계산': {\n                'markers': ['계산하시오', '산출하시오', '구하시오', '값은'],\n                'units': ['%', '원', '달러', '배', '비율']\n            }\n        }\n    \n    def evaluate(self, question: str, answer: str) -> Dict[str, Any]:\n        \"\"\"\n        문제-답변 쌍 평가\n        \n        Args:\n            question: 생성된 문제\n            answer: 생성된 답변\n            \n        Returns:\n            평가 결과 딕셔너리\n        \"\"\"\n        # 각 차원별 평가\n        scores = {\n            'format': self._evaluate_format(question, answer),\n            'content': self._evaluate_content(question, answer),\n            'difficulty': self._evaluate_difficulty(question, answer),\n            'clarity': self._evaluate_clarity(question, answer)\n        }\n        \n        # 가중 평균 계산\n        total_score = sum(\n            scores[dim] * self.weights[dim] \n            for dim in scores\n        )\n        \n        # 문제 유형 판별\n        question_type = self._identify_question_type(question)\n        \n        # 세부 분석\n        analysis = {\n            'question_type': question_type,\n            'has_options': self._has_options(question),\n            'keyword_count': self._count_keywords(question + answer),\n            'length': len(question) + len(answer),\n            'ambiguity_count': self._count_ambiguous_terms(question + answer)\n        }\n        \n        # 통계 업데이트\n        self._update_stats(total_score)\n        \n        # 결과 반환\n        return {\n            'total_score': round(total_score, 1),\n            'dimension_scores': scores,\n            'passed': total_score >= 70,\n            'analysis': analysis,\n            'feedback': self._generate_feedback(scores, analysis)\n        }\n    \n    def _evaluate_format(self, question: str, answer: str) -> float:\n        \"\"\"\n        형식 평가\n        - 문제 구조의 적절성\n        - 선택지 형식 (객관식의 경우)\n        - 질문 명확성\n        \"\"\"\n        score = 50  # 기본 점수\n        \n        # 질문 마크 확인\n        if '?' in question or any(end in question for end in ['는가', '까', '인가']):\n            score += 10\n        \n        # 문제 유형별 형식 체크\n        question_type = self._identify_question_type(question)\n        \n        if question_type == '객관식':\n            # 선택지 체크\n            if self._has_proper_options(question):\n                score += 20\n            # 선택지 개수 체크 (4-5개가 이상적)\n            option_count = self._count_options(question)\n            if 4 <= option_count <= 5:\n                score += 10\n        elif question_type == '주관식':\n            # 명확한 지시사항 체크\n            if any(marker in question for marker in self.question_patterns['주관식']['markers']):\n                score += 20\n        elif question_type == '계산':\n            # 단위 명시 체크\n            if any(unit in question or unit in answer for unit in self.question_patterns['계산']['units']):\n                score += 15\n        \n        # 구조화 체크 (줄바꿈 사용)\n        if '\\n' in question and question.count('\\n') >= 2:\n            score += 10\n        \n        return min(100, score)\n    \n    def _evaluate_content(self, question: str, answer: str) -> float:\n        \"\"\"\n        내용 평가\n        - 금융 관련성\n        - 정확성 (답변의 적절성)\n        - 전문성\n        \"\"\"\n        score = 40  # 기본 점수\n        text = question + ' ' + answer\n        \n        # 금융 키워드 포함도\n        keyword_count = self._count_keywords(text)\n        if keyword_count >= 3:\n            score += 30\n        elif keyword_count >= 2:\n            score += 20\n        elif keyword_count >= 1:\n            score += 10\n        \n        # 전문 용어 사용 (영문 약어 등)\n        professional_terms = re.findall(r'[A-Z]{2,}', text)\n        if professional_terms:\n            score += 10\n        \n        # 구체적인 예시나 규정 언급\n        if any(pattern in text for pattern in ['제\\d+조', '제\\d+항', '예를 들어', '예시']):\n            score += 10\n        \n        # 답변의 구체성 (주관식)\n        if self._identify_question_type(question) == '주관식':\n            if len(answer) > 100:  # 충분한 설명\n                score += 10\n        \n        return min(100, score)\n    \n    def _evaluate_difficulty(self, question: str, answer: str) -> float:\n        \"\"\"\n        난이도 평가\n        - 너무 쉽거나 어렵지 않은 적절한 수준\n        - FSKU 시험 수준에 맞는지\n        \"\"\"\n        score = 70  # 기본 점수 (중간 난이도)\n        \n        # 문제 길이로 복잡도 추정\n        question_length = len(question)\n        if 100 <= question_length <= 300:\n            score += 10\n        elif question_length < 50:\n            score -= 20  # 너무 단순\n        elif question_length > 500:\n            score -= 10  # 너무 복잡\n        \n        # 전문 용어 수로 난이도 추정\n        keyword_count = self._count_keywords(question + answer)\n        if 2 <= keyword_count <= 4:\n            score += 10\n        elif keyword_count > 6:\n            score -= 10  # 너무 전문적\n        \n        # 계산 문제의 경우\n        if self._identify_question_type(question) == '계산':\n            # 숫자의 복잡도 체크\n            numbers = re.findall(r'\\d+', question)\n            if numbers and all(int(n) < 10000 for n in numbers if n.isdigit()):\n                score += 10  # 적절한 숫자 범위\n        \n        return max(0, min(100, score))\n    \n    def _evaluate_clarity(self, question: str, answer: str) -> float:\n        \"\"\"\n        명확성 평가\n        - 모호한 표현 없음\n        - 이해하기 쉬운 문장\n        - 일관된 용어 사용\n        \"\"\"\n        score = 100  # 시작 점수\n        text = question + ' ' + answer\n        \n        # 모호한 표현 체크\n        ambiguity_count = self._count_ambiguous_terms(text)\n        score -= ambiguity_count * 10\n        \n        # 이중 부정 체크\n        if any(pattern in text for pattern in ['않지 않', '없지 않', '못하지 않']):\n            score -= 20\n        \n        # 너무 많은 조건문\n        condition_count = text.count('만약') + text.count('경우') + text.count('때')\n        if condition_count > 3:\n            score -= 15\n        \n        # 문장 길이 체크 (너무 긴 문장은 이해하기 어려움)\n        sentences = text.split('.')\n        long_sentences = [s for s in sentences if len(s.strip()) > 150]\n        if long_sentences:\n            score -= len(long_sentences) * 5\n        \n        # 일관된 어미 사용 체크\n        if question.endswith('시오.') or question.endswith('하라.'):\n            score += 5  # 일관된 명령형\n        \n        return max(0, score)\n    \n    def _identify_question_type(self, question: str) -> str:\n        \"\"\"문제 유형 판별\"\"\"\n        # 객관식 체크\n        for marker in self.question_patterns['객관식']['markers']:\n            if marker in question:\n                return '객관식'\n        for option_pattern in self.question_patterns['객관식']['options']:\n            if re.search(option_pattern, question):\n                return '객관식'\n        \n        # 계산 문제 체크\n        for marker in self.question_patterns['계산']['markers']:\n            if marker in question:\n                return '계산'\n        \n        # 나머지는 주관식\n        return '주관식'\n    \n    def _has_options(self, question: str) -> bool:\n        \"\"\"선택지 존재 여부 확인\"\"\"\n        for pattern in self.question_patterns['객관식']['options']:\n            if re.search(pattern, question):\n                return True\n        return False\n    \n    def _has_proper_options(self, question: str) -> bool:\n        \"\"\"적절한 형식의 선택지 확인\"\"\"\n        # 일관된 선택지 형식 체크\n        option_formats = []\n        for pattern in self.question_patterns['객관식']['options']:\n            if re.findall(pattern, question):\n                option_formats.append(pattern)\n        \n        # 하나의 일관된 형식만 사용하는지 체크\n        return len(option_formats) == 1\n    \n    def _count_options(self, question: str) -> int:\n        \"\"\"선택지 개수 세기\"\"\"\n        max_count = 0\n        for pattern in self.question_patterns['객관식']['options']:\n            matches = re.findall(pattern, question)\n            max_count = max(max_count, len(matches))\n        return max_count\n    \n    def _count_keywords(self, text: str) -> int:\n        \"\"\"금융 키워드 개수 세기\"\"\"\n        count = 0\n        text_lower = text.lower()\n        for keyword in self.finance_keywords:\n            if keyword.lower() in text_lower:\n                count += 1\n        return count\n    \n    def _count_ambiguous_terms(self, text: str) -> int:\n        \"\"\"모호한 표현 개수 세기\"\"\"\n        count = 0\n        for term in self.ambiguous_terms:\n            count += text.count(term)\n        return count\n    \n    def _generate_feedback(self, scores: Dict, analysis: Dict) -> List[str]:\n        \"\"\"개선 피드백 생성\"\"\"\n        feedback = []\n        \n        # 점수가 낮은 차원에 대한 피드백\n        for dim, score in scores.items():\n            if score < 70:\n                if dim == 'format':\n                    feedback.append(\"📝 형식 개선: 명확한 질문 구조와 일관된 선택지 형식을 사용하세요.\")\n                elif dim == 'content':\n                    feedback.append(\"📚 내용 강화: 더 많은 금융 전문 용어와 구체적인 예시를 포함하세요.\")\n                elif dim == 'difficulty':\n                    feedback.append(\"🎯 난이도 조정: FSKU 시험 수준에 맞는 적절한 난이도로 조정하세요.\")\n                elif dim == 'clarity':\n                    feedback.append(\"✨ 명확성 향상: 모호한 표현을 제거하고 간결한 문장을 사용하세요.\")\n        \n        # 추가 분석 기반 피드백\n        if analysis['ambiguity_count'] > 2:\n            feedback.append(\"⚠️ 모호한 표현이 많습니다. 구체적이고 명확한 표현으로 수정하세요.\")\n        \n        if analysis['length'] < 100:\n            feedback.append(\"📏 문제가 너무 짧습니다. 더 구체적인 상황 설명을 추가하세요.\")\n        \n        if analysis['keyword_count'] < 2:\n            feedback.append(\"🏦 금융 관련 키워드가 부족합니다. 전문 용어를 더 포함하세요.\")\n        \n        return feedback\n    \n    def _update_stats(self, score: float):\n        \"\"\"통계 정보 업데이트\"\"\"\n        self.evaluation_stats['total_evaluated'] += 1\n        \n        if score >= 70:\n            self.evaluation_stats['passed'] += 1\n        else:\n            self.evaluation_stats['failed'] += 1\n        \n        # 평균 점수 업데이트\n        n = self.evaluation_stats['total_evaluated']\n        prev_avg = self.evaluation_stats['avg_score']\n        self.evaluation_stats['avg_score'] = (prev_avg * (n-1) + score) / n\n        \n        # 점수 분포 업데이트\n        score_range = int(score // 10) * 10  # 10점 단위\n        self.evaluation_stats['score_distribution'][score_range] += 1\n    \n    def get_statistics(self) -> Dict:\n        \"\"\"평가 통계 반환\"\"\"\n        return self.evaluation_stats.copy()\n    \n    def reset_statistics(self):\n        \"\"\"통계 초기화\"\"\"\n        self.evaluation_stats = {\n            'total_evaluated': 0,\n            'passed': 0,\n            'failed': 0,\n            'avg_score': 0,\n            'score_distribution': defaultdict(int)\n        }\n\n\n# 품질 평가 시스템 테스트\nprint(\"✅ 품질 평가 시스템 생성 완료\")\nevaluator = QualityEvaluator()\n\n# 테스트 예제\ntest_question = \"\"\"\n다음 중 전자금융거래법상 금융회사가 준수해야 할 사항으로 틀린 것은?\n\n1) 전자금융거래 시 본인확인 절차를 거쳐야 한다.\n2) 고객의 개인정보를 암호화하여 보관해야 한다.\n3) 전자금융사고 발생 시 24시간 이내에 신고해야 한다.\n4) 고객의 동의 없이 제3자에게 정보를 제공할 수 있다.\n5) 정기적으로 보안 취약점 점검을 실시해야 한다.\n\"\"\"\n\ntest_answer = \"정답: 4번. 고객의 동의 없이 제3자에게 정보를 제공하는 것은 개인정보보호법 위반입니다.\"\n\n# 평가 실행\nresult = evaluator.evaluate(test_question, test_answer)\n\nprint(\"\\n📊 평가 결과:\")\nprint(f\"총점: {result['total_score']}점\")\nprint(f\"통과 여부: {'✅ 통과' if result['passed'] else '❌ 미통과'}\")\nprint(f\"\\n차원별 점수:\")\nfor dim, score in result['dimension_scores'].items():\n    print(f\"  - {dim}: {score}점\")\nprint(f\"\\n분석:\")\nprint(f\"  - 문제 유형: {result['analysis']['question_type']}\")\nprint(f\"  - 금융 키워드 수: {result['analysis']['keyword_count']}개\")\nprint(f\"\\n피드백:\")\nfor feedback in result['feedback']:\n    print(f\"  {feedback}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 12. 체이닝 데이터 생성기\n\nChain-of-Thought를 활용한 고품질 데이터 생성 시스템",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class ChainingDataGenerator:\n    \"\"\"\n    Chain-of-Thought를 활용한 체이닝 데이터 생성기\n    \n    생성 프로세스:\n    1. 초기 생성 (Initial Generation)\n    2. 자가 검증 (Self-Verification)\n    3. 개선 생성 (Improvement)\n    4. 최종 검증 (Final Check)\n    \"\"\"\n    \n    def __init__(self, model_name: str = \"beomi/llama-2-ko-7b\"):\n        \"\"\"\n        초기화\n        \n        Args:\n            model_name: 사용할 LLM 모델명\n        \"\"\"\n        self.model_name = model_name\n        self.model = None\n        self.tokenizer = None\n        \n        # 생성 통계\n        self.generation_stats = {\n            'total_attempts': 0,\n            'successful': 0,\n            'failed': 0,\n            'improvement_rate': 0,\n            'avg_iterations': 0\n        }\n        \n        # 프롬프트 템플릿\n        self.prompts = self._load_prompt_templates()\n        \n        # 품질 평가기\n        self.evaluator = QualityEvaluator()\n        \n        # 캐시 (동일한 컨텍스트에 대한 중복 생성 방지)\n        self.generation_cache = {}\n    \n    def initialize_model(self, use_quantization: bool = True):\n        \"\"\"\n        모델 초기화\n        \n        Args:\n            use_quantization: 4bit 양자화 사용 여부\n        \"\"\"\n        print(f\"🤖 모델 로드 중: {self.model_name}\")\n        \n        try:\n            # 토크나이저 로드\n            self.tokenizer = AutoTokenizer.from_pretrained(\n                self.model_name,\n                trust_remote_code=True\n            )\n            \n            # 패딩 토큰 설정\n            if self.tokenizer.pad_token is None:\n                self.tokenizer.pad_token = self.tokenizer.eos_token\n            \n            # 모델 설정\n            if use_quantization:\n                # 4bit 양자화 설정\n                bnb_config = BitsAndBytesConfig(\n                    load_in_4bit=True,\n                    bnb_4bit_quant_type=\"nf4\",\n                    bnb_4bit_compute_dtype=torch.float16,\n                    bnb_4bit_use_double_quant=True\n                )\n                \n                self.model = AutoModelForCausalLM.from_pretrained(\n                    self.model_name,\n                    quantization_config=bnb_config,\n                    device_map=\"auto\",\n                    trust_remote_code=True,\n                    torch_dtype=torch.float16\n                )\n            else:\n                # 일반 로드\n                self.model = AutoModelForCausalLM.from_pretrained(\n                    self.model_name,\n                    device_map=\"auto\",\n                    trust_remote_code=True,\n                    torch_dtype=torch.float16\n                )\n            \n            print(\"✅ 모델 로드 완료!\")\n            \n            # 메모리 사용량 출력\n            if torch.cuda.is_available():\n                memory_used = torch.cuda.memory_allocated() / 1024**3\n                print(f\"💾 GPU 메모리 사용량: {memory_used:.2f}GB\")\n                \n        except Exception as e:\n            logger.error(f\"모델 로드 실패: {e}\")\n            raise\n    \n    def _load_prompt_templates(self) -> Dict[str, str]:\n        \"\"\"프롬프트 템플릿 로드\"\"\"\n        templates = {\n            'initial_generation': \"\"\"당신은 한국 금융감독원의 FSKU(금융전문지식자격시험) 출제위원입니다.\n다음 금융 문서를 참고하여 FSKU 시험에 출제될 수 있는 고품질 문제를 생성하세요.\n\n### 참고 문서:\n{context}\n\n### 생성 지침:\n1. 문제 유형: {question_type}\n2. 난이도: 중상 (FSKU 실제 시험 수준)\n3. 금융 전문 용어를 정확히 사용하세요\n4. 실무에서 중요한 내용을 다루세요\n5. 명확하고 모호하지 않은 표현을 사용하세요\n\n### 생성할 문제:\n\"\"\",\n            \n            'self_verification': \"\"\"다음 생성된 문제를 검토하고 문제점을 찾아주세요.\n\n### 생성된 문제:\n{question}\n\n### 생성된 답변:\n{answer}\n\n### 검토 기준:\n1. 문제가 명확하고 이해하기 쉬운가?\n2. 금융 전문 용어가 정확히 사용되었는가?\n3. 답변이 정확하고 충분한 설명을 포함하는가?\n4. FSKU 시험 수준에 적합한가?\n5. 모호하거나 논란의 여지가 있는 부분은 없는가?\n\n### 문제점 분석:\n\"\"\",\n            \n            'improvement': \"\"\"다음 문제와 피드백을 바탕으로 개선된 버전을 생성하세요.\n\n### 원본 문제:\n{question}\n\n### 원본 답변:\n{answer}\n\n### 피드백:\n{feedback}\n\n### 개선 지침:\n1. 지적된 문제점을 모두 수정하세요\n2. 더 명확하고 전문적인 표현을 사용하세요\n3. 필요시 구체적인 예시나 규정을 추가하세요\n4. 답변의 설명을 더 충실하게 작성하세요\n\n### 개선된 문제:\n\"\"\",\n            \n            'final_check': \"\"\"최종 생성된 문제를 검토하고 FSKU 시험 출제 가능 여부를 판단하세요.\n\n### 최종 문제:\n{question}\n\n### 최종 답변:\n{answer}\n\n### 평가 항목:\n1. FSKU 출제 가능성 (적합/부적합)\n2. 전반적인 품질 (1-10점)\n3. 개선이 필요한 부분 (있다면)\n4. 최종 의견\n\n### 평가 결과:\n\"\"\"\n        }\n        \n        return templates\n    \n    def generate_qa_pair(self, \n                        context: str, \n                        question_type: str = \"객관식\",\n                        max_iterations: int = 3) -> Optional[Dict]:\n        \"\"\"\n        체이닝을 통한 QA 쌍 생성\n        \n        Args:\n            context: RAG에서 가져온 컨텍스트\n            question_type: 문제 유형 (객관식/주관식/계산)\n            max_iterations: 최대 개선 반복 횟수\n            \n        Returns:\n            생성된 QA 쌍 또는 None\n        \"\"\"\n        # 캐시 확인\n        cache_key = hash(context[:200] + question_type)\n        if cache_key in self.generation_cache:\n            logger.info(\"캐시에서 결과 반환\")\n            return self.generation_cache[cache_key]\n        \n        self.generation_stats['total_attempts'] += 1\n        \n        try:\n            # 1단계: 초기 생성\n            print(\"🔄 [1/4] 초기 문제 생성 중...\")\n            initial_qa = self._initial_generation(context, question_type)\n            if not initial_qa:\n                raise ValueError(\"초기 생성 실패\")\n            \n            current_question = initial_qa['question']\n            current_answer = initial_qa['answer']\n            \n            # 2단계: 반복적 개선\n            iteration_count = 0\n            for i in range(max_iterations):\n                iteration_count += 1\n                print(f\"🔄 [{2+i*2}/4] 자가 검증 중...\")\n                \n                # 자가 검증\n                verification = self._self_verification(current_question, current_answer)\n                \n                # 문제점이 없으면 종료\n                if \"문제없음\" in verification or \"적합\" in verification:\n                    break\n                \n                # 개선\n                print(f\"🔄 [{3+i*2}/4] 개선 생성 중...\")\n                improved_qa = self._improvement_generation(\n                    current_question, \n                    current_answer, \n                    verification\n                )\n                \n                if improved_qa:\n                    current_question = improved_qa['question']\n                    current_answer = improved_qa['answer']\n            \n            # 3단계: 최종 검증\n            print(\"🔄 [4/4] 최종 검증 중...\")\n            final_check = self._final_check(current_question, current_answer)\n            \n            # 4단계: 품질 평가\n            evaluation = self.evaluator.evaluate(current_question, current_answer)\n            \n            # 결과 준비\n            result = {\n                'question': current_question,\n                'answer': current_answer,\n                'context': context,\n                'question_type': question_type,\n                'quality_score': evaluation['total_score'],\n                'passed': evaluation['passed'],\n                'iterations': iteration_count,\n                'final_check': final_check,\n                'metadata': {\n                    'timestamp': datetime.now().isoformat(),\n                    'model': self.model_name,\n                    'dimension_scores': evaluation['dimension_scores']\n                }\n            }\n            \n            # 통과한 경우만 캐시에 저장\n            if result['passed']:\n                self.generation_cache[cache_key] = result\n                self.generation_stats['successful'] += 1\n            else:\n                self.generation_stats['failed'] += 1\n            \n            # 통계 업데이트\n            self._update_stats(iteration_count, result['passed'])\n            \n            return result\n            \n        except Exception as e:\n            logger.error(f\"생성 중 오류 발생: {e}\")\n            self.generation_stats['failed'] += 1\n            return None\n    \n    def _generate_text(self, prompt: str, max_length: int = 512) -> str:\n        \"\"\"\n        LLM을 사용한 텍스트 생성\n        \n        Args:\n            prompt: 입력 프롬프트\n            max_length: 최대 생성 길이\n            \n        Returns:\n            생성된 텍스트\n        \"\"\"\n        if not self.model or not self.tokenizer:\n            raise ValueError(\"모델이 초기화되지 않았습니다.\")\n        \n        # 입력 토큰화\n        inputs = self.tokenizer(\n            prompt, \n            return_tensors=\"pt\",\n            truncation=True,\n            max_length=2048\n        ).to(self.model.device)\n        \n        # 생성\n        with torch.no_grad():\n            outputs = self.model.generate(\n                **inputs,\n                max_new_tokens=max_length,\n                temperature=0.7,\n                top_p=0.9,\n                do_sample=True,\n                pad_token_id=self.tokenizer.pad_token_id,\n                eos_token_id=self.tokenizer.eos_token_id\n            )\n        \n        # 디코딩\n        generated_text = self.tokenizer.decode(\n            outputs[0][inputs['input_ids'].shape[1]:], \n            skip_special_tokens=True\n        )\n        \n        return generated_text.strip()\n    \n    def _initial_generation(self, context: str, question_type: str) -> Optional[Dict]:\n        \"\"\"초기 문제 생성\"\"\"\n        prompt = self.prompts['initial_generation'].format(\n            context=context,\n            question_type=question_type\n        )\n        \n        generated = self._generate_text(prompt)\n        \n        # 문제와 답변 분리\n        qa_pair = self._parse_qa(generated)\n        return qa_pair\n    \n    def _self_verification(self, question: str, answer: str) -> str:\n        \"\"\"자가 검증\"\"\"\n        prompt = self.prompts['self_verification'].format(\n            question=question,\n            answer=answer\n        )\n        \n        verification = self._generate_text(prompt, max_length=256)\n        return verification\n    \n    def _improvement_generation(self, question: str, answer: str, feedback: str) -> Optional[Dict]:\n        \"\"\"개선된 버전 생성\"\"\"\n        prompt = self.prompts['improvement'].format(\n            question=question,\n            answer=answer,\n            feedback=feedback\n        )\n        \n        generated = self._generate_text(prompt)\n        qa_pair = self._parse_qa(generated)\n        return qa_pair\n    \n    def _final_check(self, question: str, answer: str) -> str:\n        \"\"\"최종 검증\"\"\"\n        prompt = self.prompts['final_check'].format(\n            question=question,\n            answer=answer\n        )\n        \n        check_result = self._generate_text(prompt, max_length=256)\n        return check_result\n    \n    def _parse_qa(self, text: str) -> Optional[Dict]:\n        \"\"\"\n        생성된 텍스트에서 문제와 답변 추출\n        \"\"\"\n        try:\n            # 다양한 구분자로 시도\n            separators = ['정답:', '답:', '답변:', 'Answer:', 'A:']\n            \n            question = \"\"\n            answer = \"\"\n            \n            for sep in separators:\n                if sep in text:\n                    parts = text.split(sep, 1)\n                    question = parts[0].strip()\n                    answer = parts[1].strip() if len(parts) > 1 else \"\"\n                    break\n            \n            # 구분자가 없는 경우 휴리스틱 사용\n            if not answer:\n                lines = text.strip().split('\\n')\n                # 마지막 단락을 답변으로 간주\n                if len(lines) > 1:\n                    question = '\\n'.join(lines[:-1])\n                    answer = lines[-1]\n                else:\n                    question = text\n                    answer = \"답변 생성 필요\"\n            \n            return {\n                'question': question,\n                'answer': answer\n            }\n            \n        except Exception as e:\n            logger.error(f\"QA 파싱 오류: {e}\")\n            return None\n    \n    def _update_stats(self, iterations: int, passed: bool):\n        \"\"\"통계 업데이트\"\"\"\n        n = self.generation_stats['successful'] + self.generation_stats['failed']\n        \n        # 평균 반복 횟수 업데이트\n        prev_avg = self.generation_stats['avg_iterations']\n        self.generation_stats['avg_iterations'] = (prev_avg * (n-1) + iterations) / n\n        \n        # 개선율 계산\n        if iterations > 1 and passed:\n            improvement_count = self.generation_stats.get('improvements', 0) + 1\n            self.generation_stats['improvements'] = improvement_count\n            self.generation_stats['improvement_rate'] = improvement_count / self.generation_stats['successful']\n    \n    def get_statistics(self) -> Dict:\n        \"\"\"생성 통계 반환\"\"\"\n        return self.generation_stats.copy()\n    \n    def batch_generate(self, \n                      contexts: List[str], \n                      question_types: List[str] = None,\n                      batch_size: int = 4) -> List[Dict]:\n        \"\"\"\n        배치 생성\n        \n        Args:\n            contexts: 컨텍스트 리스트\n            question_types: 문제 유형 리스트\n            batch_size: 배치 크기\n            \n        Returns:\n            생성된 QA 리스트\n        \"\"\"\n        if question_types is None:\n            # 기본값: 객관식 60%, 주관식 30%, 계산 10%\n            question_types = []\n            for _ in range(len(contexts)):\n                rand = random.random()\n                if rand < 0.6:\n                    question_types.append(\"객관식\")\n                elif rand < 0.9:\n                    question_types.append(\"주관식\")\n                else:\n                    question_types.append(\"계산\")\n        \n        results = []\n        \n        # 배치 처리\n        for i in tqdm(range(0, len(contexts), batch_size), desc=\"배치 생성\"):\n            batch_contexts = contexts[i:i+batch_size]\n            batch_types = question_types[i:i+batch_size]\n            \n            # 각 컨텍스트에 대해 생성\n            for ctx, qtype in zip(batch_contexts, batch_types):\n                result = self.generate_qa_pair(ctx, qtype)\n                if result:\n                    results.append(result)\n        \n        return results\n\n\n# 체이닝 생성기 테스트\nprint(\"✅ 체이닝 데이터 생성기 생성 완료\")\nprint(\"\\n특징:\")\nprint(\"- 4단계 체이닝: 생성 → 검증 → 개선 → 최종확인\")\nprint(\"- 자동 품질 평가 및 필터링\")\nprint(\"- 캐싱으로 중복 생성 방지\")\nprint(\"- 배치 처리 지원\")\n\n# 사용 예시 출력\nprint(\"\\n사용 예시:\")\nprint(\"generator = ChainingDataGenerator('beomi/llama-2-ko-7b')\")\nprint(\"generator.initialize_model(use_quantization=True)\")\nprint(\"result = generator.generate_qa_pair(context, '객관식')\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 13. 프롬프트 템플릿 관리\n\n다양한 문제 유형별 프롬프트 템플릿 관리 시스템",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class PromptTemplateManager:\n    \"\"\"\n    문제 유형별 프롬프트 템플릿 관리\n    \n    FSKU 시험의 다양한 문제 유형에 맞춘\n    전문적인 프롬프트 템플릿 제공\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"템플릿 초기화\"\"\"\n        self.templates = self._initialize_templates()\n        self.usage_stats = defaultdict(int)\n    \n    def _initialize_templates(self) -> Dict[str, Dict[str, str]]:\n        \"\"\"모든 템플릿 초기화\"\"\"\n        templates = {\n            # 객관식 템플릿\n            '객관식_일반': {\n                'system': \"당신은 FSKU 출제위원입니다. 정확하고 명확한 객관식 문제를 생성하세요.\",\n                'user': \"\"\"다음 금융 문서를 참고하여 객관식 문제를 생성하세요.\n\n### 참고 문서:\n{context}\n\n### 요구사항:\n- 5개의 선택지 제공 (1번~5번)\n- 정답은 1개만\n- 오답은 그럴듯하지만 명확히 틀린 내용\n- 선택지는 비슷한 길이로 작성\n\n### 문제:\"\"\",\n                'examples': [\n                    {\n                        'question': \"다음 중 전자금융거래법상 금융회사의 의무사항이 아닌 것은?\",\n                        'options': [\n                            \"1) 접근매체의 위조나 변조를 방지하기 위한 조치\",\n                            \"2) 전자금융거래 내용의 확인 및 오류정정 요구 처리\",\n                            \"3) 전자금융거래 기록의 5년간 보존\",\n                            \"4) 이용자의 요청 없이도 정기적인 거래내역 통지\",\n                            \"5) 전자금융사고 발생 시 손해배상\"\n                        ],\n                        'answer': \"4번\"\n                    }\n                ]\n            },\n            \n            '객관식_부정형': {\n                'system': \"부정형 객관식 문제를 생성하세요. '~아닌 것은', '~틀린 것은' 형태로 작성합니다.\",\n                'user': \"\"\"다음 내용에서 틀리거나 해당하지 않는 것을 찾는 객관식 문제를 생성하세요.\n\n### 참고 문서:\n{context}\n\n### 요구사항:\n- \"다음 중 ~아닌 것은?\" 또는 \"~틀린 것은?\" 형태\n- 4개는 맞는 내용, 1개만 틀린 내용\n- 혼동하기 쉬운 내용으로 구성\n\n### 문제:\"\"\",\n                'examples': []\n            },\n            \n            '객관식_복수정답': {\n                'system': \"복수 정답형 객관식 문제를 생성하세요.\",\n                'user': \"\"\"다음 내용에서 모두 맞는 것을 고르는 복수정답형 문제를 생성하세요.\n\n### 참고 문서:\n{context}\n\n### 요구사항:\n- \"다음 중 모두 옳은 것은?\" 형태\n- 보기를 ㄱ, ㄴ, ㄷ, ㄹ로 제시\n- 선택지는 조합 형태 (예: 1) ㄱ, ㄴ  2) ㄴ, ㄷ ...)\n\n### 문제:\"\"\",\n                'examples': []\n            },\n            \n            # 주관식 템플릿\n            '주관식_설명형': {\n                'system': \"개념이나 제도를 설명하는 주관식 문제를 생성하세요.\",\n                'user': \"\"\"다음 내용을 바탕으로 설명형 주관식 문제를 생성하세요.\n\n### 참고 문서:\n{context}\n\n### 요구사항:\n- \"~에 대해 설명하시오\" 형태\n- 핵심 개념, 특징, 목적 등을 포함한 답변 요구\n- 200자 이상의 상세한 답변이 필요한 문제\n\n### 문제:\"\"\",\n                'examples': []\n            },\n            \n            '주관식_비교형': {\n                'system': \"두 개념을 비교하는 주관식 문제를 생성하세요.\",\n                'user': \"\"\"다음 내용에서 비교 가능한 개념들을 찾아 비교형 문제를 생성하세요.\n\n### 참고 문서:\n{context}\n\n### 요구사항:\n- \"A와 B를 비교하여 설명하시오\" 형태\n- 공통점과 차이점을 모두 다루도록\n- 표나 도식으로 정리 가능한 내용\n\n### 문제:\"\"\",\n                'examples': []\n            },\n            \n            '주관식_사례형': {\n                'system': \"실무 사례를 제시하고 해결방안을 묻는 문제를 생성하세요.\",\n                'user': \"\"\"다음 내용을 바탕으로 실무 사례형 문제를 생성하세요.\n\n### 참고 문서:\n{context}\n\n### 요구사항:\n- 구체적인 상황 제시\n- \"이 경우 어떻게 처리해야 하는가?\" 형태\n- 법적 근거와 실무적 해결방안 요구\n\n### 문제:\"\"\",\n                'examples': []\n            },\n            \n            # 계산 문제 템플릿\n            '계산_금리': {\n                'system': \"금리 계산 문제를 생성하세요.\",\n                'user': \"\"\"다음 내용을 참고하여 금리 계산 문제를 생성하세요.\n\n### 참고 문서:\n{context}\n\n### 요구사항:\n- 실제 금융상품의 금리 계산\n- 단리/복리, 연이율/월이율 변환 포함\n- 계산 과정을 단계별로 보여주는 답안\n\n### 문제:\"\"\",\n                'examples': []\n            },\n            \n            '계산_위험관리': {\n                'system': \"위험관리 지표 계산 문제를 생성하세요.\",\n                'user': \"\"\"다음 내용을 바탕으로 위험관리 관련 계산 문제를 생성하세요.\n\n### 참고 문서:\n{context}\n\n### 요구사항:\n- VaR, 자기자본비율 등 위험지표 계산\n- 공식과 계산과정 명시\n- 결과의 의미 해석 포함\n\n### 문제:\"\"\",\n                'examples': []\n            },\n            \n            # 특수 유형\n            '법규_조문': {\n                'system': \"특정 법규 조문의 내용을 묻는 문제를 생성하세요.\",\n                'user': \"\"\"다음 법규 내용을 바탕으로 조문 관련 문제를 생성하세요.\n\n### 참고 문서:\n{context}\n\n### 요구사항:\n- 특정 조항의 내용 확인\n- 빈칸 채우기 또는 내용 확인\n- 정확한 법률 용어 사용\n\n### 문제:\"\"\",\n                'examples': []\n            },\n            \n            '최신동향': {\n                'system': \"최신 금융 동향이나 제도 변경사항을 묻는 문제를 생성하세요.\",\n                'user': \"\"\"다음 최신 동향을 바탕으로 문제를 생성하세요.\n\n### 참고 문서:\n{context}\n\n### 요구사항:\n- 최근 도입된 제도나 정책\n- 변경 전후 비교\n- 시행 시기와 주요 내용\n\n### 문제:\"\"\",\n                'examples': []\n            }\n        }\n        \n        return templates\n    \n    def get_template(self, template_type: str) -> Dict[str, Any]:\n        \"\"\"\n        특정 템플릿 가져오기\n        \n        Args:\n            template_type: 템플릿 유형\n            \n        Returns:\n            템플릿 딕셔너리\n        \"\"\"\n        if template_type not in self.templates:\n            logger.warning(f\"템플릿 '{template_type}'이 존재하지 않습니다. 기본 템플릿 사용.\")\n            template_type = '객관식_일반'\n        \n        self.usage_stats[template_type] += 1\n        return self.templates[template_type]\n    \n    def get_random_template(self, category: str = None) -> Tuple[str, Dict[str, Any]]:\n        \"\"\"\n        랜덤 템플릿 선택\n        \n        Args:\n            category: 카테고리 (객관식/주관식/계산 등)\n            \n        Returns:\n            (템플릿명, 템플릿 내용)\n        \"\"\"\n        if category:\n            # 특정 카테고리에서 선택\n            filtered = [k for k in self.templates.keys() if k.startswith(category)]\n            if filtered:\n                template_name = random.choice(filtered)\n            else:\n                template_name = random.choice(list(self.templates.keys()))\n        else:\n            # 전체에서 선택\n            template_name = random.choice(list(self.templates.keys()))\n        \n        return template_name, self.get_template(template_name)\n    \n    def format_prompt(self, template_type: str, context: str, **kwargs) -> str:\n        \"\"\"\n        컨텍스트로 프롬프트 포맷팅\n        \n        Args:\n            template_type: 템플릿 유형\n            context: RAG에서 가져온 컨텍스트\n            **kwargs: 추가 변수\n            \n        Returns:\n            포맷된 프롬프트\n        \"\"\"\n        template = self.get_template(template_type)\n        \n        # system 프롬프트와 user 프롬프트 결합\n        system_prompt = template['system']\n        user_prompt = template['user'].format(context=context, **kwargs)\n        \n        # 예시가 있으면 추가\n        if template.get('examples'):\n            examples_text = \"\\n### 예시:\\n\"\n            for ex in template['examples'][:2]:  # 최대 2개 예시\n                examples_text += f\"문제: {ex['question']}\\n\"\n                if 'options' in ex:\n                    examples_text += \"\\n\".join(ex['options']) + \"\\n\"\n                examples_text += f\"답: {ex['answer']}\\n\\n\"\n            \n            full_prompt = f\"{system_prompt}\\n\\n{examples_text}{user_prompt}\"\n        else:\n            full_prompt = f\"{system_prompt}\\n\\n{user_prompt}\"\n        \n        return full_prompt\n    \n    def get_usage_statistics(self) -> Dict[str, int]:\n        \"\"\"\n        템플릿 사용 통계 반환\n        \"\"\"\n        return dict(self.usage_stats)\n    \n    def recommend_template(self, context: str) -> str:\n        \"\"\"\n        컨텍스트 분석 후 적절한 템플릿 추천\n        \n        Args:\n            context: 문서 컨텍스트\n            \n        Returns:\n            추천 템플릿명\n        \"\"\"\n        context_lower = context.lower()\n        \n        # 키워드 기반 추천\n        if any(word in context_lower for word in ['계산', '산출', '공식', '%', '이자']):\n            return random.choice(['계산_금리', '계산_위험관리'])\n        \n        elif any(word in context_lower for word in ['제\\d+조', '법', '규정', '시행령']):\n            return '법규_조문'\n        \n        elif any(word in context_lower for word in ['최근', '개정', '도입', '변경']):\n            return '최신동향'\n        \n        elif any(word in context_lower for word in ['비교', '차이', '공통점']):\n            return '주관식_비교형'\n        \n        elif any(word in context_lower for word in ['사례', '경우', '상황']):\n            return '주관식_사례형'\n        \n        else:\n            # 기본값: 객관식 60%, 주관식 30%, 기타 10%\n            rand = random.random()\n            if rand < 0.6:\n                return random.choice(['객관식_일반', '객관식_부정형', '객관식_복수정답'])\n            elif rand < 0.9:\n                return random.choice(['주관식_설명형', '주관식_비교형', '주관식_사례형'])\n            else:\n                return random.choice(['계산_금리', '계산_위험관리'])\n    \n    def add_custom_template(self, name: str, template: Dict[str, Any]):\n        \"\"\"\n        사용자 정의 템플릿 추가\n        \n        Args:\n            name: 템플릿 이름\n            template: 템플릿 내용\n        \"\"\"\n        if name in self.templates:\n            logger.warning(f\"템플릿 '{name}'이 이미 존재합니다. 덮어씁니다.\")\n        \n        # 필수 키 확인\n        required_keys = ['system', 'user']\n        for key in required_keys:\n            if key not in template:\n                raise ValueError(f\"템플릿에 필수 키 '{key}'가 없습니다.\")\n        \n        self.templates[name] = template\n        logger.info(f\"템플릿 '{name}' 추가됨\")\n    \n    def export_templates(self, file_path: str):\n        \"\"\"\n        템플릿을 파일로 내보내기\n        \n        Args:\n            file_path: 저장할 파일 경로\n        \"\"\"\n        with open(file_path, 'w', encoding='utf-8') as f:\n            json.dump(self.templates, f, ensure_ascii=False, indent=2)\n        \n        logger.info(f\"템플릿이 {file_path}에 저장됨\")\n    \n    def import_templates(self, file_path: str):\n        \"\"\"\n        파일에서 템플릿 가져오기\n        \n        Args:\n            file_path: 불러올 파일 경로\n        \"\"\"\n        with open(file_path, 'r', encoding='utf-8') as f:\n            imported = json.load(f)\n        \n        self.templates.update(imported)\n        logger.info(f\"{len(imported)}개 템플릿 가져옴\")\n\n\n# 프롬프트 매니저 테스트\nprint(\"✅ 프롬프트 템플릿 매니저 생성 완료\")\nprompt_manager = PromptTemplateManager()\n\nprint(f\"\\n📝 사용 가능한 템플릿 ({len(prompt_manager.templates)}개):\")\nfor i, (name, _) in enumerate(prompt_manager.templates.items()):\n    print(f\"  {i+1}. {name}\")\n\n# 템플릿 사용 예시\nprint(\"\\n📌 템플릿 사용 예시:\")\ntest_context = \"전자금융거래법 제21조에 따르면 금융회사는...\"\ntemplate_name = prompt_manager.recommend_template(test_context)\nprint(f\"추천 템플릿: {template_name}\")\n\nformatted_prompt = prompt_manager.format_prompt(template_name, test_context)\nprint(f\"\\n포맷된 프롬프트 (첫 200자):\\n{formatted_prompt[:200]}...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 🎉 Stage 2 완료!\n\n### ✅ 완료된 작업\n1. **품질 평가 시스템** - 다차원 평가로 고품질 데이터만 선별\n2. **체이닝 데이터 생성기** - 4단계 개선 프로세스로 품질 향상\n3. **프롬프트 템플릿 관리** - 10가지 이상의 전문 템플릿 제공\n\n### 📌 다음 단계 (Stage 3)\n- **모니터링 대시보드 구현**\n- **메인 실행 함수**\n- **결과 분석 및 저장**\n\nStage 3을 계속 진행하시려면 다음 셀들을 실행하세요.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 🚀 Stage 3: 실행 및 유틸리티\n\n### 14. 실시간 모니터링 대시보드",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class GenerationMonitor:\n    \"\"\"\n    데이터 생성 과정 실시간 모니터링\n    \n    기능:\n    - 진행 상황 시각화\n    - 품질 분포 차트\n    - 실시간 통계\n    - 예상 소요 시간\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"모니터 초기화\"\"\"\n        self.start_time = None\n        self.stats = {\n            'total_target': 0,\n            'total_generated': 0,\n            'passed': 0,\n            'failed': 0,\n            'current_rate': 0,\n            'quality_scores': [],\n            'generation_times': [],\n            'question_types': defaultdict(int)\n        }\n        \n        # 시각화 설정\n        plt.style.use('seaborn-v0_8-darkgrid')\n        self.fig = None\n        self.axes = None\n    \n    def start_monitoring(self, target_count: int):\n        \"\"\"\n        모니터링 시작\n        \n        Args:\n            target_count: 목표 생성 개수\n        \"\"\"\n        self.start_time = time.time()\n        self.stats['total_target'] = target_count\n        \n        # 대시보드 초기화\n        self._initialize_dashboard()\n        \n        print(\"=\" * 60)\n        print(\"📊 데이터 생성 모니터링 시작\")\n        print(\"=\" * 60)\n        print(f\"목표: {target_count}개 문제 생성\")\n        print(f\"시작 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n        print(\"=\" * 60)\n    \n    def _initialize_dashboard(self):\n        \"\"\"대시보드 초기화\"\"\"\n        # 2x2 서브플롯 생성\n        self.fig, self.axes = plt.subplots(2, 2, figsize=(15, 10))\n        self.fig.suptitle('FSKU 데이터 생성 모니터링 대시보드', fontsize=16)\n        \n        # 레이아웃 조정\n        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    \n    def update(self, result: Dict):\n        \"\"\"\n        생성 결과로 통계 업데이트\n        \n        Args:\n            result: 생성된 QA 결과\n        \"\"\"\n        # 기본 통계 업데이트\n        self.stats['total_generated'] += 1\n        \n        if result.get('passed', False):\n            self.stats['passed'] += 1\n        else:\n            self.stats['failed'] += 1\n        \n        # 품질 점수 추가\n        if 'quality_score' in result:\n            self.stats['quality_scores'].append(result['quality_score'])\n        \n        # 문제 유형 카운트\n        if 'question_type' in result:\n            self.stats['question_types'][result['question_type']] += 1\n        \n        # 생성 시간 기록\n        if hasattr(self, '_last_update_time'):\n            generation_time = time.time() - self._last_update_time\n            self.stats['generation_times'].append(generation_time)\n        self._last_update_time = time.time()\n        \n        # 성공률 계산\n        if self.stats['total_generated'] > 0:\n            self.stats['current_rate'] = self.stats['passed'] / self.stats['total_generated']\n        \n        # 주기적으로 대시보드 업데이트 (10개마다)\n        if self.stats['total_generated'] % 10 == 0:\n            self._update_dashboard()\n    \n    def _update_dashboard(self):\n        \"\"\"대시보드 업데이트\"\"\"\n        if not self.fig or not self.axes:\n            return\n        \n        # 각 서브플롯 초기화\n        for ax in self.axes.flatten():\n            ax.clear()\n        \n        # 1. 진행 상황 (왼쪽 상단)\n        ax1 = self.axes[0, 0]\n        self._plot_progress(ax1)\n        \n        # 2. 품질 점수 분포 (오른쪽 상단)\n        ax2 = self.axes[0, 1]\n        self._plot_quality_distribution(ax2)\n        \n        # 3. 문제 유형 분포 (왼쪽 하단)\n        ax3 = self.axes[1, 0]\n        self._plot_question_types(ax3)\n        \n        # 4. 시간당 생성량 (오른쪽 하단)\n        ax4 = self.axes[1, 1]\n        self._plot_generation_rate(ax4)\n        \n        # 화면 갱신\n        plt.draw()\n        plt.pause(0.01)\n    \n    def _plot_progress(self, ax):\n        \"\"\"진행 상황 플롯\"\"\"\n        # 데이터 준비\n        categories = ['생성됨', '통과', '실패']\n        values = [\n            self.stats['total_generated'],\n            self.stats['passed'],\n            self.stats['failed']\n        ]\n        \n        # 막대 그래프\n        bars = ax.bar(categories, values, color=['blue', 'green', 'red'])\n        \n        # 값 표시\n        for bar, value in zip(bars, values):\n            height = bar.get_height()\n            ax.text(bar.get_x() + bar.get_width()/2., height,\n                   f'{value}', ha='center', va='bottom')\n        \n        # 목표선 표시\n        ax.axhline(y=self.stats['total_target'], color='orange', \n                  linestyle='--', label=f\"목표: {self.stats['total_target']}\")\n        \n        ax.set_title('생성 진행 상황')\n        ax.set_ylabel('개수')\n        ax.legend()\n        \n        # 진행률 표시\n        progress = self.stats['total_generated'] / self.stats['total_target'] * 100\n        ax.text(0.5, 0.95, f'진행률: {progress:.1f}%', \n               transform=ax.transAxes, ha='center', fontsize=12, \n               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n    \n    def _plot_quality_distribution(self, ax):\n        \"\"\"품질 점수 분포\"\"\"\n        if not self.stats['quality_scores']:\n            ax.text(0.5, 0.5, '데이터 없음', transform=ax.transAxes, \n                   ha='center', va='center')\n            ax.set_title('품질 점수 분포')\n            return\n        \n        # 히스토그램\n        ax.hist(self.stats['quality_scores'], bins=20, color='skyblue', \n               edgecolor='black', alpha=0.7)\n        \n        # 평균선\n        mean_score = np.mean(self.stats['quality_scores'])\n        ax.axvline(x=mean_score, color='red', linestyle='--', \n                  label=f'평균: {mean_score:.1f}')\n        \n        # 합격선 (70점)\n        ax.axvline(x=70, color='green', linestyle='--', \n                  label='합격선: 70')\n        \n        ax.set_title('품질 점수 분포')\n        ax.set_xlabel('점수')\n        ax.set_ylabel('빈도')\n        ax.legend()\n    \n    def _plot_question_types(self, ax):\n        \"\"\"문제 유형 분포\"\"\"\n        if not self.stats['question_types']:\n            ax.text(0.5, 0.5, '데이터 없음', transform=ax.transAxes, \n                   ha='center', va='center')\n            ax.set_title('문제 유형 분포')\n            return\n        \n        # 파이 차트\n        types = list(self.stats['question_types'].keys())\n        counts = list(self.stats['question_types'].values())\n        \n        colors = plt.cm.Set3(range(len(types)))\n        wedges, texts, autotexts = ax.pie(counts, labels=types, colors=colors,\n                                          autopct='%1.1f%%', startangle=90)\n        \n        ax.set_title('문제 유형 분포')\n    \n    def _plot_generation_rate(self, ax):\n        \"\"\"생성 속도\"\"\"\n        if not self.stats['generation_times'] or not self.start_time:\n            ax.text(0.5, 0.5, '데이터 없음', transform=ax.transAxes, \n                   ha='center', va='center')\n            ax.set_title('생성 속도')\n            return\n        \n        # 시간당 생성량 계산\n        elapsed_time = time.time() - self.start_time\n        if elapsed_time > 0:\n            rate_per_hour = (self.stats['total_generated'] / elapsed_time) * 3600\n            rate_per_minute = (self.stats['total_generated'] / elapsed_time) * 60\n        else:\n            rate_per_hour = 0\n            rate_per_minute = 0\n        \n        # 예상 완료 시간\n        if rate_per_minute > 0:\n            remaining = self.stats['total_target'] - self.stats['total_generated']\n            eta_minutes = remaining / rate_per_minute\n            eta_str = f\"{int(eta_minutes)}분 {int((eta_minutes % 1) * 60)}초\"\n        else:\n            eta_str = \"계산 중...\"\n        \n        # 정보 표시\n        info_text = f\"\"\"현재 속도:\n        \n{rate_per_hour:.0f} 개/시간\n{rate_per_minute:.1f} 개/분\n\n평균 생성 시간: {np.mean(self.stats['generation_times']):.1f}초\n\n예상 완료 시간: {eta_str}\n        \"\"\"\n        \n        ax.text(0.5, 0.5, info_text, transform=ax.transAxes, \n               ha='center', va='center', fontsize=12,\n               bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n        \n        ax.set_title('생성 속도 및 예상 시간')\n        ax.axis('off')\n    \n    def print_summary(self):\n        \"\"\"최종 요약 출력\"\"\"\n        if not self.start_time:\n            return\n        \n        total_time = time.time() - self.start_time\n        \n        print(\"\\n\" + \"=\" * 60)\n        print(\"📊 데이터 생성 완료 요약\")\n        print(\"=\" * 60)\n        print(f\"총 소요 시간: {int(total_time//60)}분 {int(total_time%60)}초\")\n        print(f\"총 생성: {self.stats['total_generated']}개\")\n        print(f\"통과: {self.stats['passed']}개 ({self.stats['current_rate']*100:.1f}%)\")\n        print(f\"실패: {self.stats['failed']}개\")\n        \n        if self.stats['quality_scores']:\n            print(f\"\\n품질 점수:\")\n            print(f\"  - 평균: {np.mean(self.stats['quality_scores']):.1f}\")\n            print(f\"  - 최고: {max(self.stats['quality_scores']):.1f}\")\n            print(f\"  - 최저: {min(self.stats['quality_scores']):.1f}\")\n        \n        print(f\"\\n문제 유형별 분포:\")\n        for qtype, count in self.stats['question_types'].items():\n            percentage = count / self.stats['total_generated'] * 100\n            print(f\"  - {qtype}: {count}개 ({percentage:.1f}%)\")\n        \n        print(\"=\" * 60)\n    \n    def save_report(self, file_path: str):\n        \"\"\"\n        상세 보고서 저장\n        \n        Args:\n            file_path: 저장할 파일 경로\n        \"\"\"\n        report = {\n            'summary': {\n                'total_generated': self.stats['total_generated'],\n                'passed': self.stats['passed'],\n                'failed': self.stats['failed'],\n                'success_rate': self.stats['current_rate'],\n                'total_time_seconds': time.time() - self.start_time if self.start_time else 0\n            },\n            'quality': {\n                'scores': self.stats['quality_scores'],\n                'mean': np.mean(self.stats['quality_scores']) if self.stats['quality_scores'] else 0,\n                'std': np.std(self.stats['quality_scores']) if self.stats['quality_scores'] else 0\n            },\n            'distribution': dict(self.stats['question_types']),\n            'performance': {\n                'generation_times': self.stats['generation_times'],\n                'avg_time_per_item': np.mean(self.stats['generation_times']) if self.stats['generation_times'] else 0\n            },\n            'timestamp': datetime.now().isoformat()\n        }\n        \n        with open(file_path, 'w', encoding='utf-8') as f:\n            json.dump(report, f, ensure_ascii=False, indent=2)\n        \n        print(f\"✅ 보고서 저장됨: {file_path}\")\n    \n    def close(self):\n        \"\"\"모니터링 종료\"\"\"\n        if self.fig:\n            plt.close(self.fig)\n\n\n# 모니터링 시스템 테스트\nprint(\"✅ 실시간 모니터링 시스템 생성 완료\")\nprint(\"\\n주요 기능:\")\nprint(\"- 실시간 진행 상황 추적\")\nprint(\"- 품질 점수 분포 시각화\")\nprint(\"- 문제 유형별 통계\")\nprint(\"- 예상 완료 시간 계산\")\nprint(\"- 상세 보고서 생성\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 15. 데이터 저장 및 관리",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class DataManager:\n    \"\"\"\n    생성된 데이터 저장 및 관리\n    \n    기능:\n    - JSONL 형식으로 저장\n    - 메타데이터 관리\n    - 중복 제거\n    - 데이터 검증\n    \"\"\"\n    \n    def __init__(self, output_dir: Path):\n        \"\"\"\n        초기화\n        \n        Args:\n            output_dir: 출력 디렉토리\n        \"\"\"\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        \n        # 파일 경로 설정\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        self.data_file = self.output_dir / f\"fsku_data_{timestamp}.jsonl\"\n        self.metadata_file = self.output_dir / f\"fsku_metadata_{timestamp}.json\"\n        \n        # 데이터 버퍼\n        self.data_buffer = []\n        self.buffer_size = 100  # 100개씩 배치 저장\n        \n        # 중복 체크용\n        self.question_hashes = set()\n        \n        # 통계\n        self.save_stats = {\n            'total_saved': 0,\n            'duplicates_removed': 0,\n            'batches_written': 0\n        }\n    \n    def add_data(self, qa_data: Dict) -> bool:\n        \"\"\"\n        데이터 추가\n        \n        Args:\n            qa_data: 생성된 QA 데이터\n            \n        Returns:\n            저장 성공 여부\n        \"\"\"\n        # 필수 필드 확인\n        required_fields = ['question', 'answer', 'quality_score', 'passed']\n        if not all(field in qa_data for field in required_fields):\n            logger.warning(\"필수 필드가 누락된 데이터\")\n            return False\n        \n        # 품질 체크\n        if not qa_data.get('passed', False):\n            logger.debug(\"품질 기준 미달 데이터 스킵\")\n            return False\n        \n        # 중복 체크\n        question_hash = hash(qa_data['question'])\n        if question_hash in self.question_hashes:\n            self.save_stats['duplicates_removed'] += 1\n            logger.debug(\"중복 문제 발견, 스킵\")\n            return False\n        \n        # 저장용 포맷으로 변환\n        save_data = self._format_for_save(qa_data)\n        \n        # 버퍼에 추가\n        self.data_buffer.append(save_data)\n        self.question_hashes.add(question_hash)\n        \n        # 버퍼가 가득 차면 저장\n        if len(self.data_buffer) >= self.buffer_size:\n            self._flush_buffer()\n        \n        self.save_stats['total_saved'] += 1\n        return True\n    \n    def _format_for_save(self, qa_data: Dict) -> Dict:\n        \"\"\"\n        저장용 포맷으로 변환\n        \n        학습에 사용할 수 있는 표준 형식으로 변환\n        \"\"\"\n        # 기본 필드\n        formatted = {\n            'instruction': qa_data['question'],\n            'input': \"\",  # RAG 컨텍스트는 별도 관리\n            'output': qa_data['answer'],\n            'quality_score': qa_data['quality_score'],\n            'question_type': qa_data.get('question_type', 'unknown')\n        }\n        \n        # 메타데이터 추가\n        if 'metadata' in qa_data:\n            formatted['metadata'] = qa_data['metadata']\n        \n        # 생성 시간 추가\n        formatted['created_at'] = datetime.now().isoformat()\n        \n        return formatted\n    \n    def _flush_buffer(self):\n        \"\"\"버퍼 내용을 파일에 저장\"\"\"\n        if not self.data_buffer:\n            return\n        \n        # JSONL 형식으로 저장 (한 줄에 하나씩)\n        with open(self.data_file, 'a', encoding='utf-8') as f:\n            for data in self.data_buffer:\n                json_line = json.dumps(data, ensure_ascii=False)\n                f.write(json_line + '\\n')\n        \n        self.save_stats['batches_written'] += 1\n        logger.info(f\"배치 {self.save_stats['batches_written']} 저장 완료 ({len(self.data_buffer)}개)\")\n        \n        # 버퍼 초기화\n        self.data_buffer.clear()\n    \n    def save_metadata(self, generation_stats: Dict = None):\n        \"\"\"\n        메타데이터 저장\n        \n        Args:\n            generation_stats: 생성 통계 정보\n        \"\"\"\n        metadata = {\n            'file_info': {\n                'data_file': str(self.data_file),\n                'created_at': datetime.now().isoformat(),\n                'format': 'jsonl',\n                'encoding': 'utf-8'\n            },\n            'statistics': {\n                'total_saved': self.save_stats['total_saved'],\n                'duplicates_removed': self.save_stats['duplicates_removed'],\n                'batches_written': self.save_stats['batches_written']\n            },\n            'data_info': {\n                'fields': ['instruction', 'input', 'output', 'quality_score', 'question_type'],\n                'quality_threshold': 70\n            }\n        }\n        \n        # 생성 통계 추가\n        if generation_stats:\n            metadata['generation_stats'] = generation_stats\n        \n        # 메타데이터 저장\n        with open(self.metadata_file, 'w', encoding='utf-8') as f:\n            json.dump(metadata, f, ensure_ascii=False, indent=2)\n        \n        logger.info(f\"메타데이터 저장: {self.metadata_file}\")\n    \n    def finalize(self):\n        \"\"\"최종 저장 및 정리\"\"\"\n        # 남은 버퍼 저장\n        if self.data_buffer:\n            self._flush_buffer()\n        \n        print(\"\\n\" + \"=\" * 60)\n        print(\"💾 데이터 저장 완료\")\n        print(\"=\" * 60)\n        print(f\"저장 위치: {self.data_file}\")\n        print(f\"총 저장된 데이터: {self.save_stats['total_saved']}개\")\n        print(f\"제거된 중복: {self.save_stats['duplicates_removed']}개\")\n        print(f\"배치 수: {self.save_stats['batches_written']}개\")\n        print(\"=\" * 60)\n    \n    def validate_data(self) -> Dict:\n        \"\"\"\n        저장된 데이터 검증\n        \n        Returns:\n            검증 결과\n        \"\"\"\n        if not self.data_file.exists():\n            return {'valid': False, 'error': '데이터 파일이 없습니다'}\n        \n        validation_results = {\n            'valid': True,\n            'total_lines': 0,\n            'valid_lines': 0,\n            'invalid_lines': [],\n            'quality_distribution': defaultdict(int),\n            'type_distribution': defaultdict(int)\n        }\n        \n        with open(self.data_file, 'r', encoding='utf-8') as f:\n            for line_num, line in enumerate(f, 1):\n                validation_results['total_lines'] += 1\n                \n                try:\n                    # JSON 파싱\n                    data = json.loads(line.strip())\n                    \n                    # 필수 필드 확인\n                    required = ['instruction', 'output', 'quality_score']\n                    if all(field in data for field in required):\n                        validation_results['valid_lines'] += 1\n                        \n                        # 통계 수집\n                        score_range = int(data['quality_score'] // 10) * 10\n                        validation_results['quality_distribution'][score_range] += 1\n                        validation_results['type_distribution'][data.get('question_type', 'unknown')] += 1\n                    else:\n                        validation_results['invalid_lines'].append(line_num)\n                        \n                except json.JSONDecodeError:\n                    validation_results['invalid_lines'].append(line_num)\n                    validation_results['valid'] = False\n        \n        # 검증 결과 출력\n        print(\"\\n📋 데이터 검증 결과:\")\n        print(f\"총 라인 수: {validation_results['total_lines']}\")\n        print(f\"유효한 라인: {validation_results['valid_lines']}\")\n        print(f\"무효한 라인: {len(validation_results['invalid_lines'])}\")\n        \n        if validation_results['invalid_lines']:\n            print(f\"무효한 라인 번호: {validation_results['invalid_lines'][:10]}...\")\n        \n        return validation_results\n    \n    def export_for_training(self, output_file: str = None):\n        \"\"\"\n        학습용 형식으로 내보내기\n        \n        Args:\n            output_file: 출력 파일 경로\n        \"\"\"\n        if output_file is None:\n            output_file = self.output_dir / \"train_data.jsonl\"\n        \n        # 데이터 로드 및 변환\n        training_data = []\n        \n        with open(self.data_file, 'r', encoding='utf-8') as f:\n            for line in f:\n                data = json.loads(line.strip())\n                \n                # 학습용 형식으로 변환\n                training_format = {\n                    'text': f\"### 질문: {data['instruction']}\\n\\n### 답변: {data['output']}\"\n                }\n                \n                training_data.append(training_format)\n        \n        # 셔플\n        random.shuffle(training_data)\n        \n        # 저장\n        with open(output_file, 'w', encoding='utf-8') as f:\n            for item in training_data:\n                f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n        \n        print(f\"✅ 학습용 데이터 내보내기 완료: {output_file}\")\n        print(f\"   총 {len(training_data)}개 샘플\")\n\n\n# 데이터 매니저 테스트\nprint(\"✅ 데이터 관리 시스템 생성 완료\")\nprint(\"\\n주요 기능:\")\nprint(\"- JSONL 형식 저장 (학습 호환)\")\nprint(\"- 자동 중복 제거\")\nprint(\"- 배치 저장으로 효율성 향상\")\nprint(\"- 메타데이터 관리\")\nprint(\"- 데이터 검증 기능\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 16. 메인 실행 함수",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class FSKUDataAugmentation:\n    \"\"\"\n    FSKU 데이터 증강 통합 실행 클래스\n    \n    모든 컴포넌트를 통합하여 자동 데이터 생성\n    \"\"\"\n    \n    def __init__(self, \n                 model_name: str = \"beomi/llama-2-ko-7b\",\n                 external_dir: Path = None,\n                 output_dir: Path = None):\n        \"\"\"\n        초기화\n        \n        Args:\n            model_name: 사용할 LLM 모델\n            external_dir: 외부 문서 디렉토리\n            output_dir: 출력 디렉토리\n        \"\"\"\n        self.model_name = model_name\n        self.external_dir = external_dir or EXTERNAL_DIR\n        self.output_dir = output_dir or OUTPUT_DIR\n        \n        # 컴포넌트 초기화\n        self.rag_system = None\n        self.generator = None\n        self.prompt_manager = None\n        self.monitor = None\n        self.data_manager = None\n        \n        # 설정\n        self.config = {\n            'use_quantization': True,\n            'batch_size': 4,\n            'target_count': 1000,\n            'max_iterations': 3,\n            'quality_threshold': 70\n        }\n    \n    def initialize(self):\n        \"\"\"시스템 초기화\"\"\"\n        print(\"=\" * 60)\n        print(\"🚀 FSKU 데이터 증강 시스템 초기화\")\n        print(\"=\" * 60)\n        \n        # 1. RAG 시스템 초기화\n        print(\"\\n[1/5] RAG 시스템 초기화...\")\n        self.rag_system = RAGSystem()\n        self.rag_system.initialize(self.external_dir)\n        \n        if not self.rag_system.is_initialized:\n            raise ValueError(\"RAG 시스템 초기화 실패. 외부 문서를 확인하세요.\")\n        \n        # 2. 체이닝 생성기 초기화\n        print(\"\\n[2/5] 데이터 생성기 초기화...\")\n        self.generator = ChainingDataGenerator(self.model_name)\n        \n        # 3. 프롬프트 매니저 초기화\n        print(\"\\n[3/5] 프롬프트 매니저 초기화...\")\n        self.prompt_manager = PromptTemplateManager()\n        \n        # 4. 모니터링 시스템 초기화\n        print(\"\\n[4/5] 모니터링 시스템 초기화...\")\n        self.monitor = GenerationMonitor()\n        \n        # 5. 데이터 매니저 초기화\n        print(\"\\n[5/5] 데이터 매니저 초기화...\")\n        self.data_manager = DataManager(self.output_dir)\n        \n        print(\"\\n✅ 모든 시스템 초기화 완료!\")\n    \n    def run(self, \n            target_count: int = None,\n            load_model: bool = True,\n            test_mode: bool = False):\n        \"\"\"\n        데이터 증강 실행\n        \n        Args:\n            target_count: 생성할 문제 수\n            load_model: LLM 모델 로드 여부\n            test_mode: 테스트 모드 (소량 생성)\n        \"\"\"\n        if target_count:\n            self.config['target_count'] = target_count\n        \n        if test_mode:\n            self.config['target_count'] = 10\n            self.config['batch_size'] = 2\n            print(\"⚠️ 테스트 모드: 10개만 생성합니다.\")\n        \n        try:\n            # 모델 로드\n            if load_model:\n                print(\"\\n🤖 LLM 모델 로드 중...\")\n                self.generator.initialize_model(\n                    use_quantization=self.config['use_quantization']\n                )\n            \n            # 모니터링 시작\n            self.monitor.start_monitoring(self.config['target_count'])\n            \n            # 데이터 생성 루프\n            self._generation_loop()\n            \n            # 완료 처리\n            self._finalize()\n            \n        except KeyboardInterrupt:\n            print(\"\\n\\n⚠️ 사용자에 의해 중단됨\")\n            self._finalize()\n        except Exception as e:\n            logger.error(f\"실행 중 오류: {e}\")\n            raise\n        finally:\n            if self.monitor:\n                self.monitor.close()\n    \n    def _generation_loop(self):\n        \"\"\"데이터 생성 메인 루프\"\"\"\n        print(\"\\n\" + \"=\" * 60)\n        print(\"🔄 데이터 생성 시작\")\n        print(\"=\" * 60)\n        \n        generated_count = 0\n        attempts = 0\n        \n        # 진행률 표시\n        pbar = tqdm(total=self.config['target_count'], desc=\"생성 진행\")\n        \n        while generated_count < self.config['target_count']:\n            attempts += 1\n            \n            try:\n                # 1. RAG에서 컨텍스트 가져오기\n                if random.random() < 0.7:\n                    # 70% 확률로 관련 검색\n                    query = self._generate_search_query()\n                    context = self.rag_system.search(query, top_k=3)\n                else:\n                    # 30% 확률로 랜덤\n                    context = self.rag_system.get_random_context(n=2)\n                \n                if not context:\n                    logger.warning(\"컨텍스트 가져오기 실패\")\n                    continue\n                \n                # 2. 프롬프트 템플릿 선택\n                template_name = self.prompt_manager.recommend_template(context)\n                \n                # 3. 문제 생성\n                result = self.generator.generate_qa_pair(\n                    context=context,\n                    question_type=self._get_question_type_from_template(template_name),\n                    max_iterations=self.config['max_iterations']\n                )\n                \n                if result and result.get('passed', False):\n                    # 4. 데이터 저장\n                    if self.data_manager.add_data(result):\n                        generated_count += 1\n                        pbar.update(1)\n                    \n                    # 5. 모니터링 업데이트\n                    self.monitor.update(result)\n                    \n                    # 6. 진행 상황 출력 (50개마다)\n                    if generated_count % 50 == 0:\n                        self._print_progress(generated_count, attempts)\n                \n            except Exception as e:\n                logger.error(f\"생성 중 오류: {e}\")\n                continue\n            \n            # 너무 많은 시도 방지\n            if attempts > self.config['target_count'] * 3:\n                logger.warning(\"너무 많은 시도. 품질 기준을 확인하세요.\")\n                break\n        \n        pbar.close()\n    \n    def _generate_search_query(self) -> str:\n        \"\"\"검색 쿼리 생성\"\"\"\n        # 금융 관련 주요 토픽\n        topics = [\n            \"전자금융거래\", \"개인정보보호\", \"금융보안\", \"자금세탁방지\",\n            \"신용정보\", \"금융상품\", \"리스크관리\", \"내부통제\",\n            \"금융규제\", \"핀테크\", \"디지털금융\", \"금융소비자보호\",\n            \"KYC\", \"AML\", \"자산운용\", \"증권거래\"\n        ]\n        \n        return random.choice(topics)\n    \n    def _get_question_type_from_template(self, template_name: str) -> str:\n        \"\"\"템플릿명에서 문제 유형 추출\"\"\"\n        if '객관식' in template_name:\n            return '객관식'\n        elif '주관식' in template_name:\n            return '주관식'\n        elif '계산' in template_name:\n            return '계산'\n        else:\n            return '기타'\n    \n    def _print_progress(self, generated: int, attempts: int):\n        \"\"\"진행 상황 출력\"\"\"\n        success_rate = generated / attempts * 100 if attempts > 0 else 0\n        print(f\"\\n📊 진행 상황: {generated}/{self.config['target_count']} \"\n              f\"(성공률: {success_rate:.1f}%)\")\n    \n    def _finalize(self):\n        \"\"\"최종 처리\"\"\"\n        print(\"\\n🏁 최종 처리 중...\")\n        \n        # 데이터 저장 완료\n        if self.data_manager:\n            self.data_manager.finalize()\n            \n            # 메타데이터 저장\n            if self.generator and self.monitor:\n                generation_stats = {\n                    'generator': self.generator.get_statistics(),\n                    'monitor': self.monitor.stats\n                }\n                self.data_manager.save_metadata(generation_stats)\n            \n            # 데이터 검증\n            self.data_manager.validate_data()\n        \n        # 모니터링 요약\n        if self.monitor:\n            self.monitor.print_summary()\n            \n            # 보고서 저장\n            report_path = self.output_dir / \"generation_report.json\"\n            self.monitor.save_report(str(report_path))\n        \n        print(\"\\n✅ 모든 작업 완료!\")\n    \n    def update_config(self, **kwargs):\n        \"\"\"설정 업데이트\"\"\"\n        self.config.update(kwargs)\n        print(\"설정 업데이트됨:\")\n        for key, value in kwargs.items():\n            print(f\"  - {key}: {value}\")\n\n\n# 통합 실행 시스템 생성\nprint(\"✅ FSKU 데이터 증강 통합 시스템 생성 완료\")\nprint(\"\\n사용법:\")\nprint(\"1. augmentation = FSKUDataAugmentation()\")\nprint(\"2. augmentation.initialize()\")\nprint(\"3. augmentation.run(target_count=1000)\")\nprint(\"\\n설정 변경:\")\nprint(\"augmentation.update_config(batch_size=8, quality_threshold=75)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 🎯 실행 예제\n\n아래 셀을 실행하여 데이터 증강을 시작하세요.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 실행 예제 1: 테스트 실행 (10개만 생성)\nprint(\"=\" * 60)\nprint(\"🧪 테스트 실행 예제\")\nprint(\"=\" * 60)\nprint(\"\\n이 셀을 실행하면 10개의 샘플 데이터를 생성합니다.\")\nprint(\"실제 실행 전에 시스템이 제대로 작동하는지 확인할 수 있습니다.\")\nprint(\"\\n실행하려면 아래 주석을 제거하세요:\")\n\n# # 시스템 생성\n# augmentation = FSKUDataAugmentation(\n#     model_name=\"beomi/llama-2-ko-7b\",\n#     external_dir=EXTERNAL_DIR,\n#     output_dir=OUTPUT_DIR\n# )\n\n# # 초기화\n# augmentation.initialize()\n\n# # 테스트 실행\n# augmentation.run(test_mode=True)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 실행 예제 2: 본격 실행 (1000개 생성)\nprint(\"=\" * 60)\nprint(\"🚀 본격 실행 예제\")\nprint(\"=\" * 60)\nprint(\"\\n이 셀을 실행하면 1000개의 고품질 데이터를 생성합니다.\")\nprint(\"예상 소요 시간: 2-4시간 (모델과 하드웨어에 따라 다름)\")\nprint(\"\\n실행하려면 아래 주석을 제거하세요:\")\n\n# # 시스템 생성 (더 좋은 모델 사용)\n# augmentation = FSKUDataAugmentation(\n#     model_name=\"upstage/SOLAR-10.7B-v1.0\",  # 더 좋은 한국어 모델\n#     external_dir=EXTERNAL_DIR,\n#     output_dir=OUTPUT_DIR\n# )\n\n# # 설정 변경 (선택사항)\n# augmentation.update_config(\n#     target_count=1000,        # 생성할 문제 수\n#     batch_size=4,             # 배치 크기\n#     quality_threshold=75,     # 품질 기준 (높일수록 엄격)\n#     max_iterations=3          # 개선 반복 횟수\n# )\n\n# # 초기화\n# augmentation.initialize()\n\n# # 본격 실행\n# augmentation.run()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 실행 예제 3: 결과 분석 및 학습 데이터 내보내기\nprint(\"=\" * 60)\nprint(\"📊 결과 분석 예제\")\nprint(\"=\" * 60)\nprint(\"\\n생성이 완료된 후 이 셀을 실행하여 결과를 분석하세요.\")\n\n# 최신 생성 파일 찾기\nimport glob\n\n# JSONL 파일 찾기\njsonl_files = sorted(glob.glob(str(OUTPUT_DIR / \"fsku_data_*.jsonl\")))\n\nif jsonl_files:\n    latest_file = jsonl_files[-1]\n    print(f\"\\n최신 데이터 파일: {latest_file}\")\n    \n    # 데이터 매니저로 검증\n    temp_manager = DataManager(OUTPUT_DIR)\n    temp_manager.data_file = Path(latest_file)\n    \n    # 검증 실행\n    validation = temp_manager.validate_data()\n    \n    # 학습용 데이터로 내보내기\n    if validation['valid']:\n        print(\"\\n학습용 데이터로 내보내기...\")\n        temp_manager.export_for_training()\n    \n    # 샘플 출력\n    print(\"\\n📝 생성된 데이터 샘플 (처음 3개):\")\n    print(\"-\" * 60)\n    \n    with open(latest_file, 'r', encoding='utf-8') as f:\n        for i, line in enumerate(f):\n            if i >= 3:\n                break\n            data = json.loads(line)\n            print(f\"\\n[샘플 {i+1}]\")\n            print(f\"문제: {data['instruction'][:100]}...\")\n            print(f\"답변: {data['output'][:100]}...\")\n            print(f\"품질: {data['quality_score']}점\")\n            print(f\"유형: {data['question_type']}\")\nelse:\n    print(\"\\n⚠️ 생성된 데이터 파일이 없습니다.\")\n    print(\"먼저 데이터 생성을 실행하세요.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 🎉 완료!\n\n### ✅ 구현 완료 사항\n1. **RAG 시스템** - 외부 문서 기반 컨텍스트 검색\n2. **품질 평가 시스템** - 다차원 평가로 고품질 보장\n3. **체이닝 생성기** - 4단계 개선 프로세스\n4. **프롬프트 템플릿** - 10가지 이상의 문제 유형\n5. **실시간 모니터링** - 진행 상황 시각화\n6. **데이터 관리** - JSONL 저장 및 검증\n7. **통합 실행** - 원클릭 자동화\n\n### 📋 사용 방법 요약\n\n1. **외부 문서 준비**\n   ```\n   data/external/ 폴더에 PDF, TXT, Excel 문서 추가\n   ```\n\n2. **테스트 실행**\n   ```python\n   augmentation = FSKUDataAugmentation()\n   augmentation.initialize()\n   augmentation.run(test_mode=True)\n   ```\n\n3. **본격 실행**\n   ```python\n   augmentation.run(target_count=1000)\n   ```\n\n### 💡 Tips\n- GPU 메모리 부족시: `use_quantization=True` (기본값)\n- 품질 향상: `quality_threshold=80` 으로 설정\n- 속도 향상: `batch_size` 증가\n- 다양성 확보: 외부 문서 다양하게 추가\n\n### 📚 생성된 파일\n- `data/augmented/fsku_data_*.jsonl` - 생성된 데이터\n- `data/augmented/fsku_metadata_*.json` - 메타데이터\n- `data/augmented/generation_report.json` - 상세 보고서\n- `data/augmented/train_data.jsonl` - 학습용 포맷\n\n### 🚀 다음 단계\n1. 생성된 데이터로 모델 학습 (FSKU_2_학습.ipynb)\n2. 학습된 모델로 추론 (FSKU_3_추론.ipynb)\n\n---\n**Good Luck with FSKU Challenge! 🏆**",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}