{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ FSKU ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ (RAG + Chain-of-Thought)\n",
    "\n",
    "## ğŸ“Œ ê°œìš”\n",
    "- **ëŒ€íšŒ**: 2025 ê¸ˆìœµ AI Challenge Track1\n",
    "- **ëª©ì **: ì™¸ë¶€ ê¸ˆìœµ ë¬¸ì„œ ê¸°ë°˜ ê³ í’ˆì§ˆ í•™ìŠµ ë°ì´í„° ìë™ ìƒì„±\n",
    "- **í•µì‹¬ ê¸°ìˆ **: RAG (Retrieval Augmented Generation) + LLM ì²´ì´ë‹ + í’ˆì§ˆ ê´€ë¦¬\n",
    "\n",
    "## ğŸ”„ ì „ì²´ ë™ì‘ í”„ë¡œì„¸ìŠ¤\n",
    "```\n",
    "1. ë¬¸ì„œ ìˆ˜ì§‘ â†’ 2. RAG ì¸ë±ì‹± â†’ 3. ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ â†’ 4. LLM ë¬¸ì œ ìƒì„± \n",
    "â†’ 5. í’ˆì§ˆ í‰ê°€ â†’ 6. ì²´ì´ë‹ ê°œì„  â†’ 7. ìµœì¢… ê²€ì¦ â†’ 8. ë°ì´í„° ì €ì¥\n",
    "```\n",
    "\n",
    "## ğŸ› ï¸ í•µì‹¬ ê¸°ë²•\n",
    "1. **RAG (Retrieval Augmented Generation)**\n",
    "   - ì™¸ë¶€ ê¸ˆìœµ ë¬¸ì„œë¥¼ ë²¡í„° DBì— ì €ì¥\n",
    "   - ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "   - LLM ìƒì„± ì‹œ ì°¸ê³  ìë£Œë¡œ í™œìš©\n",
    "\n",
    "2. **Chain-of-Thought ì²´ì´ë‹**\n",
    "   - ìƒì„± â†’ ê²€ì¦ â†’ ê°œì„  â†’ ìµœì¢…í™•ì¸ 4ë‹¨ê³„\n",
    "   - ê° ë‹¨ê³„ë³„ ì „ë¬¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\n",
    "   - í’ˆì§ˆ ì ìˆ˜ ê¸°ë°˜ ìë™ ê°œì„ \n",
    "\n",
    "3. **í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ**\n",
    "   - ë‹¤ì°¨ì› í‰ê°€ (ê¸¸ì´, êµ¬ì¡°, ëª…í™•ì„±, ê¸ˆìœµìš©ì–´)\n",
    "   - 70ì  ì´ìƒë§Œ í†µê³¼\n",
    "   - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ\n",
    "\n",
    "## ğŸ“Š ì˜ˆìƒ ê²°ê³¼\n",
    "- ìƒì„± ëª©í‘œ: 1,000~5,000ê°œ ê³ í’ˆì§ˆ ë¬¸ì œ\n",
    "- í’ˆì§ˆ ê¸°ì¤€: 70ì  ì´ìƒ\n",
    "- ì†Œìš” ì‹œê°„: ì•½ 2-4ì‹œê°„ (ëª¨ë¸ í¬ê¸° ë”°ë¼)\n",
    "- ì¶œë ¥ í˜•ì‹: JSONL (í•™ìŠµìš©), ë©”íƒ€ë°ì´í„° (ë¶„ì„ìš©)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ì‹œìŠ¤í…œ ì •ë³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥\n",
    "import platform\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ–¥ï¸  ì‹œìŠ¤í…œ í™˜ê²½ ì •ë³´\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"OS: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python: {platform.python_version()}\")\n",
    "print(f\"í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "# ì£¼ì˜: ì´ë¯¸ ì„¤ì¹˜ëœ ê²½ìš° ìŠ¤í‚µë©ë‹ˆë‹¤\n",
    "\n",
    "print(\"ğŸ“¦ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\")\n",
    "print(\"(ì´ë¯¸ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ëŠ” ìë™ìœ¼ë¡œ ìŠ¤í‚µë©ë‹ˆë‹¤)\\n\")\n",
    "\n",
    "# ê¸°ë³¸ íŒ¨í‚¤ì§€\n",
    "%pip install -q transformers accelerate bitsandbytes\n",
    "print(\"âœ… Transformers ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "\n",
    "# ë²¡í„° ê²€ìƒ‰ ë° ì„ë² ë”©\n",
    "%pip install -q sentence-transformers faiss-cpu\n",
    "print(\"âœ… ë²¡í„° ê²€ìƒ‰ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "\n",
    "# ë¬¸ì„œ ì²˜ë¦¬\n",
    "%pip install -q PyPDF2 pdfplumber pandas openpyxl\n",
    "print(\"âœ… ë¬¸ì„œ ì²˜ë¦¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "\n",
    "# ì¶”ê°€ ìœ í‹¸ë¦¬í‹°\n",
    "%pip install -q tiktoken langchain tqdm matplotlib seaborn\n",
    "print(\"âœ… ìœ í‹¸ë¦¬í‹° íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë“  íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° í™˜ê²½ ì²´í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "print(\"ğŸ“š ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì¤‘...\")\n",
    "\n",
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Any, Tuple\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import logging\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ì‹œê°í™”\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'  # í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "\n",
    "# ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer, \n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\\n\")\n",
    "\n",
    "# GPU/í™˜ê²½ ì²´í¬\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ”¥ PyTorch í™˜ê²½ ì •ë³´\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU ì´ë¦„: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
    "    print(f\"í˜„ì¬ í• ë‹¹ëœ ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated() / 1024**3:.2f}GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\")\n",
    "    print(\"   ì„±ëŠ¥ì´ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“ í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# í˜„ì¬ ë…¸íŠ¸ë¶ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "EXTERNAL_DIR = DATA_DIR / \"external\"  # ì™¸ë¶€ ë¬¸ì„œ ë””ë ‰í† ë¦¬\n",
    "OUTPUT_DIR = DATA_DIR / \"augmented\"   # ìƒì„±ëœ ë°ì´í„° ì €ì¥\n",
    "CACHE_DIR = DATA_DIR / \"cache\"        # ìºì‹œ ë””ë ‰í† ë¦¬\n",
    "VECTORDB_DIR = DATA_DIR / \"vectordb\"  # ë²¡í„° DB ì €ì¥\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "for dir_path in [DATA_DIR, EXTERNAL_DIR, OUTPUT_DIR, CACHE_DIR, VECTORDB_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âœ… {dir_path.name}/\")\n",
    "\n",
    "print(f\"\\ní”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}\")\n",
    "print(f\"ì™¸ë¶€ ë°ì´í„°: {EXTERNAL_DIR}\")\n",
    "print(f\"ì¶œë ¥ ë””ë ‰í† ë¦¬: {OUTPUT_DIR}\")\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"\\nâœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RAG ì‹œìŠ¤í…œ - ë¬¸ì„œ ë¡œë” í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentLoader:\n",
    "    \"\"\"\n",
    "    ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ëŠ” í´ë˜ìŠ¤\n",
    "    \n",
    "    ì§€ì› í˜•ì‹:\n",
    "    - PDF: PyPDF2 ë˜ëŠ” pdfplumber ì‚¬ìš©\n",
    "    - Excel: pandasë¡œ ì½ê¸°\n",
    "    - TXT: ê¸°ë³¸ íŒŒì¼ ì½ê¸°\n",
    "    - JSON: êµ¬ì¡°í™”ëœ ë°ì´í„° ë¡œë“œ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # ì§€ì›í•˜ëŠ” íŒŒì¼ í˜•ì‹ë“¤\n",
    "        self.supported_formats = ['.pdf', '.txt', '.xlsx', '.xls', '.json']\n",
    "        \n",
    "    def load_document(self, file_path: Path) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        ë¬¸ì„œë¥¼ ë¡œë“œí•˜ëŠ” ë©”ì¸ í•¨ìˆ˜\n",
    "        \n",
    "        Args:\n",
    "            file_path: ë¬¸ì„œ íŒŒì¼ ê²½ë¡œ\n",
    "            \n",
    "        Returns:\n",
    "            Dict: {\n",
    "                'content': str,      # ë¬¸ì„œ ì „ì²´ í…ìŠ¤íŠ¸\n",
    "                'metadata': dict,    # ë©”íƒ€ë°ì´í„°\n",
    "                'pages': list       # í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ (PDFì˜ ê²½ìš°)\n",
    "            }\n",
    "        \"\"\"\n",
    "        # íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "        if not file_path.exists():\n",
    "            logger.error(f\"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}\")\n",
    "            return None\n",
    "            \n",
    "        # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ\n",
    "        suffix = file_path.suffix.lower()\n",
    "        \n",
    "        # ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ ì²´í¬\n",
    "        if suffix not in self.supported_formats:\n",
    "            logger.warning(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {suffix}\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # íŒŒì¼ í˜•ì‹ë³„ ì²˜ë¦¬\n",
    "            if suffix == '.pdf':\n",
    "                return self._load_pdf(file_path)\n",
    "            elif suffix == '.txt':\n",
    "                return self._load_text(file_path)\n",
    "            elif suffix in ['.xlsx', '.xls']:\n",
    "                return self._load_excel(file_path)\n",
    "            elif suffix == '.json':\n",
    "                return self._load_json(file_path)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨ {file_path}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _load_pdf(self, file_path: Path) -> Dict:\n",
    "        \"\"\"\n",
    "        PDF íŒŒì¼ ë¡œë“œ - í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        \"\"\"\n",
    "        try:\n",
    "            import PyPDF2\n",
    "            \n",
    "            text_pages = []\n",
    "            metadata = {\n",
    "                'source': file_path.name,\n",
    "                'type': 'pdf',\n",
    "                'pages': 0\n",
    "            }\n",
    "            \n",
    "            # PDF íŒŒì¼ ì—´ê¸°\n",
    "            with open(file_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                metadata['pages'] = len(pdf_reader.pages)\n",
    "                \n",
    "                # ê° í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "                for page_num, page in enumerate(pdf_reader.pages):\n",
    "                    try:\n",
    "                        text = page.extract_text()\n",
    "                        if text.strip():  # ë¹ˆ í˜ì´ì§€ ì œì™¸\n",
    "                            text_pages.append({\n",
    "                                'page': page_num + 1,\n",
    "                                'content': text\n",
    "                            })\n",
    "                    except Exception as e:\n",
    "                        logger.debug(f\"í˜ì´ì§€ {page_num+1} ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "                        continue\n",
    "                        \n",
    "        except ImportError:\n",
    "            # PyPDF2ê°€ ì—†ìœ¼ë©´ pdfplumber ì‹œë„\n",
    "            logger.info(\"PyPDF2 ëŒ€ì‹  pdfplumber ì‚¬ìš©\")\n",
    "            return self._load_pdf_with_pdfplumber(file_path)\n",
    "            \n",
    "        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©\n",
    "        full_text = \"\\n\\n\".join([\n",
    "            f\"[í˜ì´ì§€ {p['page']}]\\n{p['content']}\" \n",
    "            for p in text_pages\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            'content': full_text,\n",
    "            'metadata': metadata,\n",
    "            'pages': text_pages\n",
    "        }\n",
    "    \n",
    "    def _load_pdf_with_pdfplumber(self, file_path: Path) -> Dict:\n",
    "        \"\"\"\n",
    "        pdfplumberë¡œ PDF ë¡œë“œ (ëŒ€ì²´ ë°©ë²•)\n",
    "        \"\"\"\n",
    "        import pdfplumber\n",
    "        \n",
    "        text_pages = []\n",
    "        metadata = {\n",
    "            'source': file_path.name,\n",
    "            'type': 'pdf',\n",
    "            'pages': 0\n",
    "        }\n",
    "        \n",
    "        # pdfplumberë¡œ íŒŒì¼ ì—´ê¸°\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            metadata['pages'] = len(pdf.pages)\n",
    "            \n",
    "            # ê° í˜ì´ì§€ ì²˜ë¦¬\n",
    "            for page_num, page in enumerate(pdf.pages):\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    text_pages.append({\n",
    "                        'page': page_num + 1,\n",
    "                        'content': text\n",
    "                    })\n",
    "        \n",
    "        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©\n",
    "        full_text = \"\\n\\n\".join([\n",
    "            f\"[í˜ì´ì§€ {p['page']}]\\n{p['content']}\" \n",
    "            for p in text_pages\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            'content': full_text,\n",
    "            'metadata': metadata,\n",
    "            'pages': text_pages\n",
    "        }\n",
    "    \n",
    "    def _load_text(self, file_path: Path) -> Dict:\n",
    "        \"\"\"\n",
    "        í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # UTF-8ë¡œ ì‹œë„\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            # ì‹¤íŒ¨ì‹œ cp949(í•œê¸€ ìœˆë„ìš°) ì¸ì½”ë”© ì‹œë„\n",
    "            with open(file_path, 'r', encoding='cp949') as f:\n",
    "                content = f.read()\n",
    "        \n",
    "        return {\n",
    "            'content': content,\n",
    "            'metadata': {\n",
    "                'source': file_path.name,\n",
    "                'type': 'text',\n",
    "                'size': len(content)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _load_excel(self, file_path: Path) -> Dict:\n",
    "        \"\"\"\n",
    "        Excel íŒŒì¼ ë¡œë“œ\n",
    "        \"\"\"\n",
    "        # ëª¨ë“  ì‹œíŠ¸ ì½ê¸°\n",
    "        dfs = pd.read_excel(file_path, sheet_name=None)\n",
    "        \n",
    "        text_parts = []\n",
    "        # ê° ì‹œíŠ¸ë³„ë¡œ ì²˜ë¦¬\n",
    "        for sheet_name, df in dfs.items():\n",
    "            text_parts.append(f\"\\n[ì‹œíŠ¸: {sheet_name}]\\n\")\n",
    "            # DataFrameì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "            text_parts.append(df.to_string())\n",
    "        \n",
    "        content = \"\\n\".join(text_parts)\n",
    "        \n",
    "        return {\n",
    "            'content': content,\n",
    "            'metadata': {\n",
    "                'source': file_path.name,\n",
    "                'type': 'excel',\n",
    "                'sheets': list(dfs.keys()),\n",
    "                'total_rows': sum(len(df) for df in dfs.values())\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _load_json(self, file_path: Path) -> Dict:\n",
    "        \"\"\"\n",
    "        JSON íŒŒì¼ ë¡œë“œ\n",
    "        \"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # JSONì„ ë³´ê¸° ì¢‹ì€ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "        content = json.dumps(data, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        return {\n",
    "            'content': content,\n",
    "            'metadata': {\n",
    "                'source': file_path.name,\n",
    "                'type': 'json',\n",
    "                'keys': list(data.keys()) if isinstance(data, dict) else None\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def load_directory(self, dir_path: Path) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ë¬¸ì„œ ë¡œë“œ\n",
    "        \n",
    "        Args:\n",
    "            dir_path: ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "            \n",
    "        Returns:\n",
    "            ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        documents = []\n",
    "        \n",
    "        if not dir_path.exists():\n",
    "            logger.error(f\"ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {dir_path}\")\n",
    "            return documents\n",
    "        \n",
    "        # ì§€ì›í•˜ëŠ” í˜•ì‹ì˜ íŒŒì¼ë“¤ ì°¾ê¸°\n",
    "        total_files = 0\n",
    "        for ext in self.supported_formats:\n",
    "            for file_path in dir_path.glob(f\"*{ext}\"):\n",
    "                total_files += 1\n",
    "                print(f\"ğŸ“„ ë¡œë”©: {file_path.name}\")\n",
    "                \n",
    "                doc = self.load_document(file_path)\n",
    "                if doc:\n",
    "                    documents.append(doc)\n",
    "                    print(f\"   âœ… ì„±ê³µ (í¬ê¸°: {len(doc['content']):,}ì)\")\n",
    "                else:\n",
    "                    print(f\"   âŒ ì‹¤íŒ¨\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ë¡œë“œ ê²°ê³¼: {len(documents)}/{total_files}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\")\n",
    "        return documents\n",
    "\n",
    "\n",
    "# ë¬¸ì„œ ë¡œë” í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ”„ ë¬¸ì„œ ë¡œë” í´ë˜ìŠ¤ ìƒì„± ì™„ë£Œ\")\n",
    "loader = DocumentLoader()\n",
    "print(f\"ì§€ì› í˜•ì‹: {', '.join(loader.supported_formats)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RAG ì‹œìŠ¤í…œ - ë¬¸ì„œ ì²­í‚¹ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentChunker:\n",
    "    \"\"\"\n",
    "    ê¸´ ë¬¸ì„œë¥¼ ì˜ë¯¸ ìˆëŠ” ë‹¨ìœ„ë¡œ ë¶„í• í•˜ëŠ” í´ë˜ìŠ¤\n",
    "    \n",
    "    íŠ¹ì§•:\n",
    "    - ì²­í¬ í¬ê¸°: 300 í† í° (RAG ìµœì í™”)\n",
    "    - ì˜¤ë²„ë©: 50 í† í° (ë¬¸ë§¥ ìœ ì§€)\n",
    "    - í•œêµ­ì–´ íŠ¹í™”: í˜•íƒœì†Œ ê¸°ë°˜ ë¶„í• \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, chunk_size: int = 300, chunk_overlap: int = 50):\n",
    "        \"\"\"\n",
    "        ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            chunk_size: ê° ì²­í¬ì˜ ìµœëŒ€ í† í° ìˆ˜\n",
    "            chunk_overlap: ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” í† í° ìˆ˜\n",
    "        \"\"\"\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.min_chunk_size = 50  # ìµœì†Œ ì²­í¬ í¬ê¸°\n",
    "        \n",
    "    def chunk_document(self, document: Dict) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• \n",
    "        \n",
    "        ì²˜ë¦¬ ê³¼ì •:\n",
    "        1. ë¬¸ì„œë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• \n",
    "        2. ê° ë¬¸ì¥ì˜ í† í° ìˆ˜ ê³„ì‚°\n",
    "        3. ì²­í¬ í¬ê¸°ì— ë§ê²Œ ë¬¸ì¥ë“¤ì„ ê²°í•©\n",
    "        4. ì˜¤ë²„ë© ì²˜ë¦¬í•˜ì—¬ ë¬¸ë§¥ ìœ ì§€\n",
    "        \"\"\"\n",
    "        content = document.get('content', '')\n",
    "        metadata = document.get('metadata', {})\n",
    "        \n",
    "        # PDFì¸ ê²½ìš° í˜ì´ì§€ë³„ ì²˜ë¦¬ ê³ ë ¤\n",
    "        if metadata.get('type') == 'pdf' and 'pages' in document:\n",
    "            chunks = []\n",
    "            # ê° í˜ì´ì§€ë³„ë¡œ ì²­í‚¹\n",
    "            for page_info in document['pages']:\n",
    "                page_chunks = self._chunk_text(\n",
    "                    page_info['content'],\n",
    "                    {**metadata, 'page': page_info['page']}\n",
    "                )\n",
    "                chunks.extend(page_chunks)\n",
    "            return chunks\n",
    "        else:\n",
    "            # ì¼ë°˜ í…ìŠ¤íŠ¸ ì²˜ë¦¬\n",
    "            return self._chunk_text(content, metadata)\n",
    "    \n",
    "    def _chunk_text(self, text: str, metadata: Dict = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” ì‹¤ì œ ë¡œì§\n",
    "        \"\"\"\n",
    "        if not text or len(text.strip()) < self.min_chunk_size:\n",
    "            return []\n",
    "        \n",
    "        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• \n",
    "        sentences = self._split_sentences(text)\n",
    "        \n",
    "        # ì²­í¬ ìƒì„±\n",
    "        chunks = []\n",
    "        current_chunk = []  # í˜„ì¬ ì²­í¬ì˜ ë¬¸ì¥ë“¤\n",
    "        current_length = 0  # í˜„ì¬ ì²­í¬ì˜ í† í° ìˆ˜\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            # ë¬¸ì¥ì˜ ì˜ˆìƒ í† í° ìˆ˜ ê³„ì‚°\n",
    "            sentence_length = self._estimate_tokens(sentence)\n",
    "            \n",
    "            # í˜„ì¬ ì²­í¬ê°€ í¬ê¸°ë¥¼ ì´ˆê³¼í•˜ë©´ ìƒˆ ì²­í¬ ì‹œì‘\n",
    "            if current_length + sentence_length > self.chunk_size and current_chunk:\n",
    "                # í˜„ì¬ ì²­í¬ ì €ì¥\n",
    "                chunk_text = ' '.join(current_chunk)\n",
    "                chunks.append(self._create_chunk(chunk_text, len(chunks), metadata))\n",
    "                \n",
    "                # ì˜¤ë²„ë© ì²˜ë¦¬: ì´ì „ ì²­í¬ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ì„ ë‹¤ìŒ ì²­í¬ì— í¬í•¨\n",
    "                if self.chunk_overlap > 0:\n",
    "                    overlap_sentences = []\n",
    "                    overlap_length = 0\n",
    "                    \n",
    "                    # ë’¤ì—ì„œë¶€í„° ì˜¤ë²„ë© í¬ê¸°ë§Œí¼ ë¬¸ì¥ ì„ íƒ\n",
    "                    for sent in reversed(current_chunk):\n",
    "                        sent_len = self._estimate_tokens(sent)\n",
    "                        if overlap_length + sent_len <= self.chunk_overlap:\n",
    "                            overlap_sentences.insert(0, sent)\n",
    "                            overlap_length += sent_len\n",
    "                        else:\n",
    "                            break\n",
    "                    \n",
    "                    current_chunk = overlap_sentences\n",
    "                    current_length = overlap_length\n",
    "                else:\n",
    "                    current_chunk = []\n",
    "                    current_length = 0\n",
    "            \n",
    "            # í˜„ì¬ ë¬¸ì¥ ì¶”ê°€\n",
    "            current_chunk.append(sentence)\n",
    "            current_length += sentence_length\n",
    "        \n",
    "        # ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬\n",
    "        if current_chunk:\n",
    "            chunk_text = ' '.join(current_chunk)\n",
    "            if len(chunk_text.strip()) >= self.min_chunk_size:\n",
    "                chunks.append(self._create_chunk(chunk_text, len(chunks), metadata))\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def _split_sentences(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ìœ¼ë¡œ ë¶„í• \n",
    "        í•œêµ­ì–´ ë¬¸ì¥ ì¢…ê²° ì–´ë¯¸ë¥¼ ê³ ë ¤í•œ ë¶„í• \n",
    "        \"\"\"\n",
    "        # ë¬¸ì¥ ì¢…ê²° íŒ¨í„´ (í•œêµ­ì–´ + ì˜ì–´)\n",
    "        sentence_endings = r'[.!?ã€‚]\\s+'\n",
    "        \n",
    "        # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì²˜ë¦¬ (ì˜ˆ: ì¡°í•­ ë²ˆí˜¸)\n",
    "        # \"ì œ1ì¡°.\" ê°™ì€ ê²½ìš°ë¥¼ ë¬¸ì¥ ëìœ¼ë¡œ ì¸ì‹í•˜ì§€ ì•Šë„ë¡\n",
    "        text = re.sub(r'(\\d+)\\.\\s*(\\d+)', r'\\1_\\2', text)  # 1.2 -> 1_2\n",
    "        text = re.sub(r'(\\d+)\\.\\s*([ê°€-í£])', r'\\1_\\2', text)  # 1.ê°€ -> 1_ê°€\n",
    "        text = re.sub(r'ì œ(\\d+)ì¡°\\.', r'ì œ\\1ì¡°_', text)  # ì œ1ì¡°. -> ì œ1ì¡°_\n",
    "        \n",
    "        # ë¬¸ì¥ ë¶„í• \n",
    "        sentences = re.split(sentence_endings, text)\n",
    "        \n",
    "        # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ë³µì›\n",
    "        sentences = [s.replace('_', '.') for s in sentences]\n",
    "        \n",
    "        # ë¹ˆ ë¬¸ì¥ ì œê±° ë° ì •ë¦¬\n",
    "        sentences = [s.strip() for s in sentences if s.strip()]\n",
    "        \n",
    "        # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ì€ ë‹¤ìŒ ë¬¸ì¥ê³¼ ê²°í•©\n",
    "        combined_sentences = []\n",
    "        temp_sentence = \"\"\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if len(sentence) < 20 and temp_sentence:\n",
    "                # ì§§ì€ ë¬¸ì¥ì€ ì´ì „ ë¬¸ì¥ê³¼ ê²°í•©\n",
    "                temp_sentence += \" \" + sentence\n",
    "            else:\n",
    "                if temp_sentence:\n",
    "                    combined_sentences.append(temp_sentence)\n",
    "                temp_sentence = sentence\n",
    "        \n",
    "        if temp_sentence:\n",
    "            combined_sentences.append(temp_sentence)\n",
    "        \n",
    "        return combined_sentences\n",
    "    \n",
    "    def _estimate_tokens(self, text: str) -> int:\n",
    "        \"\"\"\n",
    "        í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ ì¶”ì •\n",
    "        \n",
    "        í•œêµ­ì–´/ì˜ì–´/ìˆ«ìë¥¼ ê³ ë ¤í•œ ì¶”ì •:\n",
    "        - í•œê¸€: í‰ê·  2.5ì = 1í† í°\n",
    "        - ì˜ì–´: í‰ê·  4ì = 1í† í°\n",
    "        - ìˆ«ì: í‰ê·  3ì = 1í† í°\n",
    "        \"\"\"\n",
    "        # ë¬¸ì ìœ í˜•ë³„ ê°œìˆ˜ ê³„ì‚°\n",
    "        korean_chars = len(re.findall(r'[ê°€-í£]', text))\n",
    "        english_chars = len(re.findall(r'[a-zA-Z]', text))\n",
    "        numbers = len(re.findall(r'\\d', text))\n",
    "        \n",
    "        # í† í° ìˆ˜ ì¶”ì •\n",
    "        estimated_tokens = (\n",
    "            korean_chars / 2.5 +\n",
    "            english_chars / 4 +\n",
    "            numbers / 3\n",
    "        )\n",
    "        \n",
    "        return int(estimated_tokens)\n",
    "    \n",
    "    def _create_chunk(self, text: str, index: int, metadata: Dict = None) -> Dict:\n",
    "        \"\"\"\n",
    "        ì²­í¬ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "        \"\"\"\n",
    "        chunk = {\n",
    "            'content': text.strip(),\n",
    "            'chunk_id': index,\n",
    "            'tokens': self._estimate_tokens(text),\n",
    "            'metadata': metadata or {}\n",
    "        }\n",
    "        \n",
    "        # ì²­í¬ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "        keywords = self._extract_keywords(text)\n",
    "        if keywords:\n",
    "            chunk['keywords'] = keywords\n",
    "        \n",
    "        return chunk\n",
    "    \n",
    "    def _extract_keywords(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "        ê¸ˆìœµ ë¬¸ì„œì˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "        \"\"\"\n",
    "        keywords = []\n",
    "        \n",
    "        # ì¡°í•­ ë²ˆí˜¸ íŒ¨í„´ (ì˜ˆ: ì œ1ì¡°, ì œ2í•­)\n",
    "        article_patterns = re.findall(r'ì œ\\d+ì¡°', text)\n",
    "        keywords.extend(article_patterns[:3])  # ìµœëŒ€ 3ê°œ\n",
    "        \n",
    "        # ê´„í˜¸ ì•ˆì˜ ì •ì˜ (ì˜ˆ: ì „ìê¸ˆìœµê±°ë˜(ì´í•˜ \"ì „ìê±°ë˜\"ë¼ í•œë‹¤))\n",
    "        definitions = re.findall(r'[ê°€-í£]+(?:\\([^)]+\\))', text)\n",
    "        keywords.extend(definitions[:3])  # ìµœëŒ€ 3ê°œ\n",
    "        \n",
    "        # ê¸ˆìœµ ê´€ë ¨ í•µì‹¬ ìš©ì–´ë“¤\n",
    "        finance_terms = [\n",
    "            'ê¸ˆìœµ', 'ì€í–‰', 'ì¦ê¶Œ', 'ë³´í—˜', 'ì‹ ìš©', 'ëŒ€ì¶œ', 'ì˜ˆê¸ˆ',\n",
    "            'ì „ìê¸ˆìœµ', 'ê°œì¸ì •ë³´', 'ì•”í˜¸í™”', 'ë³´ì•ˆ', 'ì¸ì¦'\n",
    "        ]\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ì— í¬í•¨ëœ ê¸ˆìœµ ìš©ì–´ ì°¾ê¸°\n",
    "        found_terms = [term for term in finance_terms if term in text]\n",
    "        keywords.extend(found_terms[:2])  # ìµœëŒ€ 2ê°œ\n",
    "        \n",
    "        # ì¤‘ë³µ ì œê±°í•˜ì—¬ ë°˜í™˜\n",
    "        return list(dict.fromkeys(keywords))  # ìˆœì„œ ìœ ì§€í•˜ë©° ì¤‘ë³µ ì œê±°\n",
    "\n",
    "\n",
    "# ì²­í‚¹ í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ”„ ë¬¸ì„œ ì²­í‚¹ í´ë˜ìŠ¤ ìƒì„± ì™„ë£Œ\")\n",
    "chunker = DocumentChunker(chunk_size=300, chunk_overlap=50)\n",
    "print(f\"ì²­í¬ í¬ê¸°: {chunker.chunk_size} í† í°\")\n",
    "print(f\"ì˜¤ë²„ë©: {chunker.chunk_overlap} í† í°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RAG ì‹œìŠ¤í…œ - ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentRetriever:\n",
    "    \"\"\"\n",
    "    RAGì˜ í•µì‹¬ - ë²¡í„° ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ\n",
    "    \n",
    "    íŠ¹ì§•:\n",
    "    - ì„ë² ë”© ëª¨ë¸: jhgan/ko-sbert-nli (í•œêµ­ì–´ íŠ¹í™”)\n",
    "    - ê²€ìƒ‰ ë°©ë²•: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ + BM25 í•˜ì´ë¸Œë¦¬ë“œ\n",
    "    - ìºì‹±: ì¸ë±ìŠ¤ ì €ì¥ìœ¼ë¡œ ë¹ ë¥¸ ì¬ì‹¤í–‰\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, use_cache: bool = True):\n",
    "        \"\"\"\n",
    "        ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€\n",
    "        \"\"\"\n",
    "        self.use_cache = use_cache\n",
    "        self.cache_path = VECTORDB_DIR / \"rag_index.pkl\"\n",
    "        \n",
    "        # ë°ì´í„° ì €ì¥ì†Œ\n",
    "        self.documents = []  # ì›ë³¸ ë¬¸ì„œë“¤\n",
    "        self.chunks = []     # ì²­í‚¹ëœ í…ìŠ¤íŠ¸ë“¤\n",
    "        self.embeddings = None  # ë²¡í„° ì„ë² ë”©\n",
    "        self.embedding_model = None  # ì„ë² ë”© ëª¨ë¸\n",
    "        \n",
    "        # BM25ë¥¼ ìœ„í•œ ì¸ë±ìŠ¤\n",
    "        self.chunk_index = defaultdict(list)  # í‚¤ì›Œë“œ -> ì²­í¬ ì¸ë±ìŠ¤\n",
    "        \n",
    "        # ìºì‹œ í™•ì¸ ë° ë¡œë“œ\n",
    "        if use_cache and self.cache_path.exists():\n",
    "            print(\"ğŸ“‚ ìºì‹œëœ ì¸ë±ìŠ¤ ë°œê²¬...\")\n",
    "            if self._load_cache():\n",
    "                print(\"âœ… ìºì‹œì—ì„œ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!\")\n",
    "                return\n",
    "                \n",
    "        print(\"ğŸ”„ ìƒˆë¡œìš´ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    def build_index(self, documents: List[Dict]):\n",
    "        \"\"\"\n",
    "        ê²€ìƒ‰ ì¸ë±ìŠ¤ êµ¬ì¶•\n",
    "        \n",
    "        ë‹¨ê³„:\n",
    "        1. ë¬¸ì„œ ì²­í‚¹\n",
    "        2. ì„ë² ë”© ìƒì„±\n",
    "        3. BM25 ì¸ë±ìŠ¤ êµ¬ì¶•\n",
    "        4. ìºì‹œ ì €ì¥\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ”¨ ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 1. ë¬¸ì„œ ì €ì¥\n",
    "        self.documents = documents\n",
    "        \n",
    "        # 2. ì²­í‚¹\n",
    "        print(\"ğŸ“„ ë¬¸ì„œ ì²­í‚¹ ì¤‘...\")\n",
    "        chunker = DocumentChunker(chunk_size=300, chunk_overlap=50)\n",
    "        \n",
    "        for doc in tqdm(documents, desc=\"ë¬¸ì„œ ì²˜ë¦¬\"):\n",
    "            doc_chunks = chunker.chunk_document(doc)\n",
    "            \n",
    "            # ê° ì²­í¬ì— ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€\n",
    "            for chunk in doc_chunks:\n",
    "                chunk['source'] = doc['metadata']['source']\n",
    "                chunk['doc_type'] = doc['metadata']['type']\n",
    "            \n",
    "            self.chunks.extend(doc_chunks)\n",
    "        \n",
    "        print(f\"âœ… {len(self.chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ\")\n",
    "        \n",
    "        # 3. ì„ë² ë”© ìƒì„±\n",
    "        self._create_embeddings()\n",
    "        \n",
    "        # 4. BM25 ì¸ë±ìŠ¤ êµ¬ì¶•\n",
    "        self._build_bm25_index()\n",
    "        \n",
    "        # 5. ìºì‹œ ì €ì¥\n",
    "        if self.use_cache:\n",
    "            self._save_cache()\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"\\nâœ… ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ)\")\n",
    "    \n",
    "    def _create_embeddings(self):\n",
    "        \"\"\"\n",
    "        ëª¨ë“  ì²­í¬ì— ëŒ€í•œ ë²¡í„° ì„ë² ë”© ìƒì„±\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            \n",
    "            # í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ì‚¬ìš©\n",
    "            model_name = \"jhgan/ko-sbert-nli\"\n",
    "            print(f\"\\nğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}\")\n",
    "            \n",
    "            self.embedding_model = SentenceTransformer(model_name)\n",
    "            print(\"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "            \n",
    "            # ëª¨ë“  ì²­í¬ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "            texts = [chunk['content'] for chunk in self.chunks]\n",
    "            \n",
    "            # ì„ë² ë”© ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬)\n",
    "            print(f\"ğŸ”„ {len(texts)}ê°œ ì²­í¬ ì„ë² ë”© ì¤‘...\")\n",
    "            self.embeddings = self.embedding_model.encode(\n",
    "                texts,\n",
    "                normalize_embeddings=True,  # ì •ê·œí™”ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ìµœì í™”\n",
    "                show_progress_bar=True,\n",
    "                batch_size=32\n",
    "            )\n",
    "            \n",
    "            print(f\"âœ… ì„ë² ë”© ì™„ë£Œ (ì°¨ì›: {self.embeddings.shape})\")\n",
    "            \n",
    "        except ImportError:\n",
    "            logger.warning(\"sentence-transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            logger.warning(\"BM25 ê²€ìƒ‰ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "            self.embeddings = None\n",
    "    \n",
    "    def _build_bm25_index(self):\n",
    "        \"\"\"\n",
    "        BM25 ê²€ìƒ‰ì„ ìœ„í•œ ì—­ì¸ë±ìŠ¤ êµ¬ì¶•\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ“‘ BM25 ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...\")\n",
    "        \n",
    "        for idx, chunk in enumerate(self.chunks):\n",
    "            content = chunk['content'].lower()\n",
    "            \n",
    "            # ë‹¨ì–´ ì¶”ì¶œ (í•œê¸€, ì˜ì–´, ìˆ«ì)\n",
    "            words = re.findall(r'[ê°€-í£]+|[a-zA-Z]+|\\d+', content)\n",
    "            \n",
    "            # ê° ë‹¨ì–´ì— ëŒ€í•´ ì²­í¬ ì¸ë±ìŠ¤ ì €ì¥\n",
    "            for word in set(words):  # ì¤‘ë³µ ì œê±°\n",
    "                if len(word) >= 2:  # 2ê¸€ì ì´ìƒë§Œ\n",
    "                    self.chunk_index[word].append(idx)\n",
    "            \n",
    "            # í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì¶”ê°€\n",
    "            if 'keywords' in chunk:\n",
    "                for keyword in chunk['keywords']:\n",
    "                    self.chunk_index[keyword.lower()].append(idx)\n",
    "        \n",
    "        print(f\"âœ… BM25 ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(self.chunk_index)}ê°œ í‚¤ì›Œë“œ\")\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 3, method: str = \"hybrid\") -> str:\n",
    "        \"\"\"\n",
    "        ë¬¸ì„œ ê²€ìƒ‰\n",
    "        \n",
    "        Args:\n",
    "            query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "            top_k: ë°˜í™˜í•  ì²­í¬ ìˆ˜\n",
    "            method: ê²€ìƒ‰ ë°©ë²• (\"similarity\", \"bm25\", \"hybrid\")\n",
    "            \n",
    "        Returns:\n",
    "            ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´\n",
    "        \"\"\"\n",
    "        if not self.chunks:\n",
    "            return \"\"\n",
    "        \n",
    "        # ê²€ìƒ‰ ë°©ë²•ë³„ ì²˜ë¦¬\n",
    "        if method == \"similarity\" and self.embeddings is not None:\n",
    "            results = self._similarity_search(query, top_k * 2)\n",
    "        elif method == \"bm25\":\n",
    "            results = self._bm25_search(query, top_k * 2)\n",
    "        elif method == \"hybrid\" and self.embeddings is not None:\n",
    "            results = self._hybrid_search(query, top_k * 2)\n",
    "        else:\n",
    "            # í´ë°±: BM25 ì‚¬ìš©\n",
    "            results = self._bm25_search(query, top_k * 2)\n",
    "        \n",
    "        # ìƒìœ„ kê°œ ì„ íƒ ë° ì¤‘ë³µ ì œê±°\n",
    "        seen_content = set()\n",
    "        final_results = []\n",
    "        \n",
    "        for chunk_idx, score in results[:top_k*2]:\n",
    "            chunk = self.chunks[chunk_idx]\n",
    "            content_hash = hash(chunk['content'][:100])  # ì•ë¶€ë¶„ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬\n",
    "            \n",
    "            if content_hash not in seen_content:\n",
    "                seen_content.add(content_hash)\n",
    "                final_results.append((chunk, score))\n",
    "                \n",
    "                if len(final_results) >= top_k:\n",
    "                    break\n",
    "        \n",
    "        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±\n",
    "        contexts = []\n",
    "        for chunk, score in final_results:\n",
    "            source = chunk.get('source', 'Unknown')\n",
    "            content = chunk['content']\n",
    "            \n",
    "            # ì†ŒìŠ¤ ì •ë³´ í¬í•¨\n",
    "            context = f\"[ì¶œì²˜: {source}]\\n{content}\"\n",
    "            contexts.append(context)\n",
    "        \n",
    "        return \"\\n\\n---\\n\\n\".join(contexts)\n",
    "    \n",
    "    def _similarity_search(self, query: str, top_k: int) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "        \"\"\"\n",
    "        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±\n",
    "        query_embedding = self.embedding_model.encode(\n",
    "            [query],\n",
    "            normalize_embeddings=True\n",
    "        )\n",
    "        \n",
    "        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ì •ê·œí™”ëœ ë²¡í„°ì´ë¯€ë¡œ ë‚´ì ì´ ì½”ì‚¬ì¸ ìœ ì‚¬ë„)\n",
    "        similarities = np.dot(self.embeddings, query_embedding.T).flatten()\n",
    "        \n",
    "        # ìƒìœ„ kê°œ ì¸ë±ìŠ¤\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "        \n",
    "        # (ì¸ë±ìŠ¤, ì ìˆ˜) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "        results = [(int(idx), float(similarities[idx])) for idx in top_indices]\n",
    "        return results\n",
    "    \n",
    "    def _bm25_search(self, query: str, top_k: int) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        BM25 ê¸°ë°˜ í‚¤ì›Œë“œ ê²€ìƒ‰\n",
    "        \"\"\"\n",
    "        query_lower = query.lower()\n",
    "        query_words = re.findall(r'[ê°€-í£]+|[a-zA-Z]+|\\d+', query_lower)\n",
    "        \n",
    "        # BM25 íŒŒë¼ë¯¸í„°\n",
    "        k1 = 1.2  # ë‹¨ì–´ ë¹ˆë„ í¬í™”ë„\n",
    "        b = 0.75  # ë¬¸ì„œ ê¸¸ì´ ì •ê·œí™”\n",
    "        \n",
    "        # í‰ê·  ë¬¸ì„œ ê¸¸ì´\n",
    "        avg_len = np.mean([len(chunk['content']) for chunk in self.chunks])\n",
    "        \n",
    "        # ê° ì²­í¬ì— ëŒ€í•œ ì ìˆ˜ ê³„ì‚°\n",
    "        scores = defaultdict(float)\n",
    "        \n",
    "        for word in query_words:\n",
    "            if word in self.chunk_index:\n",
    "                # IDF ê³„ì‚°\n",
    "                df = len(self.chunk_index[word])  # ë¬¸ì„œ ë¹ˆë„\n",
    "                idf = np.log((len(self.chunks) - df + 0.5) / (df + 0.5) + 1)\n",
    "                \n",
    "                # ê° ë¬¸ì„œì— ëŒ€í•œ BM25 ì ìˆ˜\n",
    "                for chunk_idx in self.chunk_index[word]:\n",
    "                    chunk = self.chunks[chunk_idx]\n",
    "                    tf = chunk['content'].lower().count(word)  # ë‹¨ì–´ ë¹ˆë„\n",
    "                    doc_len = len(chunk['content'])\n",
    "                    \n",
    "                    # BM25 ì ìˆ˜ ê³„ì‚°\n",
    "                    score = idf * (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * doc_len / avg_len))\n",
    "                    scores[chunk_idx] += score\n",
    "        \n",
    "        # ì ìˆ˜ìˆœ ì •ë ¬\n",
    "        sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_scores[:top_k]\n",
    "    \n",
    "    def _hybrid_search(self, query: str, top_k: int) -> List[Tuple[int, float]]:\n",
    "        \"\"\"\n",
    "        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ìœ ì‚¬ë„ + BM25)\n",
    "        \"\"\"\n",
    "        # ê°ê°ì˜ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "        similarity_results = self._similarity_search(query, top_k)\n",
    "        bm25_results = self._bm25_search(query, top_k)\n",
    "        \n",
    "        # ì ìˆ˜ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
    "        similarity_scores = {idx: score for idx, score in similarity_results}\n",
    "        bm25_scores = {idx: score for idx, score in bm25_results}\n",
    "        \n",
    "        # ëª¨ë“  ê³ ìœ  ì¸ë±ìŠ¤\n",
    "        all_indices = set(similarity_scores.keys()) | set(bm25_scores.keys())\n",
    "        \n",
    "        # ì ìˆ˜ ì •ê·œí™” ë° ê²°í•©\n",
    "        hybrid_scores = {}\n",
    "        \n",
    "        # ìµœëŒ€ê°’ìœ¼ë¡œ ì •ê·œí™”\n",
    "        max_sim = max(similarity_scores.values()) if similarity_scores else 1\n",
    "        max_bm25 = max(bm25_scores.values()) if bm25_scores else 1\n",
    "        \n",
    "        for idx in all_indices:\n",
    "            # ì •ê·œí™”ëœ ì ìˆ˜ (ì—†ìœ¼ë©´ 0)\n",
    "            norm_sim = similarity_scores.get(idx, 0) / max_sim\n",
    "            norm_bm25 = bm25_scores.get(idx, 0) / max_bm25\n",
    "            \n",
    "            # ê°€ì¤‘ í‰ê·  (ìœ ì‚¬ë„ 0.7, BM25 0.3)\n",
    "            hybrid_scores[idx] = 0.7 * norm_sim + 0.3 * norm_bm25\n",
    "        \n",
    "        # ì •ë ¬\n",
    "        sorted_scores = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_scores[:top_k]\n",
    "    \n",
    "    def get_random_chunks(self, n: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        ëœë¤ ì²­í¬ ê°€ì ¸ì˜¤ê¸° (ë°ì´í„° ìƒì„±ì‹œ ë‹¤ì–‘ì„± í™•ë³´ìš©)\n",
    "        \"\"\"\n",
    "        if not self.chunks:\n",
    "            return \"\"\n",
    "        \n",
    "        # ëœë¤í•˜ê²Œ nê°œ ì²­í¬ ì„ íƒ\n",
    "        selected_chunks = random.sample(self.chunks, min(n, len(self.chunks)))\n",
    "        \n",
    "        contexts = []\n",
    "        for chunk in selected_chunks:\n",
    "            source = chunk.get('source', 'Unknown')\n",
    "            content = chunk['content']\n",
    "            context = f\"[ì¶œì²˜: {source}]\\n{content}\"\n",
    "            contexts.append(context)\n",
    "        \n",
    "        return \"\\n\\n---\\n\\n\".join(contexts)\n",
    "    \n",
    "    def get_statistics(self) -> Dict:\n",
    "        \"\"\"\n",
    "        í†µê³„ ì •ë³´ ë°˜í™˜\n",
    "        \"\"\"\n",
    "        stats = {\n",
    "            'total_documents': len(self.documents),\n",
    "            'total_chunks': len(self.chunks),\n",
    "            'total_keywords': len(self.chunk_index),\n",
    "            'avg_chunk_size': np.mean([chunk.get('tokens', 0) for chunk in self.chunks]) if self.chunks else 0,\n",
    "            'has_embeddings': self.embeddings is not None\n",
    "        }\n",
    "        \n",
    "        # ë¬¸ì„œ íƒ€ì…ë³„ í†µê³„\n",
    "        if self.chunks:\n",
    "            doc_types = Counter(chunk.get('doc_type', 'Unknown') for chunk in self.chunks)\n",
    "            stats['document_types'] = dict(doc_types)\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def _save_cache(self):\n",
    "        \"\"\"\n",
    "        ì¸ë±ìŠ¤ë¥¼ ìºì‹œ íŒŒì¼ë¡œ ì €ì¥\n",
    "        \"\"\"\n",
    "        print(\"\\nğŸ’¾ ì¸ë±ìŠ¤ ìºì‹œ ì €ì¥ ì¤‘...\")\n",
    "        \n",
    "        cache_data = {\n",
    "            'chunks': self.chunks,\n",
    "            'chunk_index': dict(self.chunk_index),\n",
    "            'embeddings': self.embeddings,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(self.cache_path, 'wb') as f:\n",
    "            pickle.dump(cache_data, f)\n",
    "        \n",
    "        print(f\"âœ… ìºì‹œ ì €ì¥ ì™„ë£Œ: {self.cache_path}\")\n",
    "    \n",
    "    def _load_cache(self) -> bool:\n",
    "        \"\"\"\n",
    "        ìºì‹œ íŒŒì¼ì—ì„œ ì¸ë±ìŠ¤ ë¡œë“œ\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(self.cache_path, 'rb') as f:\n",
    "                cache_data = pickle.load(f)\n",
    "            \n",
    "            self.chunks = cache_data['chunks']\n",
    "            self.chunk_index = defaultdict(list, cache_data['chunk_index'])\n",
    "            self.embeddings = cache_data['embeddings']\n",
    "            \n",
    "            print(f\"ğŸ“… ìºì‹œ ìƒì„± ì‹œê°„: {cache_data.get('timestamp', 'Unknown')}\")\n",
    "            print(f\"ğŸ“Š ë¡œë“œëœ ì²­í¬ ìˆ˜: {len(self.chunks)}\")\n",
    "            \n",
    "            # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (í•„ìš”ì‹œ)\n",
    "            if self.embeddings is not None:\n",
    "                from sentence_transformers import SentenceTransformer\n",
    "                self.embedding_model = SentenceTransformer(\"jhgan/ko-sbert-nli\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "# ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ”„ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ í´ë˜ìŠ¤ ìƒì„± ì™„ë£Œ\")\n",
    "print(\"ì§€ì› ê²€ìƒ‰ ë°©ë²•: similarity (ë²¡í„°), bm25 (í‚¤ì›Œë“œ), hybrid (ê²°í•©)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. RAG ì‹œìŠ¤í…œ í†µí•© í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSystem:\n",
    "    \"\"\"\n",
    "    RAG ì»´í¬ë„ŒíŠ¸ í†µí•© ê´€ë¦¬ í´ë˜ìŠ¤\n",
    "    \n",
    "    ì£¼ìš” ê¸°ëŠ¥:\n",
    "    - ë¬¸ì„œ ë¡œë“œ â†’ ì²­í‚¹ â†’ ì¸ë±ì‹± â†’ ê²€ìƒ‰\n",
    "    - ìºì‹œ ê´€ë¦¬ë¡œ ë¹ ë¥¸ ì¬ì‹¤í–‰\n",
    "    - í†µí•© ì¸í„°í˜ì´ìŠ¤ ì œê³µ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”\"\"\"\n",
    "        self.loader = DocumentLoader()\n",
    "        self.chunker = DocumentChunker()\n",
    "        self.retriever = DocumentRetriever()\n",
    "        self.is_initialized = False\n",
    "        \n",
    "    def initialize(self, data_dir: Path, force_rebuild: bool = False):\n",
    "        \"\"\"\n",
    "        RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "        \n",
    "        Args:\n",
    "            data_dir: ë¬¸ì„œê°€ ìˆëŠ” ë””ë ‰í† ë¦¬\n",
    "            force_rebuild: ìºì‹œ ë¬´ì‹œí•˜ê³  ì¬êµ¬ì¶•\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # ìºì‹œ í™•ì¸\n",
    "        cache_exists = (VECTORDB_DIR / \"rag_index.pkl\").exists()\n",
    "        \n",
    "        if cache_exists and not force_rebuild:\n",
    "            # ìºì‹œê°€ ìˆìœ¼ë©´ ë¡œë“œ ì‹œë„\n",
    "            if self.retriever.chunks:  # ì´ë¯¸ ë¡œë“œë¨\n",
    "                print(\"âœ… RAG ì‹œìŠ¤í…œì´ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "                self.is_initialized = True\n",
    "                return\n",
    "        \n",
    "        # ìƒˆë¡œ êµ¬ì¶•ì´ í•„ìš”í•œ ê²½ìš°\n",
    "        if force_rebuild:\n",
    "            print(\"ğŸ”„ ê°•ì œ ì¬êµ¬ì¶• ëª¨ë“œ\")\n",
    "        \n",
    "        # 1. ë¬¸ì„œ ë¡œë“œ\n",
    "        print(\"\\n[1/3] ë¬¸ì„œ ë¡œë“œ ì¤‘...\")\n",
    "        documents = self.loader.load_directory(data_dir)\n",
    "        \n",
    "        if not documents:\n",
    "            print(\"âš ï¸ ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "            print(f\"   {data_dir} ë””ë ‰í† ë¦¬ì— PDF, TXT, Excel íŒŒì¼ì„ ì¶”ê°€í•˜ì„¸ìš”.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nğŸ“š ì´ {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\")\n",
    "        \n",
    "        # 2. ì¸ë±ìŠ¤ êµ¬ì¶•\n",
    "        print(\"\\n[2/3] ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...\")\n",
    "        self.retriever.build_index(documents)\n",
    "        \n",
    "        # 3. í†µê³„ ì¶œë ¥\n",
    "        print(\"\\n[3/3] ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "        stats = self.retriever.get_statistics()\n",
    "        self._print_statistics(stats)\n",
    "        \n",
    "        self.is_initialized = True\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 3, method: str = \"hybrid\") -> str:\n",
    "        \"\"\"\n",
    "        ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰\n",
    "        \n",
    "        Args:\n",
    "            query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "            top_k: ë°˜í™˜í•  ì²­í¬ ìˆ˜\n",
    "            method: ê²€ìƒ‰ ë°©ë²•\n",
    "            \n",
    "        Returns:\n",
    "            ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        if not self.is_initialized:\n",
    "            logger.warning(\"RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            return \"\"\n",
    "        \n",
    "        return self.retriever.search(query, top_k, method)\n",
    "    \n",
    "    def get_random_context(self, n: int = 2) -> str:\n",
    "        \"\"\"\n",
    "        ëœë¤ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "        \n",
    "        Args:\n",
    "            n: ê°€ì ¸ì˜¬ ì²­í¬ ìˆ˜\n",
    "            \n",
    "        Returns:\n",
    "            ëœë¤ ì»¨í…ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        if not self.is_initialized:\n",
    "            logger.warning(\"RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            return \"\"\n",
    "        \n",
    "        return self.retriever.get_random_chunks(n)\n",
    "    \n",
    "    def _print_statistics(self, stats: Dict):\n",
    "        \"\"\"\n",
    "        í†µê³„ ì •ë³´ ì¶œë ¥\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"ğŸ“Š RAG ì‹œìŠ¤í…œ í†µê³„\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"ë¬¸ì„œ ìˆ˜: {stats['total_documents']}ê°œ\")\n",
    "        print(f\"ì²­í¬ ìˆ˜: {stats['total_chunks']}ê°œ\")\n",
    "        print(f\"ì¸ë±ì‹±ëœ í‚¤ì›Œë“œ: {stats['total_keywords']}ê°œ\")\n",
    "        print(f\"í‰ê·  ì²­í¬ í¬ê¸°: {stats['avg_chunk_size']:.1f} í† í°\")\n",
    "        print(f\"ë²¡í„° ì„ë² ë”©: {'í™œì„±í™”' if stats['has_embeddings'] else 'ë¹„í™œì„±í™”'}\")\n",
    "        \n",
    "        if 'document_types' in stats:\n",
    "            print(\"\\në¬¸ì„œ íƒ€ì…ë³„ ë¶„í¬:\")\n",
    "            for doc_type, count in stats['document_types'].items():\n",
    "                print(f\"  - {doc_type}: {count}ê°œ\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    def rebuild_index(self, data_dir: Path):\n",
    "        \"\"\"\n",
    "        ì¸ë±ìŠ¤ ì¬êµ¬ì¶•\n",
    "        \"\"\"\n",
    "        print(\"ğŸ”„ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹œì‘...\")\n",
    "        self.initialize(data_dir, force_rebuild=True)\n",
    "    \n",
    "    def test_search(self, test_queries: List[str] = None):\n",
    "        \"\"\"\n",
    "        ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        if not self.is_initialized:\n",
    "            print(\"âš ï¸ RAG ì‹œìŠ¤í…œì„ ë¨¼ì € ì´ˆê¸°í™”í•˜ì„¸ìš”.\")\n",
    "            return\n",
    "        \n",
    "        # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬\n",
    "        if test_queries is None:\n",
    "            test_queries = [\n",
    "                \"ì „ìê¸ˆìœµê±°ë˜\",\n",
    "                \"ê°œì¸ì •ë³´ë³´í˜¸\",\n",
    "                \"ì•”í˜¸í™” ê¸°ìˆ \",\n",
    "                \"ê¸ˆìœµë³´ì•ˆ\"\n",
    "            ]\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"ğŸ” RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for query in test_queries:\n",
    "            print(f\"\\nğŸ“Œ ê²€ìƒ‰ì–´: '{query}'\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\n",
    "            result = self.search(query, top_k=2, method=\"hybrid\")\n",
    "            \n",
    "            if result:\n",
    "                # ê²°ê³¼ë¥¼ 200ìë¡œ ì œí•œí•˜ì—¬ ì¶œë ¥\n",
    "                preview = result[:200] + \"...\" if len(result) > 200 else result\n",
    "                print(preview)\n",
    "            else:\n",
    "                print(\"ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "# RAG ì‹œìŠ¤í…œ ìƒì„±\n",
    "print(\"âœ… RAG ì‹œìŠ¤í…œ í†µí•© í´ë˜ìŠ¤ ìƒì„± ì™„ë£Œ\")\n",
    "rag_system = RAGSystem()\n",
    "print(\"\\nRAG ì‹œìŠ¤í…œ ì‚¬ìš© ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ì„¸ìš”:\")\n",
    "print(\"  rag_system.initialize(EXTERNAL_DIR)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "# ì£¼ì˜: ì™¸ë¶€ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\n",
    "\n",
    "# ì™¸ë¶€ ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "print(\"ğŸ“ ì™¸ë¶€ ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸...\")\n",
    "print(f\"ê²½ë¡œ: {EXTERNAL_DIR}\")\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ ëª©ë¡ í™•ì¸\n",
    "if EXTERNAL_DIR.exists():\n",
    "    files = list(EXTERNAL_DIR.glob(\"*\"))\n",
    "    if files:\n",
    "        print(f\"\\në°œê²¬ëœ íŒŒì¼ ({len(files)}ê°œ):\")\n",
    "        for file in files[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ\n",
    "            print(f\"  - {file.name}\")\n",
    "        if len(files) > 10:\n",
    "            print(f\"  ... ì™¸ {len(files)-10}ê°œ\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ ë””ë ‰í† ë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!\")\n",
    "        print(\"PDF, TXT, Excel í˜•ì‹ì˜ ê¸ˆìœµ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"\\nâŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\")\n",
    "    EXTERNAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âœ… ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ: {EXTERNAL_DIR}\")\n",
    "\n",
    "# RAG ì´ˆê¸°í™” ì‹¤í–‰\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "choice = input(\"RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \")\n",
    "\n",
    "if choice.lower() == 'y':\n",
    "    # ì´ˆê¸°í™” ì‹¤í–‰\n",
    "    rag_system.initialize(EXTERNAL_DIR)\n",
    "    \n",
    "    # ì´ˆê¸°í™” ì„±ê³µì‹œ í…ŒìŠ¤íŠ¸\n",
    "    if rag_system.is_initialized:\n",
    "        print(\"\\nâœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì„±ê³µ!\")\n",
    "        \n",
    "        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸\n",
    "        test_choice = input(\"\\nê²€ìƒ‰ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \")\n",
    "        if test_choice.lower() == 'y':\n",
    "            rag_system.test_search()\n",
    "else:\n",
    "    print(\"\\nì´ˆê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "    print(\"ë‚˜ì¤‘ì— ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì´ˆê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\")\n",
    "    print(\"  rag_system.initialize(EXTERNAL_DIR)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. RAG ê²€ìƒ‰ ì˜ˆì œ ë° í™œìš©ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG ê²€ìƒ‰ í™œìš© ì˜ˆì œ\n",
    "\n",
    "if rag_system.is_initialized:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ“š RAG ê²€ìƒ‰ í™œìš© ì˜ˆì œ\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. íŠ¹ì • ì£¼ì œ ê²€ìƒ‰\n",
    "    print(\"\\n1ï¸âƒ£ íŠ¹ì • ì£¼ì œ ê²€ìƒ‰\")\n",
    "    query = \"ê°œì¸ì •ë³´ë³´í˜¸ë²•\"\n",
    "    result = rag_system.search(query, top_k=2)\n",
    "    print(f\"ê²€ìƒ‰ì–´: '{query}'\")\n",
    "    print(f\"ê²°ê³¼:\\n{result[:300]}...\\n\")\n",
    "    \n",
    "    # 2. ë‹¤ì–‘í•œ ê²€ìƒ‰ ë°©ë²• ë¹„êµ\n",
    "    print(\"\\n2ï¸âƒ£ ê²€ìƒ‰ ë°©ë²• ë¹„êµ\")\n",
    "    query = \"ì•”í˜¸í™”\"\n",
    "    \n",
    "    # BM25 ê²€ìƒ‰\n",
    "    bm25_result = rag_system.search(query, top_k=1, method=\"bm25\")\n",
    "    print(f\"BM25 ê²€ìƒ‰ ê²°ê³¼ ê¸¸ì´: {len(bm25_result)}ì\")\n",
    "    \n",
    "    # ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "    if rag_system.retriever.embeddings is not None:\n",
    "        sim_result = rag_system.search(query, top_k=1, method=\"similarity\")\n",
    "        print(f\"ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ ê¸¸ì´: {len(sim_result)}ì\")\n",
    "    \n",
    "    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\n",
    "    hybrid_result = rag_system.search(query, top_k=1, method=\"hybrid\")\n",
    "    print(f\"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ ê¸¸ì´: {len(hybrid_result)}ì\")\n",
    "    \n",
    "    # 3. ëœë¤ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "    print(\"\\n3ï¸âƒ£ ëœë¤ ì»¨í…ìŠ¤íŠ¸ (ë°ì´í„° ìƒì„±ìš©)\")\n",
    "    random_context = rag_system.get_random_context(n=2)\n",
    "    print(f\"ëœë¤ ì»¨í…ìŠ¤íŠ¸:\\n{random_context[:300]}...\\n\")\n",
    "    \n",
    "    # 4. ë³µí•© ì¿¼ë¦¬ ì˜ˆì œ\n",
    "    print(\"\\n4ï¸âƒ£ ë³µí•© ì¿¼ë¦¬ ì˜ˆì œ\")\n",
    "    complex_query = \"ì „ìê¸ˆìœµê±°ë˜ ë³´ì•ˆ ì¸ì¦\"\n",
    "    result = rag_system.search(complex_query, top_k=3)\n",
    "    print(f\"ë³µí•© ê²€ìƒ‰ì–´: '{complex_query}'\")\n",
    "    print(f\"ê²€ìƒ‰ëœ ì²­í¬ ìˆ˜: {len(result.split('---'))}ê°œ\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ë¨¼ì € ìœ„ì˜ ì…€ì—ì„œ RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. RAG ëª¨ë“ˆ ì €ì¥ (ì¶”ë¡ ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶”ë¡ ì—ì„œë„ ì‚¬ìš©í•  RAG ëª¨ë“ˆì„ ë³„ë„ íŒŒì¼ë¡œ ì €ì¥\n",
    "# ì´ë ‡ê²Œ í•˜ë©´ ì¶”ë¡  ë…¸íŠ¸ë¶ì—ì„œë„ ë™ì¼í•œ RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "rag_module_content = '''\n",
    "\"\"\"\n",
    "RAG ëª¨ë“ˆ (ê²½ëŸ‰í™” ë²„ì „)\n",
    "ì¶”ë¡  ì‹œì—ë„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìµœì†Œí•œì˜ RAG ê¸°ëŠ¥ë§Œ í¬í•¨\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class LightweightRAG:\n",
    "    \"\"\"ì¶”ë¡ ìš© ê²½ëŸ‰ RAG ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    def __init__(self, index_path: str):\n",
    "        \"\"\"ì‚¬ì „ êµ¬ì¶•ëœ ì¸ë±ìŠ¤ ë¡œë“œ\"\"\"\n",
    "        self.index_path = Path(index_path)\n",
    "        self.chunks = []\n",
    "        self.chunk_index = defaultdict(list)\n",
    "        self.embeddings = None\n",
    "        self._load_index()\n",
    "    \n",
    "    def _load_index(self):\n",
    "        \"\"\"ì¸ë±ìŠ¤ ë¡œë“œ\"\"\"\n",
    "        if not self.index_path.exists():\n",
    "            raise FileNotFoundError(f\"ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.index_path}\")\n",
    "        \n",
    "        with open(self.index_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        self.chunks = data['chunks']\n",
    "        self.chunk_index = defaultdict(list, data['chunk_index'])\n",
    "        self.embeddings = data.get('embeddings')\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 3) -> str:\n",
    "        \"\"\"BM25 ê¸°ë°˜ ê²€ìƒ‰ (ì„ë² ë”© ë¶ˆí•„ìš”)\"\"\"\n",
    "        query_words = re.findall(r'[ê°€-í£]+|[a-zA-Z]+|\\\\d+', query.lower())\n",
    "        \n",
    "        # BM25 ì ìˆ˜ ê³„ì‚°\n",
    "        scores = defaultdict(float)\n",
    "        for word in query_words:\n",
    "            if word in self.chunk_index:\n",
    "                for idx in self.chunk_index[word]:\n",
    "                    scores[idx] += 1.0\n",
    "        \n",
    "        # ìƒìœ„ kê°œ ì„ íƒ\n",
    "        top_indices = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        \n",
    "        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±\n",
    "        contexts = []\n",
    "        for idx, _ in top_indices:\n",
    "            chunk = self.chunks[idx]\n",
    "            context = f\"[ì¶œì²˜: {chunk.get('source', 'Unknown')}]\\\\n{chunk['content']}\"\n",
    "            contexts.append(context)\n",
    "        \n",
    "        return \"\\\\n\\\\n---\\\\n\\\\n\".join(contexts)\n",
    "'''\n",
    "\n",
    "# íŒŒì¼ ì €ì¥\n",
    "rag_module_path = PROJECT_ROOT / \"rag_module.py\"\n",
    "with open(rag_module_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(rag_module_content)\n",
    "\n",
    "print(\"âœ… RAG ëª¨ë“ˆ ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\"ì €ì¥ ìœ„ì¹˜: {rag_module_path}\")\n",
    "print(\"\\nì´ íŒŒì¼ì„ ì¶”ë¡  ë…¸íŠ¸ë¶ì—ì„œ importí•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\")\n",
    "print(\"  from rag_module import LightweightRAG\")\n",
    "print(\"  rag = LightweightRAG('data/vectordb/rag_index.pkl')\")\n",
    "print(\"  context = rag.search('ê²€ìƒ‰ì–´')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ”¥ Stage 2: ë°ì´í„° ìƒì„± ë° í’ˆì§ˆ ê´€ë¦¬\n\n### 11. í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ\n\nFSKU í‰ê°€ ê¸°ì¤€ì— ë§ì¶˜ ë‹¤ì°¨ì› í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "source": "class QualityEvaluator:\n    \"\"\"\n    FSKU ê¸°ì¤€ì— ë§ì¶˜ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ\n    \n    í‰ê°€ ì°¨ì›:\n    1. í˜•ì‹ (Format): ë¬¸ì œ êµ¬ì¡°, ì„ íƒì§€ í˜•ì‹\n    2. ë‚´ìš© (Content): ê¸ˆìœµ ê´€ë ¨ì„±, ì •í™•ì„±\n    3. ë‚œì´ë„ (Difficulty): ì ì ˆí•œ ë‚œì´ë„\n    4. ëª…í™•ì„± (Clarity): ëª¨í˜¸í•˜ì§€ ì•Šì€ í‘œí˜„\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\"\"\"\n        # í‰ê°€ ê°€ì¤‘ì¹˜ ì„¤ì •\n        self.weights = {\n            'format': 0.25,      # í˜•ì‹ ì ì ˆì„±\n            'content': 0.35,     # ë‚´ìš© í’ˆì§ˆ\n            'difficulty': 0.20,  # ë‚œì´ë„ ì ì ˆì„±\n            'clarity': 0.20      # ëª…í™•ì„±\n        }\n        \n        # í†µê³„ ì •ë³´\n        self.evaluation_stats = {\n            'total_evaluated': 0,\n            'passed': 0,\n            'failed': 0,\n            'avg_score': 0,\n            'score_distribution': defaultdict(int)\n        }\n        \n        # ê¸ˆìœµ í‚¤ì›Œë“œ (ê¸°ì¡´ í’ˆì§ˆ í‰ê°€ ëª¨ë“ˆì—ì„œ ê°€ì ¸ì˜´)\n        self.finance_keywords = [\n            'ê¸ˆìœµ', 'ì€í–‰', 'ì¦ê¶Œ', 'ë³´í—˜', 'ì˜ˆê¸ˆ', 'ëŒ€ì¶œ', 'íˆ¬ì',\n            'ì „ìê¸ˆìœµ', 'í•€í…Œí¬', 'ë¸”ë¡ì²´ì¸', 'ì•”í˜¸í™”í', 'ë””ì§€í„¸ìì‚°',\n            'ì‹ ìš©', 'ë¦¬ìŠ¤í¬', 'ê·œì œ', 'ê°ë…', 'ì¤€ë²•', 'ê°œì¸ì •ë³´',\n            'KYC', 'AML', 'ìê¸ˆì„¸íƒ', 'ë³´ì•ˆ', 'ì¸ì¦', 'ë³¸ì¸í™•ì¸'\n        ]\n        \n        # ëª¨í˜¸í•œ í‘œí˜„ë“¤\n        self.ambiguous_terms = [\n            'ëŒ€ëµ', 'ì•„ë§ˆ', 'ì–´ëŠì •ë„', 'ì¼ë¶€', 'ëª‡ëª‡', 'ì•½ê°„',\n            'ê°€ëŠ¥í•œ', 'ì¼ë°˜ì ìœ¼ë¡œ', 'ë³´í†µ', 'ëŒ€ì²´ë¡œ', 'ì¢…ì¢…'\n        ]\n        \n        # FSKU ë¬¸ì œ ìœ í˜• íŒ¨í„´\n        self.question_patterns = {\n            'ê°ê´€ì‹': {\n                'markers': ['ë‹¤ìŒ ì¤‘', 'ì˜¬ë°”ë¥¸ ê²ƒì€', 'ë§ëŠ” ê²ƒì€', 'í‹€ë¦° ê²ƒì€', 'í•´ë‹¹í•˜ëŠ” ê²ƒì€'],\n                'options': [r'[1-5]\\)', r'[ê°€-ë§ˆ]\\)', r'[A-E]\\)', r'â‘ â‘¡â‘¢â‘£â‘¤']\n            },\n            'ì£¼ê´€ì‹': {\n                'markers': ['ì„¤ëª…í•˜ì‹œì˜¤', 'ì„œìˆ í•˜ì‹œì˜¤', 'ë¬´ì—‡ì¸ê°€', 'ì •ì˜í•˜ì‹œì˜¤', 'ë¹„êµí•˜ì‹œì˜¤'],\n                'requirements': ['ì´ìœ ', 'ê·¼ê±°', 'ì˜ˆì‹œ', 'íŠ¹ì§•']\n            },\n            'ê³„ì‚°': {\n                'markers': ['ê³„ì‚°í•˜ì‹œì˜¤', 'ì‚°ì¶œí•˜ì‹œì˜¤', 'êµ¬í•˜ì‹œì˜¤', 'ê°’ì€'],\n                'units': ['%', 'ì›', 'ë‹¬ëŸ¬', 'ë°°', 'ë¹„ìœ¨']\n            }\n        }\n    \n    def evaluate(self, question: str, answer: str) -> Dict[str, Any]:\n        \"\"\"\n        ë¬¸ì œ-ë‹µë³€ ìŒ í‰ê°€\n        \n        Args:\n            question: ìƒì„±ëœ ë¬¸ì œ\n            answer: ìƒì„±ëœ ë‹µë³€\n            \n        Returns:\n            í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬\n        \"\"\"\n        # ê° ì°¨ì›ë³„ í‰ê°€\n        scores = {\n            'format': self._evaluate_format(question, answer),\n            'content': self._evaluate_content(question, answer),\n            'difficulty': self._evaluate_difficulty(question, answer),\n            'clarity': self._evaluate_clarity(question, answer)\n        }\n        \n        # ê°€ì¤‘ í‰ê·  ê³„ì‚°\n        total_score = sum(\n            scores[dim] * self.weights[dim] \n            for dim in scores\n        )\n        \n        # ë¬¸ì œ ìœ í˜• íŒë³„\n        question_type = self._identify_question_type(question)\n        \n        # ì„¸ë¶€ ë¶„ì„\n        analysis = {\n            'question_type': question_type,\n            'has_options': self._has_options(question),\n            'keyword_count': self._count_keywords(question + answer),\n            'length': len(question) + len(answer),\n            'ambiguity_count': self._count_ambiguous_terms(question + answer)\n        }\n        \n        # í†µê³„ ì—…ë°ì´íŠ¸\n        self._update_stats(total_score)\n        \n        # ê²°ê³¼ ë°˜í™˜\n        return {\n            'total_score': round(total_score, 1),\n            'dimension_scores': scores,\n            'passed': total_score >= 70,\n            'analysis': analysis,\n            'feedback': self._generate_feedback(scores, analysis)\n        }\n    \n    def _evaluate_format(self, question: str, answer: str) -> float:\n        \"\"\"\n        í˜•ì‹ í‰ê°€\n        - ë¬¸ì œ êµ¬ì¡°ì˜ ì ì ˆì„±\n        - ì„ íƒì§€ í˜•ì‹ (ê°ê´€ì‹ì˜ ê²½ìš°)\n        - ì§ˆë¬¸ ëª…í™•ì„±\n        \"\"\"\n        score = 50  # ê¸°ë³¸ ì ìˆ˜\n        \n        # ì§ˆë¬¸ ë§ˆí¬ í™•ì¸\n        if '?' in question or any(end in question for end in ['ëŠ”ê°€', 'ê¹Œ', 'ì¸ê°€']):\n            score += 10\n        \n        # ë¬¸ì œ ìœ í˜•ë³„ í˜•ì‹ ì²´í¬\n        question_type = self._identify_question_type(question)\n        \n        if question_type == 'ê°ê´€ì‹':\n            # ì„ íƒì§€ ì²´í¬\n            if self._has_proper_options(question):\n                score += 20\n            # ì„ íƒì§€ ê°œìˆ˜ ì²´í¬ (4-5ê°œê°€ ì´ìƒì )\n            option_count = self._count_options(question)\n            if 4 <= option_count <= 5:\n                score += 10\n        elif question_type == 'ì£¼ê´€ì‹':\n            # ëª…í™•í•œ ì§€ì‹œì‚¬í•­ ì²´í¬\n            if any(marker in question for marker in self.question_patterns['ì£¼ê´€ì‹']['markers']):\n                score += 20\n        elif question_type == 'ê³„ì‚°':\n            # ë‹¨ìœ„ ëª…ì‹œ ì²´í¬\n            if any(unit in question or unit in answer for unit in self.question_patterns['ê³„ì‚°']['units']):\n                score += 15\n        \n        # êµ¬ì¡°í™” ì²´í¬ (ì¤„ë°”ê¿ˆ ì‚¬ìš©)\n        if '\\n' in question and question.count('\\n') >= 2:\n            score += 10\n        \n        return min(100, score)\n    \n    def _evaluate_content(self, question: str, answer: str) -> float:\n        \"\"\"\n        ë‚´ìš© í‰ê°€\n        - ê¸ˆìœµ ê´€ë ¨ì„±\n        - ì •í™•ì„± (ë‹µë³€ì˜ ì ì ˆì„±)\n        - ì „ë¬¸ì„±\n        \"\"\"\n        score = 40  # ê¸°ë³¸ ì ìˆ˜\n        text = question + ' ' + answer\n        \n        # ê¸ˆìœµ í‚¤ì›Œë“œ í¬í•¨ë„\n        keyword_count = self._count_keywords(text)\n        if keyword_count >= 3:\n            score += 30\n        elif keyword_count >= 2:\n            score += 20\n        elif keyword_count >= 1:\n            score += 10\n        \n        # ì „ë¬¸ ìš©ì–´ ì‚¬ìš© (ì˜ë¬¸ ì•½ì–´ ë“±)\n        professional_terms = re.findall(r'[A-Z]{2,}', text)\n        if professional_terms:\n            score += 10\n        \n        # êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ê·œì • ì–¸ê¸‰\n        if any(pattern in text for pattern in ['ì œ\\d+ì¡°', 'ì œ\\d+í•­', 'ì˜ˆë¥¼ ë“¤ì–´', 'ì˜ˆì‹œ']):\n            score += 10\n        \n        # ë‹µë³€ì˜ êµ¬ì²´ì„± (ì£¼ê´€ì‹)\n        if self._identify_question_type(question) == 'ì£¼ê´€ì‹':\n            if len(answer) > 100:  # ì¶©ë¶„í•œ ì„¤ëª…\n                score += 10\n        \n        return min(100, score)\n    \n    def _evaluate_difficulty(self, question: str, answer: str) -> float:\n        \"\"\"\n        ë‚œì´ë„ í‰ê°€\n        - ë„ˆë¬´ ì‰½ê±°ë‚˜ ì–´ë µì§€ ì•Šì€ ì ì ˆí•œ ìˆ˜ì¤€\n        - FSKU ì‹œí—˜ ìˆ˜ì¤€ì— ë§ëŠ”ì§€\n        \"\"\"\n        score = 70  # ê¸°ë³¸ ì ìˆ˜ (ì¤‘ê°„ ë‚œì´ë„)\n        \n        # ë¬¸ì œ ê¸¸ì´ë¡œ ë³µì¡ë„ ì¶”ì •\n        question_length = len(question)\n        if 100 <= question_length <= 300:\n            score += 10\n        elif question_length < 50:\n            score -= 20  # ë„ˆë¬´ ë‹¨ìˆœ\n        elif question_length > 500:\n            score -= 10  # ë„ˆë¬´ ë³µì¡\n        \n        # ì „ë¬¸ ìš©ì–´ ìˆ˜ë¡œ ë‚œì´ë„ ì¶”ì •\n        keyword_count = self._count_keywords(question + answer)\n        if 2 <= keyword_count <= 4:\n            score += 10\n        elif keyword_count > 6:\n            score -= 10  # ë„ˆë¬´ ì „ë¬¸ì \n        \n        # ê³„ì‚° ë¬¸ì œì˜ ê²½ìš°\n        if self._identify_question_type(question) == 'ê³„ì‚°':\n            # ìˆ«ìì˜ ë³µì¡ë„ ì²´í¬\n            numbers = re.findall(r'\\d+', question)\n            if numbers and all(int(n) < 10000 for n in numbers if n.isdigit()):\n                score += 10  # ì ì ˆí•œ ìˆ«ì ë²”ìœ„\n        \n        return max(0, min(100, score))\n    \n    def _evaluate_clarity(self, question: str, answer: str) -> float:\n        \"\"\"\n        ëª…í™•ì„± í‰ê°€\n        - ëª¨í˜¸í•œ í‘œí˜„ ì—†ìŒ\n        - ì´í•´í•˜ê¸° ì‰¬ìš´ ë¬¸ì¥\n        - ì¼ê´€ëœ ìš©ì–´ ì‚¬ìš©\n        \"\"\"\n        score = 100  # ì‹œì‘ ì ìˆ˜\n        text = question + ' ' + answer\n        \n        # ëª¨í˜¸í•œ í‘œí˜„ ì²´í¬\n        ambiguity_count = self._count_ambiguous_terms(text)\n        score -= ambiguity_count * 10\n        \n        # ì´ì¤‘ ë¶€ì • ì²´í¬\n        if any(pattern in text for pattern in ['ì•Šì§€ ì•Š', 'ì—†ì§€ ì•Š', 'ëª»í•˜ì§€ ì•Š']):\n            score -= 20\n        \n        # ë„ˆë¬´ ë§ì€ ì¡°ê±´ë¬¸\n        condition_count = text.count('ë§Œì•½') + text.count('ê²½ìš°') + text.count('ë•Œ')\n        if condition_count > 3:\n            score -= 15\n        \n        # ë¬¸ì¥ ê¸¸ì´ ì²´í¬ (ë„ˆë¬´ ê¸´ ë¬¸ì¥ì€ ì´í•´í•˜ê¸° ì–´ë ¤ì›€)\n        sentences = text.split('.')\n        long_sentences = [s for s in sentences if len(s.strip()) > 150]\n        if long_sentences:\n            score -= len(long_sentences) * 5\n        \n        # ì¼ê´€ëœ ì–´ë¯¸ ì‚¬ìš© ì²´í¬\n        if question.endswith('ì‹œì˜¤.') or question.endswith('í•˜ë¼.'):\n            score += 5  # ì¼ê´€ëœ ëª…ë ¹í˜•\n        \n        return max(0, score)\n    \n    def _identify_question_type(self, question: str) -> str:\n        \"\"\"ë¬¸ì œ ìœ í˜• íŒë³„\"\"\"\n        # ê°ê´€ì‹ ì²´í¬\n        for marker in self.question_patterns['ê°ê´€ì‹']['markers']:\n            if marker in question:\n                return 'ê°ê´€ì‹'\n        for option_pattern in self.question_patterns['ê°ê´€ì‹']['options']:\n            if re.search(option_pattern, question):\n                return 'ê°ê´€ì‹'\n        \n        # ê³„ì‚° ë¬¸ì œ ì²´í¬\n        for marker in self.question_patterns['ê³„ì‚°']['markers']:\n            if marker in question:\n                return 'ê³„ì‚°'\n        \n        # ë‚˜ë¨¸ì§€ëŠ” ì£¼ê´€ì‹\n        return 'ì£¼ê´€ì‹'\n    \n    def _has_options(self, question: str) -> bool:\n        \"\"\"ì„ íƒì§€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\"\"\"\n        for pattern in self.question_patterns['ê°ê´€ì‹']['options']:\n            if re.search(pattern, question):\n                return True\n        return False\n    \n    def _has_proper_options(self, question: str) -> bool:\n        \"\"\"ì ì ˆí•œ í˜•ì‹ì˜ ì„ íƒì§€ í™•ì¸\"\"\"\n        # ì¼ê´€ëœ ì„ íƒì§€ í˜•ì‹ ì²´í¬\n        option_formats = []\n        for pattern in self.question_patterns['ê°ê´€ì‹']['options']:\n            if re.findall(pattern, question):\n                option_formats.append(pattern)\n        \n        # í•˜ë‚˜ì˜ ì¼ê´€ëœ í˜•ì‹ë§Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì²´í¬\n        return len(option_formats) == 1\n    \n    def _count_options(self, question: str) -> int:\n        \"\"\"ì„ íƒì§€ ê°œìˆ˜ ì„¸ê¸°\"\"\"\n        max_count = 0\n        for pattern in self.question_patterns['ê°ê´€ì‹']['options']:\n            matches = re.findall(pattern, question)\n            max_count = max(max_count, len(matches))\n        return max_count\n    \n    def _count_keywords(self, text: str) -> int:\n        \"\"\"ê¸ˆìœµ í‚¤ì›Œë“œ ê°œìˆ˜ ì„¸ê¸°\"\"\"\n        count = 0\n        text_lower = text.lower()\n        for keyword in self.finance_keywords:\n            if keyword.lower() in text_lower:\n                count += 1\n        return count\n    \n    def _count_ambiguous_terms(self, text: str) -> int:\n        \"\"\"ëª¨í˜¸í•œ í‘œí˜„ ê°œìˆ˜ ì„¸ê¸°\"\"\"\n        count = 0\n        for term in self.ambiguous_terms:\n            count += text.count(term)\n        return count\n    \n    def _generate_feedback(self, scores: Dict, analysis: Dict) -> List[str]:\n        \"\"\"ê°œì„  í”¼ë“œë°± ìƒì„±\"\"\"\n        feedback = []\n        \n        # ì ìˆ˜ê°€ ë‚®ì€ ì°¨ì›ì— ëŒ€í•œ í”¼ë“œë°±\n        for dim, score in scores.items():\n            if score < 70:\n                if dim == 'format':\n                    feedback.append(\"ğŸ“ í˜•ì‹ ê°œì„ : ëª…í™•í•œ ì§ˆë¬¸ êµ¬ì¡°ì™€ ì¼ê´€ëœ ì„ íƒì§€ í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.\")\n                elif dim == 'content':\n                    feedback.append(\"ğŸ“š ë‚´ìš© ê°•í™”: ë” ë§ì€ ê¸ˆìœµ ì „ë¬¸ ìš©ì–´ì™€ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì„¸ìš”.\")\n                elif dim == 'difficulty':\n                    feedback.append(\"ğŸ¯ ë‚œì´ë„ ì¡°ì •: FSKU ì‹œí—˜ ìˆ˜ì¤€ì— ë§ëŠ” ì ì ˆí•œ ë‚œì´ë„ë¡œ ì¡°ì •í•˜ì„¸ìš”.\")\n                elif dim == 'clarity':\n                    feedback.append(\"âœ¨ ëª…í™•ì„± í–¥ìƒ: ëª¨í˜¸í•œ í‘œí˜„ì„ ì œê±°í•˜ê³  ê°„ê²°í•œ ë¬¸ì¥ì„ ì‚¬ìš©í•˜ì„¸ìš”.\")\n        \n        # ì¶”ê°€ ë¶„ì„ ê¸°ë°˜ í”¼ë“œë°±\n        if analysis['ambiguity_count'] > 2:\n            feedback.append(\"âš ï¸ ëª¨í˜¸í•œ í‘œí˜„ì´ ë§ìŠµë‹ˆë‹¤. êµ¬ì²´ì ì´ê³  ëª…í™•í•œ í‘œí˜„ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”.\")\n        \n        if analysis['length'] < 100:\n            feedback.append(\"ğŸ“ ë¬¸ì œê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ìƒí™© ì„¤ëª…ì„ ì¶”ê°€í•˜ì„¸ìš”.\")\n        \n        if analysis['keyword_count'] < 2:\n            feedback.append(\"ğŸ¦ ê¸ˆìœµ ê´€ë ¨ í‚¤ì›Œë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì „ë¬¸ ìš©ì–´ë¥¼ ë” í¬í•¨í•˜ì„¸ìš”.\")\n        \n        return feedback\n    \n    def _update_stats(self, score: float):\n        \"\"\"í†µê³„ ì •ë³´ ì—…ë°ì´íŠ¸\"\"\"\n        self.evaluation_stats['total_evaluated'] += 1\n        \n        if score >= 70:\n            self.evaluation_stats['passed'] += 1\n        else:\n            self.evaluation_stats['failed'] += 1\n        \n        # í‰ê·  ì ìˆ˜ ì—…ë°ì´íŠ¸\n        n = self.evaluation_stats['total_evaluated']\n        prev_avg = self.evaluation_stats['avg_score']\n        self.evaluation_stats['avg_score'] = (prev_avg * (n-1) + score) / n\n        \n        # ì ìˆ˜ ë¶„í¬ ì—…ë°ì´íŠ¸\n        score_range = int(score // 10) * 10  # 10ì  ë‹¨ìœ„\n        self.evaluation_stats['score_distribution'][score_range] += 1\n    \n    def get_statistics(self) -> Dict:\n        \"\"\"í‰ê°€ í†µê³„ ë°˜í™˜\"\"\"\n        return self.evaluation_stats.copy()\n    \n    def reset_statistics(self):\n        \"\"\"í†µê³„ ì´ˆê¸°í™”\"\"\"\n        self.evaluation_stats = {\n            'total_evaluated': 0,\n            'passed': 0,\n            'failed': 0,\n            'avg_score': 0,\n            'score_distribution': defaultdict(int)\n        }\n\n\n# í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\nprint(\"âœ… í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ\")\nevaluator = QualityEvaluator()\n\n# í…ŒìŠ¤íŠ¸ ì˜ˆì œ\ntest_question = \"\"\"\në‹¤ìŒ ì¤‘ ì „ìê¸ˆìœµê±°ë˜ë²•ìƒ ê¸ˆìœµíšŒì‚¬ê°€ ì¤€ìˆ˜í•´ì•¼ í•  ì‚¬í•­ìœ¼ë¡œ í‹€ë¦° ê²ƒì€?\n\n1) ì „ìê¸ˆìœµê±°ë˜ ì‹œ ë³¸ì¸í™•ì¸ ì ˆì°¨ë¥¼ ê±°ì³ì•¼ í•œë‹¤.\n2) ê³ ê°ì˜ ê°œì¸ì •ë³´ë¥¼ ì•”í˜¸í™”í•˜ì—¬ ë³´ê´€í•´ì•¼ í•œë‹¤.\n3) ì „ìê¸ˆìœµì‚¬ê³  ë°œìƒ ì‹œ 24ì‹œê°„ ì´ë‚´ì— ì‹ ê³ í•´ì•¼ í•œë‹¤.\n4) ê³ ê°ì˜ ë™ì˜ ì—†ì´ ì œ3ìì—ê²Œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆë‹¤.\n5) ì •ê¸°ì ìœ¼ë¡œ ë³´ì•ˆ ì·¨ì•½ì  ì ê²€ì„ ì‹¤ì‹œí•´ì•¼ í•œë‹¤.\n\"\"\"\n\ntest_answer = \"ì •ë‹µ: 4ë²ˆ. ê³ ê°ì˜ ë™ì˜ ì—†ì´ ì œ3ìì—ê²Œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì€ ê°œì¸ì •ë³´ë³´í˜¸ë²• ìœ„ë°˜ì…ë‹ˆë‹¤.\"\n\n# í‰ê°€ ì‹¤í–‰\nresult = evaluator.evaluate(test_question, test_answer)\n\nprint(\"\\nğŸ“Š í‰ê°€ ê²°ê³¼:\")\nprint(f\"ì´ì : {result['total_score']}ì \")\nprint(f\"í†µê³¼ ì—¬ë¶€: {'âœ… í†µê³¼' if result['passed'] else 'âŒ ë¯¸í†µê³¼'}\")\nprint(f\"\\nì°¨ì›ë³„ ì ìˆ˜:\")\nfor dim, score in result['dimension_scores'].items():\n    print(f\"  - {dim}: {score}ì \")\nprint(f\"\\në¶„ì„:\")\nprint(f\"  - ë¬¸ì œ ìœ í˜•: {result['analysis']['question_type']}\")\nprint(f\"  - ê¸ˆìœµ í‚¤ì›Œë“œ ìˆ˜: {result['analysis']['keyword_count']}ê°œ\")\nprint(f\"\\ní”¼ë“œë°±:\")\nfor feedback in result['feedback']:\n    print(f\"  {feedback}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 12. ì²´ì´ë‹ ë°ì´í„° ìƒì„±ê¸°\n\nChain-of-Thoughtë¥¼ í™œìš©í•œ ê³ í’ˆì§ˆ ë°ì´í„° ìƒì„± ì‹œìŠ¤í…œ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class ChainingDataGenerator:\n    \"\"\"\n    Chain-of-Thoughtë¥¼ í™œìš©í•œ ì²´ì´ë‹ ë°ì´í„° ìƒì„±ê¸°\n    \n    ìƒì„± í”„ë¡œì„¸ìŠ¤:\n    1. ì´ˆê¸° ìƒì„± (Initial Generation)\n    2. ìê°€ ê²€ì¦ (Self-Verification)\n    3. ê°œì„  ìƒì„± (Improvement)\n    4. ìµœì¢… ê²€ì¦ (Final Check)\n    \"\"\"\n    \n    def __init__(self, model_name: str = \"beomi/llama-2-ko-7b\"):\n        \"\"\"\n        ì´ˆê¸°í™”\n        \n        Args:\n            model_name: ì‚¬ìš©í•  LLM ëª¨ë¸ëª…\n        \"\"\"\n        self.model_name = model_name\n        self.model = None\n        self.tokenizer = None\n        \n        # ìƒì„± í†µê³„\n        self.generation_stats = {\n            'total_attempts': 0,\n            'successful': 0,\n            'failed': 0,\n            'improvement_rate': 0,\n            'avg_iterations': 0\n        }\n        \n        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n        self.prompts = self._load_prompt_templates()\n        \n        # í’ˆì§ˆ í‰ê°€ê¸°\n        self.evaluator = QualityEvaluator()\n        \n        # ìºì‹œ (ë™ì¼í•œ ì»¨í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì¤‘ë³µ ìƒì„± ë°©ì§€)\n        self.generation_cache = {}\n    \n    def initialize_model(self, use_quantization: bool = True):\n        \"\"\"\n        ëª¨ë¸ ì´ˆê¸°í™”\n        \n        Args:\n            use_quantization: 4bit ì–‘ìí™” ì‚¬ìš© ì—¬ë¶€\n        \"\"\"\n        print(f\"ğŸ¤– ëª¨ë¸ ë¡œë“œ ì¤‘: {self.model_name}\")\n        \n        try:\n            # í† í¬ë‚˜ì´ì € ë¡œë“œ\n            self.tokenizer = AutoTokenizer.from_pretrained(\n                self.model_name,\n                trust_remote_code=True\n            )\n            \n            # íŒ¨ë”© í† í° ì„¤ì •\n            if self.tokenizer.pad_token is None:\n                self.tokenizer.pad_token = self.tokenizer.eos_token\n            \n            # ëª¨ë¸ ì„¤ì •\n            if use_quantization:\n                # 4bit ì–‘ìí™” ì„¤ì •\n                bnb_config = BitsAndBytesConfig(\n                    load_in_4bit=True,\n                    bnb_4bit_quant_type=\"nf4\",\n                    bnb_4bit_compute_dtype=torch.float16,\n                    bnb_4bit_use_double_quant=True\n                )\n                \n                self.model = AutoModelForCausalLM.from_pretrained(\n                    self.model_name,\n                    quantization_config=bnb_config,\n                    device_map=\"auto\",\n                    trust_remote_code=True,\n                    torch_dtype=torch.float16\n                )\n            else:\n                # ì¼ë°˜ ë¡œë“œ\n                self.model = AutoModelForCausalLM.from_pretrained(\n                    self.model_name,\n                    device_map=\"auto\",\n                    trust_remote_code=True,\n                    torch_dtype=torch.float16\n                )\n            \n            print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n            \n            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥\n            if torch.cuda.is_available():\n                memory_used = torch.cuda.memory_allocated() / 1024**3\n                print(f\"ğŸ’¾ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_used:.2f}GB\")\n                \n        except Exception as e:\n            logger.error(f\"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n            raise\n    \n    def _load_prompt_templates(self) -> Dict[str, str]:\n        \"\"\"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ\"\"\"\n        templates = {\n            'initial_generation': \"\"\"ë‹¹ì‹ ì€ í•œêµ­ ê¸ˆìœµê°ë…ì›ì˜ FSKU(ê¸ˆìœµì „ë¬¸ì§€ì‹ìê²©ì‹œí—˜) ì¶œì œìœ„ì›ì…ë‹ˆë‹¤.\në‹¤ìŒ ê¸ˆìœµ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ FSKU ì‹œí—˜ì— ì¶œì œë  ìˆ˜ ìˆëŠ” ê³ í’ˆì§ˆ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n\n### ì°¸ê³  ë¬¸ì„œ:\n{context}\n\n### ìƒì„± ì§€ì¹¨:\n1. ë¬¸ì œ ìœ í˜•: {question_type}\n2. ë‚œì´ë„: ì¤‘ìƒ (FSKU ì‹¤ì œ ì‹œí—˜ ìˆ˜ì¤€)\n3. ê¸ˆìœµ ì „ë¬¸ ìš©ì–´ë¥¼ ì •í™•íˆ ì‚¬ìš©í•˜ì„¸ìš”\n4. ì‹¤ë¬´ì—ì„œ ì¤‘ìš”í•œ ë‚´ìš©ì„ ë‹¤ë£¨ì„¸ìš”\n5. ëª…í™•í•˜ê³  ëª¨í˜¸í•˜ì§€ ì•Šì€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”\n\n### ìƒì„±í•  ë¬¸ì œ:\n\"\"\",\n            \n            'self_verification': \"\"\"ë‹¤ìŒ ìƒì„±ëœ ë¬¸ì œë¥¼ ê²€í† í•˜ê³  ë¬¸ì œì ì„ ì°¾ì•„ì£¼ì„¸ìš”.\n\n### ìƒì„±ëœ ë¬¸ì œ:\n{question}\n\n### ìƒì„±ëœ ë‹µë³€:\n{answer}\n\n### ê²€í†  ê¸°ì¤€:\n1. ë¬¸ì œê°€ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?\n2. ê¸ˆìœµ ì „ë¬¸ ìš©ì–´ê°€ ì •í™•íˆ ì‚¬ìš©ë˜ì—ˆëŠ”ê°€?\n3. ë‹µë³€ì´ ì •í™•í•˜ê³  ì¶©ë¶„í•œ ì„¤ëª…ì„ í¬í•¨í•˜ëŠ”ê°€?\n4. FSKU ì‹œí—˜ ìˆ˜ì¤€ì— ì í•©í•œê°€?\n5. ëª¨í˜¸í•˜ê±°ë‚˜ ë…¼ë€ì˜ ì—¬ì§€ê°€ ìˆëŠ” ë¶€ë¶„ì€ ì—†ëŠ”ê°€?\n\n### ë¬¸ì œì  ë¶„ì„:\n\"\"\",\n            \n            'improvement': \"\"\"ë‹¤ìŒ ë¬¸ì œì™€ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ê°œì„ ëœ ë²„ì „ì„ ìƒì„±í•˜ì„¸ìš”.\n\n### ì›ë³¸ ë¬¸ì œ:\n{question}\n\n### ì›ë³¸ ë‹µë³€:\n{answer}\n\n### í”¼ë“œë°±:\n{feedback}\n\n### ê°œì„  ì§€ì¹¨:\n1. ì§€ì ëœ ë¬¸ì œì ì„ ëª¨ë‘ ìˆ˜ì •í•˜ì„¸ìš”\n2. ë” ëª…í™•í•˜ê³  ì „ë¬¸ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”\n3. í•„ìš”ì‹œ êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ê·œì •ì„ ì¶”ê°€í•˜ì„¸ìš”\n4. ë‹µë³€ì˜ ì„¤ëª…ì„ ë” ì¶©ì‹¤í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”\n\n### ê°œì„ ëœ ë¬¸ì œ:\n\"\"\",\n            \n            'final_check': \"\"\"ìµœì¢… ìƒì„±ëœ ë¬¸ì œë¥¼ ê²€í† í•˜ê³  FSKU ì‹œí—˜ ì¶œì œ ê°€ëŠ¥ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì„¸ìš”.\n\n### ìµœì¢… ë¬¸ì œ:\n{question}\n\n### ìµœì¢… ë‹µë³€:\n{answer}\n\n### í‰ê°€ í•­ëª©:\n1. FSKU ì¶œì œ ê°€ëŠ¥ì„± (ì í•©/ë¶€ì í•©)\n2. ì „ë°˜ì ì¸ í’ˆì§ˆ (1-10ì )\n3. ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ (ìˆë‹¤ë©´)\n4. ìµœì¢… ì˜ê²¬\n\n### í‰ê°€ ê²°ê³¼:\n\"\"\"\n        }\n        \n        return templates\n    \n    def generate_qa_pair(self, \n                        context: str, \n                        question_type: str = \"ê°ê´€ì‹\",\n                        max_iterations: int = 3) -> Optional[Dict]:\n        \"\"\"\n        ì²´ì´ë‹ì„ í†µí•œ QA ìŒ ìƒì„±\n        \n        Args:\n            context: RAGì—ì„œ ê°€ì ¸ì˜¨ ì»¨í…ìŠ¤íŠ¸\n            question_type: ë¬¸ì œ ìœ í˜• (ê°ê´€ì‹/ì£¼ê´€ì‹/ê³„ì‚°)\n            max_iterations: ìµœëŒ€ ê°œì„  ë°˜ë³µ íšŸìˆ˜\n            \n        Returns:\n            ìƒì„±ëœ QA ìŒ ë˜ëŠ” None\n        \"\"\"\n        # ìºì‹œ í™•ì¸\n        cache_key = hash(context[:200] + question_type)\n        if cache_key in self.generation_cache:\n            logger.info(\"ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜\")\n            return self.generation_cache[cache_key]\n        \n        self.generation_stats['total_attempts'] += 1\n        \n        try:\n            # 1ë‹¨ê³„: ì´ˆê¸° ìƒì„±\n            print(\"ğŸ”„ [1/4] ì´ˆê¸° ë¬¸ì œ ìƒì„± ì¤‘...\")\n            initial_qa = self._initial_generation(context, question_type)\n            if not initial_qa:\n                raise ValueError(\"ì´ˆê¸° ìƒì„± ì‹¤íŒ¨\")\n            \n            current_question = initial_qa['question']\n            current_answer = initial_qa['answer']\n            \n            # 2ë‹¨ê³„: ë°˜ë³µì  ê°œì„ \n            iteration_count = 0\n            for i in range(max_iterations):\n                iteration_count += 1\n                print(f\"ğŸ”„ [{2+i*2}/4] ìê°€ ê²€ì¦ ì¤‘...\")\n                \n                # ìê°€ ê²€ì¦\n                verification = self._self_verification(current_question, current_answer)\n                \n                # ë¬¸ì œì ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ\n                if \"ë¬¸ì œì—†ìŒ\" in verification or \"ì í•©\" in verification:\n                    break\n                \n                # ê°œì„ \n                print(f\"ğŸ”„ [{3+i*2}/4] ê°œì„  ìƒì„± ì¤‘...\")\n                improved_qa = self._improvement_generation(\n                    current_question, \n                    current_answer, \n                    verification\n                )\n                \n                if improved_qa:\n                    current_question = improved_qa['question']\n                    current_answer = improved_qa['answer']\n            \n            # 3ë‹¨ê³„: ìµœì¢… ê²€ì¦\n            print(\"ğŸ”„ [4/4] ìµœì¢… ê²€ì¦ ì¤‘...\")\n            final_check = self._final_check(current_question, current_answer)\n            \n            # 4ë‹¨ê³„: í’ˆì§ˆ í‰ê°€\n            evaluation = self.evaluator.evaluate(current_question, current_answer)\n            \n            # ê²°ê³¼ ì¤€ë¹„\n            result = {\n                'question': current_question,\n                'answer': current_answer,\n                'context': context,\n                'question_type': question_type,\n                'quality_score': evaluation['total_score'],\n                'passed': evaluation['passed'],\n                'iterations': iteration_count,\n                'final_check': final_check,\n                'metadata': {\n                    'timestamp': datetime.now().isoformat(),\n                    'model': self.model_name,\n                    'dimension_scores': evaluation['dimension_scores']\n                }\n            }\n            \n            # í†µê³¼í•œ ê²½ìš°ë§Œ ìºì‹œì— ì €ì¥\n            if result['passed']:\n                self.generation_cache[cache_key] = result\n                self.generation_stats['successful'] += 1\n            else:\n                self.generation_stats['failed'] += 1\n            \n            # í†µê³„ ì—…ë°ì´íŠ¸\n            self._update_stats(iteration_count, result['passed'])\n            \n            return result\n            \n        except Exception as e:\n            logger.error(f\"ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n            self.generation_stats['failed'] += 1\n            return None\n    \n    def _generate_text(self, prompt: str, max_length: int = 512) -> str:\n        \"\"\"\n        LLMì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ìƒì„±\n        \n        Args:\n            prompt: ì…ë ¥ í”„ë¡¬í”„íŠ¸\n            max_length: ìµœëŒ€ ìƒì„± ê¸¸ì´\n            \n        Returns:\n            ìƒì„±ëœ í…ìŠ¤íŠ¸\n        \"\"\"\n        if not self.model or not self.tokenizer:\n            raise ValueError(\"ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n        \n        # ì…ë ¥ í† í°í™”\n        inputs = self.tokenizer(\n            prompt, \n            return_tensors=\"pt\",\n            truncation=True,\n            max_length=2048\n        ).to(self.model.device)\n        \n        # ìƒì„±\n        with torch.no_grad():\n            outputs = self.model.generate(\n                **inputs,\n                max_new_tokens=max_length,\n                temperature=0.7,\n                top_p=0.9,\n                do_sample=True,\n                pad_token_id=self.tokenizer.pad_token_id,\n                eos_token_id=self.tokenizer.eos_token_id\n            )\n        \n        # ë””ì½”ë”©\n        generated_text = self.tokenizer.decode(\n            outputs[0][inputs['input_ids'].shape[1]:], \n            skip_special_tokens=True\n        )\n        \n        return generated_text.strip()\n    \n    def _initial_generation(self, context: str, question_type: str) -> Optional[Dict]:\n        \"\"\"ì´ˆê¸° ë¬¸ì œ ìƒì„±\"\"\"\n        prompt = self.prompts['initial_generation'].format(\n            context=context,\n            question_type=question_type\n        )\n        \n        generated = self._generate_text(prompt)\n        \n        # ë¬¸ì œì™€ ë‹µë³€ ë¶„ë¦¬\n        qa_pair = self._parse_qa(generated)\n        return qa_pair\n    \n    def _self_verification(self, question: str, answer: str) -> str:\n        \"\"\"ìê°€ ê²€ì¦\"\"\"\n        prompt = self.prompts['self_verification'].format(\n            question=question,\n            answer=answer\n        )\n        \n        verification = self._generate_text(prompt, max_length=256)\n        return verification\n    \n    def _improvement_generation(self, question: str, answer: str, feedback: str) -> Optional[Dict]:\n        \"\"\"ê°œì„ ëœ ë²„ì „ ìƒì„±\"\"\"\n        prompt = self.prompts['improvement'].format(\n            question=question,\n            answer=answer,\n            feedback=feedback\n        )\n        \n        generated = self._generate_text(prompt)\n        qa_pair = self._parse_qa(generated)\n        return qa_pair\n    \n    def _final_check(self, question: str, answer: str) -> str:\n        \"\"\"ìµœì¢… ê²€ì¦\"\"\"\n        prompt = self.prompts['final_check'].format(\n            question=question,\n            answer=answer\n        )\n        \n        check_result = self._generate_text(prompt, max_length=256)\n        return check_result\n    \n    def _parse_qa(self, text: str) -> Optional[Dict]:\n        \"\"\"\n        ìƒì„±ëœ í…ìŠ¤íŠ¸ì—ì„œ ë¬¸ì œì™€ ë‹µë³€ ì¶”ì¶œ\n        \"\"\"\n        try:\n            # ë‹¤ì–‘í•œ êµ¬ë¶„ìë¡œ ì‹œë„\n            separators = ['ì •ë‹µ:', 'ë‹µ:', 'ë‹µë³€:', 'Answer:', 'A:']\n            \n            question = \"\"\n            answer = \"\"\n            \n            for sep in separators:\n                if sep in text:\n                    parts = text.split(sep, 1)\n                    question = parts[0].strip()\n                    answer = parts[1].strip() if len(parts) > 1 else \"\"\n                    break\n            \n            # êµ¬ë¶„ìê°€ ì—†ëŠ” ê²½ìš° íœ´ë¦¬ìŠ¤í‹± ì‚¬ìš©\n            if not answer:\n                lines = text.strip().split('\\n')\n                # ë§ˆì§€ë§‰ ë‹¨ë½ì„ ë‹µë³€ìœ¼ë¡œ ê°„ì£¼\n                if len(lines) > 1:\n                    question = '\\n'.join(lines[:-1])\n                    answer = lines[-1]\n                else:\n                    question = text\n                    answer = \"ë‹µë³€ ìƒì„± í•„ìš”\"\n            \n            return {\n                'question': question,\n                'answer': answer\n            }\n            \n        except Exception as e:\n            logger.error(f\"QA íŒŒì‹± ì˜¤ë¥˜: {e}\")\n            return None\n    \n    def _update_stats(self, iterations: int, passed: bool):\n        \"\"\"í†µê³„ ì—…ë°ì´íŠ¸\"\"\"\n        n = self.generation_stats['successful'] + self.generation_stats['failed']\n        \n        # í‰ê·  ë°˜ë³µ íšŸìˆ˜ ì—…ë°ì´íŠ¸\n        prev_avg = self.generation_stats['avg_iterations']\n        self.generation_stats['avg_iterations'] = (prev_avg * (n-1) + iterations) / n\n        \n        # ê°œì„ ìœ¨ ê³„ì‚°\n        if iterations > 1 and passed:\n            improvement_count = self.generation_stats.get('improvements', 0) + 1\n            self.generation_stats['improvements'] = improvement_count\n            self.generation_stats['improvement_rate'] = improvement_count / self.generation_stats['successful']\n    \n    def get_statistics(self) -> Dict:\n        \"\"\"ìƒì„± í†µê³„ ë°˜í™˜\"\"\"\n        return self.generation_stats.copy()\n    \n    def batch_generate(self, \n                      contexts: List[str], \n                      question_types: List[str] = None,\n                      batch_size: int = 4) -> List[Dict]:\n        \"\"\"\n        ë°°ì¹˜ ìƒì„±\n        \n        Args:\n            contexts: ì»¨í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n            question_types: ë¬¸ì œ ìœ í˜• ë¦¬ìŠ¤íŠ¸\n            batch_size: ë°°ì¹˜ í¬ê¸°\n            \n        Returns:\n            ìƒì„±ëœ QA ë¦¬ìŠ¤íŠ¸\n        \"\"\"\n        if question_types is None:\n            # ê¸°ë³¸ê°’: ê°ê´€ì‹ 60%, ì£¼ê´€ì‹ 30%, ê³„ì‚° 10%\n            question_types = []\n            for _ in range(len(contexts)):\n                rand = random.random()\n                if rand < 0.6:\n                    question_types.append(\"ê°ê´€ì‹\")\n                elif rand < 0.9:\n                    question_types.append(\"ì£¼ê´€ì‹\")\n                else:\n                    question_types.append(\"ê³„ì‚°\")\n        \n        results = []\n        \n        # ë°°ì¹˜ ì²˜ë¦¬\n        for i in tqdm(range(0, len(contexts), batch_size), desc=\"ë°°ì¹˜ ìƒì„±\"):\n            batch_contexts = contexts[i:i+batch_size]\n            batch_types = question_types[i:i+batch_size]\n            \n            # ê° ì»¨í…ìŠ¤íŠ¸ì— ëŒ€í•´ ìƒì„±\n            for ctx, qtype in zip(batch_contexts, batch_types):\n                result = self.generate_qa_pair(ctx, qtype)\n                if result:\n                    results.append(result)\n        \n        return results\n\n\n# ì²´ì´ë‹ ìƒì„±ê¸° í…ŒìŠ¤íŠ¸\nprint(\"âœ… ì²´ì´ë‹ ë°ì´í„° ìƒì„±ê¸° ìƒì„± ì™„ë£Œ\")\nprint(\"\\níŠ¹ì§•:\")\nprint(\"- 4ë‹¨ê³„ ì²´ì´ë‹: ìƒì„± â†’ ê²€ì¦ â†’ ê°œì„  â†’ ìµœì¢…í™•ì¸\")\nprint(\"- ìë™ í’ˆì§ˆ í‰ê°€ ë° í•„í„°ë§\")\nprint(\"- ìºì‹±ìœ¼ë¡œ ì¤‘ë³µ ìƒì„± ë°©ì§€\")\nprint(\"- ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›\")\n\n# ì‚¬ìš© ì˜ˆì‹œ ì¶œë ¥\nprint(\"\\nì‚¬ìš© ì˜ˆì‹œ:\")\nprint(\"generator = ChainingDataGenerator('beomi/llama-2-ko-7b')\")\nprint(\"generator.initialize_model(use_quantization=True)\")\nprint(\"result = generator.generate_qa_pair(context, 'ê°ê´€ì‹')\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 13. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬\n\në‹¤ì–‘í•œ ë¬¸ì œ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬ ì‹œìŠ¤í…œ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class PromptTemplateManager:\n    \"\"\"\n    ë¬¸ì œ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬\n    \n    FSKU ì‹œí—˜ì˜ ë‹¤ì–‘í•œ ë¬¸ì œ ìœ í˜•ì— ë§ì¶˜\n    ì „ë¬¸ì ì¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì œê³µ\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"í…œí”Œë¦¿ ì´ˆê¸°í™”\"\"\"\n        self.templates = self._initialize_templates()\n        self.usage_stats = defaultdict(int)\n    \n    def _initialize_templates(self) -> Dict[str, Dict[str, str]]:\n        \"\"\"ëª¨ë“  í…œí”Œë¦¿ ì´ˆê¸°í™”\"\"\"\n        templates = {\n            # ê°ê´€ì‹ í…œí”Œë¦¿\n            'ê°ê´€ì‹_ì¼ë°˜': {\n                'system': \"ë‹¹ì‹ ì€ FSKU ì¶œì œìœ„ì›ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ëª…í™•í•œ ê°ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\",\n                'user': \"\"\"ë‹¤ìŒ ê¸ˆìœµ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ê°ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n\n### ì°¸ê³  ë¬¸ì„œ:\n{context}\n\n### ìš”êµ¬ì‚¬í•­:\n- 5ê°œì˜ ì„ íƒì§€ ì œê³µ (1ë²ˆ~5ë²ˆ)\n- ì •ë‹µì€ 1ê°œë§Œ\n- ì˜¤ë‹µì€ ê·¸ëŸ´ë“¯í•˜ì§€ë§Œ ëª…í™•íˆ í‹€ë¦° ë‚´ìš©\n- ì„ íƒì§€ëŠ” ë¹„ìŠ·í•œ ê¸¸ì´ë¡œ ì‘ì„±\n\n### ë¬¸ì œ:\"\"\",\n                'examples': [\n                    {\n                        'question': \"ë‹¤ìŒ ì¤‘ ì „ìê¸ˆìœµê±°ë˜ë²•ìƒ ê¸ˆìœµíšŒì‚¬ì˜ ì˜ë¬´ì‚¬í•­ì´ ì•„ë‹Œ ê²ƒì€?\",\n                        'options': [\n                            \"1) ì ‘ê·¼ë§¤ì²´ì˜ ìœ„ì¡°ë‚˜ ë³€ì¡°ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ì¡°ì¹˜\",\n                            \"2) ì „ìê¸ˆìœµê±°ë˜ ë‚´ìš©ì˜ í™•ì¸ ë° ì˜¤ë¥˜ì •ì • ìš”êµ¬ ì²˜ë¦¬\",\n                            \"3) ì „ìê¸ˆìœµê±°ë˜ ê¸°ë¡ì˜ 5ë…„ê°„ ë³´ì¡´\",\n                            \"4) ì´ìš©ìì˜ ìš”ì²­ ì—†ì´ë„ ì •ê¸°ì ì¸ ê±°ë˜ë‚´ì—­ í†µì§€\",\n                            \"5) ì „ìê¸ˆìœµì‚¬ê³  ë°œìƒ ì‹œ ì†í•´ë°°ìƒ\"\n                        ],\n                        'answer': \"4ë²ˆ\"\n                    }\n                ]\n            },\n            \n            'ê°ê´€ì‹_ë¶€ì •í˜•': {\n                'system': \"ë¶€ì •í˜• ê°ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”. '~ì•„ë‹Œ ê²ƒì€', '~í‹€ë¦° ê²ƒì€' í˜•íƒœë¡œ ì‘ì„±í•©ë‹ˆë‹¤.\",\n                'user': \"\"\"ë‹¤ìŒ ë‚´ìš©ì—ì„œ í‹€ë¦¬ê±°ë‚˜ í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê²ƒì„ ì°¾ëŠ” ê°ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n\n### ì°¸ê³  ë¬¸ì„œ:\n{context}\n\n### ìš”êµ¬ì‚¬í•­:\n- \"ë‹¤ìŒ ì¤‘ ~ì•„ë‹Œ ê²ƒì€?\" ë˜ëŠ” \"~í‹€ë¦° ê²ƒì€?\" í˜•íƒœ\n- 4ê°œëŠ” ë§ëŠ” ë‚´ìš©, 1ê°œë§Œ í‹€ë¦° ë‚´ìš©\n- í˜¼ë™í•˜ê¸° ì‰¬ìš´ ë‚´ìš©ìœ¼ë¡œ êµ¬ì„±\n\n### ë¬¸ì œ:\"\"\",\n                'examples': []\n            },\n            \n            'ê°ê´€ì‹_ë³µìˆ˜ì •ë‹µ': {\n                'system': \"ë³µìˆ˜ ì •ë‹µí˜• ê°ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\",\n                'user': \"\"\"ë‹¤ìŒ ë‚´ìš©ì—ì„œ ëª¨ë‘ ë§ëŠ” ê²ƒì„ ê³ ë¥´ëŠ” ë³µìˆ˜ì •ë‹µí˜• ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n\n### ì°¸ê³  ë¬¸ì„œ:\n{context}\n\n### ìš”êµ¬ì‚¬í•­:\n- \"ë‹¤ìŒ ì¤‘ ëª¨ë‘ ì˜³ì€ ê²ƒì€?\" í˜•íƒœ\n- ë³´ê¸°ë¥¼ ã„±, ã„´, ã„·, ã„¹ë¡œ ì œì‹œ\n- ì„ íƒì§€ëŠ” ì¡°í•© í˜•íƒœ (ì˜ˆ: 1) ã„±, ã„´  2) ã„´, ã„· ...)\n\n### ë¬¸ì œ:\"\"\",\n                'examples': []\n            },\n            \n            # ì£¼ê´€ì‹ í…œí”Œë¦¿\n            'ì£¼ê´€ì‹_ì„¤ëª…í˜•': {\n                'system': \"ê°œë…ì´ë‚˜ ì œë„ë¥¼ ì„¤ëª…í•˜ëŠ” ì£¼ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\",\n                'user': \"\"\"ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì„¤ëª…í˜• ì£¼ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n\n### ì°¸ê³  ë¬¸ì„œ:\n{context}\n\n### ìš”êµ¬ì‚¬í•­:\n- \"~ì— ëŒ€í•´ ì„¤ëª…í•˜ì‹œì˜¤\" í˜•íƒœ\n- í•µì‹¬ ê°œë…, íŠ¹ì§•, ëª©ì  ë“±ì„ í¬í•¨í•œ ë‹µë³€ ìš”êµ¬\n- 200ì ì´ìƒì˜ ìƒì„¸í•œ ë‹µë³€ì´ í•„ìš”í•œ ë¬¸ì œ\n\n### ë¬¸ì œ:\"\"\",\n                'examples': []\n            },\n            \n            'ì£¼ê´€ì‹_ë¹„êµí˜•': {\n                'system': \"ë‘ ê°œë…ì„ ë¹„êµí•˜ëŠ” ì£¼ê´€ì‹ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\",\n                'user': \"\"\"ë‹¤ìŒ ë‚´ìš©ì—ì„œ ë¹„êµ ê°€ëŠ¥í•œ ê°œë…ë“¤ì„ ì°¾ì•„ ë¹„êµí˜• ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n\n### ì°¸ê³  ë¬¸ì„œ:\n{context}\n\n### ìš”êµ¬ì‚¬í•­:\n- \"Aì™€ Bë¥¼ ë¹„êµí•˜ì—¬ ì„¤ëª…í•˜ì‹œì˜¤\" í˜•íƒœ\n- ê³µí†µì ê³¼ ì°¨ì´ì ì„ ëª¨ë‘ ë‹¤ë£¨ë„ë¡\n- í‘œë‚˜ ë„ì‹ìœ¼ë¡œ ì •ë¦¬ ê°€ëŠ¥í•œ ë‚´ìš©\n\n### ë¬¸ì œ:\"\"\",\n                'examples': []\n            },\n            \n            'ì£¼ê´€ì‹_ì‚¬ë¡€í˜•': {\n                'system': \"ì‹¤ë¬´ ì‚¬ë¡€ë¥¼ ì œì‹œí•˜ê³  í•´ê²°ë°©ì•ˆì„ ë¬»ëŠ” ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\",\n                'user': \"\"\"ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤ë¬´ ì‚¬ë¡€í˜• ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n\n### ì°¸ê³  ë¬¸ì„œ:\n{context}\n\n### ìš”êµ¬ì‚¬í•­:\n- êµ¬ì²´ì ì¸ ìƒí™© ì œì‹œ\n- \"ì´ ê²½ìš° ì–´ë–»ê²Œ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ”ê°€?\" í˜•íƒœ\n- ë²•ì  ê·¼ê±°ì™€ ì‹¤ë¬´ì  í•´ê²°ë°©ì•ˆ ìš”êµ¬\n\n### ë¬¸ì œ:\"\"\",\n                'examples': []\n            },\n            \n            # ê³„ì‚° ë¬¸ì œ í…œí”Œë¦¿\n            'ê³„ì‚°_ê¸ˆë¦¬': {\n                'system': \"ê¸ˆë¦¬ ê³„ì‚° ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\",\n                'user': \"\"\"ë‹¤ìŒ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ê¸ˆë¦¬ ê³„ì‚° ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n\n### ì°¸ê³  ë¬¸ì„œ:\n{context}\n\n### ìš”êµ¬ì‚¬í•­:\n- ì‹¤ì œ ê¸ˆìœµìƒí’ˆì˜ ê¸ˆë¦¬ ê³„ì‚°\n- ë‹¨ë¦¬/ë³µë¦¬, ì—°ì´ìœ¨/ì›”ì´ìœ¨ ë³€í™˜ í¬í•¨\n- ê³„ì‚° ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ë³´ì—¬ì£¼ëŠ” ë‹µì•ˆ\n\n### ë¬¸ì œ:\"\"\",\n                'examples': []\n            },\n            \n            'ê³„ì‚°_ìœ„í—˜ê´€ë¦¬': {\n                'system': \"ìœ„í—˜ê´€ë¦¬ ì§€í‘œ ê³„ì‚° ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\",\n                'user': \"\"\"ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìœ„í—˜ê´€ë¦¬ ê´€ë ¨ ê³„ì‚° ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n\n### ì°¸ê³  ë¬¸ì„œ:\n{context}\n\n### ìš”êµ¬ì‚¬í•­:\n- VaR, ìê¸°ìë³¸ë¹„ìœ¨ ë“± ìœ„í—˜ì§€í‘œ ê³„ì‚°\n- ê³µì‹ê³¼ ê³„ì‚°ê³¼ì • ëª…ì‹œ\n- ê²°ê³¼ì˜ ì˜ë¯¸ í•´ì„ í¬í•¨\n\n### ë¬¸ì œ:\"\"\",\n                'examples': []\n            },\n            \n            # íŠ¹ìˆ˜ ìœ í˜•\n            'ë²•ê·œ_ì¡°ë¬¸': {\n                'system': \"íŠ¹ì • ë²•ê·œ ì¡°ë¬¸ì˜ ë‚´ìš©ì„ ë¬»ëŠ” ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\",\n                'user': \"\"\"ë‹¤ìŒ ë²•ê·œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¡°ë¬¸ ê´€ë ¨ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n\n### ì°¸ê³  ë¬¸ì„œ:\n{context}\n\n### ìš”êµ¬ì‚¬í•­:\n- íŠ¹ì • ì¡°í•­ì˜ ë‚´ìš© í™•ì¸\n- ë¹ˆì¹¸ ì±„ìš°ê¸° ë˜ëŠ” ë‚´ìš© í™•ì¸\n- ì •í™•í•œ ë²•ë¥  ìš©ì–´ ì‚¬ìš©\n\n### ë¬¸ì œ:\"\"\",\n                'examples': []\n            },\n            \n            'ìµœì‹ ë™í–¥': {\n                'system': \"ìµœì‹  ê¸ˆìœµ ë™í–¥ì´ë‚˜ ì œë„ ë³€ê²½ì‚¬í•­ì„ ë¬»ëŠ” ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\",\n                'user': \"\"\"ë‹¤ìŒ ìµœì‹  ë™í–¥ì„ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.\n\n### ì°¸ê³  ë¬¸ì„œ:\n{context}\n\n### ìš”êµ¬ì‚¬í•­:\n- ìµœê·¼ ë„ì…ëœ ì œë„ë‚˜ ì •ì±…\n- ë³€ê²½ ì „í›„ ë¹„êµ\n- ì‹œí–‰ ì‹œê¸°ì™€ ì£¼ìš” ë‚´ìš©\n\n### ë¬¸ì œ:\"\"\",\n                'examples': []\n            }\n        }\n        \n        return templates\n    \n    def get_template(self, template_type: str) -> Dict[str, Any]:\n        \"\"\"\n        íŠ¹ì • í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°\n        \n        Args:\n            template_type: í…œí”Œë¦¿ ìœ í˜•\n            \n        Returns:\n            í…œí”Œë¦¿ ë”•ì…”ë„ˆë¦¬\n        \"\"\"\n        if template_type not in self.templates:\n            logger.warning(f\"í…œí”Œë¦¿ '{template_type}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©.\")\n            template_type = 'ê°ê´€ì‹_ì¼ë°˜'\n        \n        self.usage_stats[template_type] += 1\n        return self.templates[template_type]\n    \n    def get_random_template(self, category: str = None) -> Tuple[str, Dict[str, Any]]:\n        \"\"\"\n        ëœë¤ í…œí”Œë¦¿ ì„ íƒ\n        \n        Args:\n            category: ì¹´í…Œê³ ë¦¬ (ê°ê´€ì‹/ì£¼ê´€ì‹/ê³„ì‚° ë“±)\n            \n        Returns:\n            (í…œí”Œë¦¿ëª…, í…œí”Œë¦¿ ë‚´ìš©)\n        \"\"\"\n        if category:\n            # íŠ¹ì • ì¹´í…Œê³ ë¦¬ì—ì„œ ì„ íƒ\n            filtered = [k for k in self.templates.keys() if k.startswith(category)]\n            if filtered:\n                template_name = random.choice(filtered)\n            else:\n                template_name = random.choice(list(self.templates.keys()))\n        else:\n            # ì „ì²´ì—ì„œ ì„ íƒ\n            template_name = random.choice(list(self.templates.keys()))\n        \n        return template_name, self.get_template(template_name)\n    \n    def format_prompt(self, template_type: str, context: str, **kwargs) -> str:\n        \"\"\"\n        ì»¨í…ìŠ¤íŠ¸ë¡œ í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…\n        \n        Args:\n            template_type: í…œí”Œë¦¿ ìœ í˜•\n            context: RAGì—ì„œ ê°€ì ¸ì˜¨ ì»¨í…ìŠ¤íŠ¸\n            **kwargs: ì¶”ê°€ ë³€ìˆ˜\n            \n        Returns:\n            í¬ë§·ëœ í”„ë¡¬í”„íŠ¸\n        \"\"\"\n        template = self.get_template(template_type)\n        \n        # system í”„ë¡¬í”„íŠ¸ì™€ user í”„ë¡¬í”„íŠ¸ ê²°í•©\n        system_prompt = template['system']\n        user_prompt = template['user'].format(context=context, **kwargs)\n        \n        # ì˜ˆì‹œê°€ ìˆìœ¼ë©´ ì¶”ê°€\n        if template.get('examples'):\n            examples_text = \"\\n### ì˜ˆì‹œ:\\n\"\n            for ex in template['examples'][:2]:  # ìµœëŒ€ 2ê°œ ì˜ˆì‹œ\n                examples_text += f\"ë¬¸ì œ: {ex['question']}\\n\"\n                if 'options' in ex:\n                    examples_text += \"\\n\".join(ex['options']) + \"\\n\"\n                examples_text += f\"ë‹µ: {ex['answer']}\\n\\n\"\n            \n            full_prompt = f\"{system_prompt}\\n\\n{examples_text}{user_prompt}\"\n        else:\n            full_prompt = f\"{system_prompt}\\n\\n{user_prompt}\"\n        \n        return full_prompt\n    \n    def get_usage_statistics(self) -> Dict[str, int]:\n        \"\"\"\n        í…œí”Œë¦¿ ì‚¬ìš© í†µê³„ ë°˜í™˜\n        \"\"\"\n        return dict(self.usage_stats)\n    \n    def recommend_template(self, context: str) -> str:\n        \"\"\"\n        ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ í›„ ì ì ˆí•œ í…œí”Œë¦¿ ì¶”ì²œ\n        \n        Args:\n            context: ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸\n            \n        Returns:\n            ì¶”ì²œ í…œí”Œë¦¿ëª…\n        \"\"\"\n        context_lower = context.lower()\n        \n        # í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ\n        if any(word in context_lower for word in ['ê³„ì‚°', 'ì‚°ì¶œ', 'ê³µì‹', '%', 'ì´ì']):\n            return random.choice(['ê³„ì‚°_ê¸ˆë¦¬', 'ê³„ì‚°_ìœ„í—˜ê´€ë¦¬'])\n        \n        elif any(word in context_lower for word in ['ì œ\\d+ì¡°', 'ë²•', 'ê·œì •', 'ì‹œí–‰ë ¹']):\n            return 'ë²•ê·œ_ì¡°ë¬¸'\n        \n        elif any(word in context_lower for word in ['ìµœê·¼', 'ê°œì •', 'ë„ì…', 'ë³€ê²½']):\n            return 'ìµœì‹ ë™í–¥'\n        \n        elif any(word in context_lower for word in ['ë¹„êµ', 'ì°¨ì´', 'ê³µí†µì ']):\n            return 'ì£¼ê´€ì‹_ë¹„êµí˜•'\n        \n        elif any(word in context_lower for word in ['ì‚¬ë¡€', 'ê²½ìš°', 'ìƒí™©']):\n            return 'ì£¼ê´€ì‹_ì‚¬ë¡€í˜•'\n        \n        else:\n            # ê¸°ë³¸ê°’: ê°ê´€ì‹ 60%, ì£¼ê´€ì‹ 30%, ê¸°íƒ€ 10%\n            rand = random.random()\n            if rand < 0.6:\n                return random.choice(['ê°ê´€ì‹_ì¼ë°˜', 'ê°ê´€ì‹_ë¶€ì •í˜•', 'ê°ê´€ì‹_ë³µìˆ˜ì •ë‹µ'])\n            elif rand < 0.9:\n                return random.choice(['ì£¼ê´€ì‹_ì„¤ëª…í˜•', 'ì£¼ê´€ì‹_ë¹„êµí˜•', 'ì£¼ê´€ì‹_ì‚¬ë¡€í˜•'])\n            else:\n                return random.choice(['ê³„ì‚°_ê¸ˆë¦¬', 'ê³„ì‚°_ìœ„í—˜ê´€ë¦¬'])\n    \n    def add_custom_template(self, name: str, template: Dict[str, Any]):\n        \"\"\"\n        ì‚¬ìš©ì ì •ì˜ í…œí”Œë¦¿ ì¶”ê°€\n        \n        Args:\n            name: í…œí”Œë¦¿ ì´ë¦„\n            template: í…œí”Œë¦¿ ë‚´ìš©\n        \"\"\"\n        if name in self.templates:\n            logger.warning(f\"í…œí”Œë¦¿ '{name}'ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë®ì–´ì”ë‹ˆë‹¤.\")\n        \n        # í•„ìˆ˜ í‚¤ í™•ì¸\n        required_keys = ['system', 'user']\n        for key in required_keys:\n            if key not in template:\n                raise ValueError(f\"í…œí”Œë¦¿ì— í•„ìˆ˜ í‚¤ '{key}'ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n        \n        self.templates[name] = template\n        logger.info(f\"í…œí”Œë¦¿ '{name}' ì¶”ê°€ë¨\")\n    \n    def export_templates(self, file_path: str):\n        \"\"\"\n        í…œí”Œë¦¿ì„ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°\n        \n        Args:\n            file_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ\n        \"\"\"\n        with open(file_path, 'w', encoding='utf-8') as f:\n            json.dump(self.templates, f, ensure_ascii=False, indent=2)\n        \n        logger.info(f\"í…œí”Œë¦¿ì´ {file_path}ì— ì €ì¥ë¨\")\n    \n    def import_templates(self, file_path: str):\n        \"\"\"\n        íŒŒì¼ì—ì„œ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°\n        \n        Args:\n            file_path: ë¶ˆëŸ¬ì˜¬ íŒŒì¼ ê²½ë¡œ\n        \"\"\"\n        with open(file_path, 'r', encoding='utf-8') as f:\n            imported = json.load(f)\n        \n        self.templates.update(imported)\n        logger.info(f\"{len(imported)}ê°œ í…œí”Œë¦¿ ê°€ì ¸ì˜´\")\n\n\n# í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸\nprint(\"âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë§¤ë‹ˆì € ìƒì„± ì™„ë£Œ\")\nprompt_manager = PromptTemplateManager()\n\nprint(f\"\\nğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿ ({len(prompt_manager.templates)}ê°œ):\")\nfor i, (name, _) in enumerate(prompt_manager.templates.items()):\n    print(f\"  {i+1}. {name}\")\n\n# í…œí”Œë¦¿ ì‚¬ìš© ì˜ˆì‹œ\nprint(\"\\nğŸ“Œ í…œí”Œë¦¿ ì‚¬ìš© ì˜ˆì‹œ:\")\ntest_context = \"ì „ìê¸ˆìœµê±°ë˜ë²• ì œ21ì¡°ì— ë”°ë¥´ë©´ ê¸ˆìœµíšŒì‚¬ëŠ”...\"\ntemplate_name = prompt_manager.recommend_template(test_context)\nprint(f\"ì¶”ì²œ í…œí”Œë¦¿: {template_name}\")\n\nformatted_prompt = prompt_manager.format_prompt(template_name, test_context)\nprint(f\"\\ní¬ë§·ëœ í”„ë¡¬í”„íŠ¸ (ì²« 200ì):\\n{formatted_prompt[:200]}...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ‰ Stage 2 ì™„ë£Œ!\n\n### âœ… ì™„ë£Œëœ ì‘ì—…\n1. **í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ** - ë‹¤ì°¨ì› í‰ê°€ë¡œ ê³ í’ˆì§ˆ ë°ì´í„°ë§Œ ì„ ë³„\n2. **ì²´ì´ë‹ ë°ì´í„° ìƒì„±ê¸°** - 4ë‹¨ê³„ ê°œì„  í”„ë¡œì„¸ìŠ¤ë¡œ í’ˆì§ˆ í–¥ìƒ\n3. **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬** - 10ê°€ì§€ ì´ìƒì˜ ì „ë¬¸ í…œí”Œë¦¿ ì œê³µ\n\n### ğŸ“Œ ë‹¤ìŒ ë‹¨ê³„ (Stage 3)\n- **ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬í˜„**\n- **ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜**\n- **ê²°ê³¼ ë¶„ì„ ë° ì €ì¥**\n\nStage 3ì„ ê³„ì† ì§„í–‰í•˜ì‹œë ¤ë©´ ë‹¤ìŒ ì…€ë“¤ì„ ì‹¤í–‰í•˜ì„¸ìš”.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸš€ Stage 3: ì‹¤í–‰ ë° ìœ í‹¸ë¦¬í‹°\n\n### 14. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class GenerationMonitor:\n    \"\"\"\n    ë°ì´í„° ìƒì„± ê³¼ì • ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§\n    \n    ê¸°ëŠ¥:\n    - ì§„í–‰ ìƒí™© ì‹œê°í™”\n    - í’ˆì§ˆ ë¶„í¬ ì°¨íŠ¸\n    - ì‹¤ì‹œê°„ í†µê³„\n    - ì˜ˆìƒ ì†Œìš” ì‹œê°„\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"ëª¨ë‹ˆí„° ì´ˆê¸°í™”\"\"\"\n        self.start_time = None\n        self.stats = {\n            'total_target': 0,\n            'total_generated': 0,\n            'passed': 0,\n            'failed': 0,\n            'current_rate': 0,\n            'quality_scores': [],\n            'generation_times': [],\n            'question_types': defaultdict(int)\n        }\n        \n        # ì‹œê°í™” ì„¤ì •\n        plt.style.use('seaborn-v0_8-darkgrid')\n        self.fig = None\n        self.axes = None\n    \n    def start_monitoring(self, target_count: int):\n        \"\"\"\n        ëª¨ë‹ˆí„°ë§ ì‹œì‘\n        \n        Args:\n            target_count: ëª©í‘œ ìƒì„± ê°œìˆ˜\n        \"\"\"\n        self.start_time = time.time()\n        self.stats['total_target'] = target_count\n        \n        # ëŒ€ì‹œë³´ë“œ ì´ˆê¸°í™”\n        self._initialize_dashboard()\n        \n        print(\"=\" * 60)\n        print(\"ğŸ“Š ë°ì´í„° ìƒì„± ëª¨ë‹ˆí„°ë§ ì‹œì‘\")\n        print(\"=\" * 60)\n        print(f\"ëª©í‘œ: {target_count}ê°œ ë¬¸ì œ ìƒì„±\")\n        print(f\"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n        print(\"=\" * 60)\n    \n    def _initialize_dashboard(self):\n        \"\"\"ëŒ€ì‹œë³´ë“œ ì´ˆê¸°í™”\"\"\"\n        # 2x2 ì„œë¸Œí”Œë¡¯ ìƒì„±\n        self.fig, self.axes = plt.subplots(2, 2, figsize=(15, 10))\n        self.fig.suptitle('FSKU ë°ì´í„° ìƒì„± ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ', fontsize=16)\n        \n        # ë ˆì´ì•„ì›ƒ ì¡°ì •\n        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    \n    def update(self, result: Dict):\n        \"\"\"\n        ìƒì„± ê²°ê³¼ë¡œ í†µê³„ ì—…ë°ì´íŠ¸\n        \n        Args:\n            result: ìƒì„±ëœ QA ê²°ê³¼\n        \"\"\"\n        # ê¸°ë³¸ í†µê³„ ì—…ë°ì´íŠ¸\n        self.stats['total_generated'] += 1\n        \n        if result.get('passed', False):\n            self.stats['passed'] += 1\n        else:\n            self.stats['failed'] += 1\n        \n        # í’ˆì§ˆ ì ìˆ˜ ì¶”ê°€\n        if 'quality_score' in result:\n            self.stats['quality_scores'].append(result['quality_score'])\n        \n        # ë¬¸ì œ ìœ í˜• ì¹´ìš´íŠ¸\n        if 'question_type' in result:\n            self.stats['question_types'][result['question_type']] += 1\n        \n        # ìƒì„± ì‹œê°„ ê¸°ë¡\n        if hasattr(self, '_last_update_time'):\n            generation_time = time.time() - self._last_update_time\n            self.stats['generation_times'].append(generation_time)\n        self._last_update_time = time.time()\n        \n        # ì„±ê³µë¥  ê³„ì‚°\n        if self.stats['total_generated'] > 0:\n            self.stats['current_rate'] = self.stats['passed'] / self.stats['total_generated']\n        \n        # ì£¼ê¸°ì ìœ¼ë¡œ ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸ (10ê°œë§ˆë‹¤)\n        if self.stats['total_generated'] % 10 == 0:\n            self._update_dashboard()\n    \n    def _update_dashboard(self):\n        \"\"\"ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸\"\"\"\n        if not self.fig or not self.axes:\n            return\n        \n        # ê° ì„œë¸Œí”Œë¡¯ ì´ˆê¸°í™”\n        for ax in self.axes.flatten():\n            ax.clear()\n        \n        # 1. ì§„í–‰ ìƒí™© (ì™¼ìª½ ìƒë‹¨)\n        ax1 = self.axes[0, 0]\n        self._plot_progress(ax1)\n        \n        # 2. í’ˆì§ˆ ì ìˆ˜ ë¶„í¬ (ì˜¤ë¥¸ìª½ ìƒë‹¨)\n        ax2 = self.axes[0, 1]\n        self._plot_quality_distribution(ax2)\n        \n        # 3. ë¬¸ì œ ìœ í˜• ë¶„í¬ (ì™¼ìª½ í•˜ë‹¨)\n        ax3 = self.axes[1, 0]\n        self._plot_question_types(ax3)\n        \n        # 4. ì‹œê°„ë‹¹ ìƒì„±ëŸ‰ (ì˜¤ë¥¸ìª½ í•˜ë‹¨)\n        ax4 = self.axes[1, 1]\n        self._plot_generation_rate(ax4)\n        \n        # í™”ë©´ ê°±ì‹ \n        plt.draw()\n        plt.pause(0.01)\n    \n    def _plot_progress(self, ax):\n        \"\"\"ì§„í–‰ ìƒí™© í”Œë¡¯\"\"\"\n        # ë°ì´í„° ì¤€ë¹„\n        categories = ['ìƒì„±ë¨', 'í†µê³¼', 'ì‹¤íŒ¨']\n        values = [\n            self.stats['total_generated'],\n            self.stats['passed'],\n            self.stats['failed']\n        ]\n        \n        # ë§‰ëŒ€ ê·¸ë˜í”„\n        bars = ax.bar(categories, values, color=['blue', 'green', 'red'])\n        \n        # ê°’ í‘œì‹œ\n        for bar, value in zip(bars, values):\n            height = bar.get_height()\n            ax.text(bar.get_x() + bar.get_width()/2., height,\n                   f'{value}', ha='center', va='bottom')\n        \n        # ëª©í‘œì„  í‘œì‹œ\n        ax.axhline(y=self.stats['total_target'], color='orange', \n                  linestyle='--', label=f\"ëª©í‘œ: {self.stats['total_target']}\")\n        \n        ax.set_title('ìƒì„± ì§„í–‰ ìƒí™©')\n        ax.set_ylabel('ê°œìˆ˜')\n        ax.legend()\n        \n        # ì§„í–‰ë¥  í‘œì‹œ\n        progress = self.stats['total_generated'] / self.stats['total_target'] * 100\n        ax.text(0.5, 0.95, f'ì§„í–‰ë¥ : {progress:.1f}%', \n               transform=ax.transAxes, ha='center', fontsize=12, \n               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n    \n    def _plot_quality_distribution(self, ax):\n        \"\"\"í’ˆì§ˆ ì ìˆ˜ ë¶„í¬\"\"\"\n        if not self.stats['quality_scores']:\n            ax.text(0.5, 0.5, 'ë°ì´í„° ì—†ìŒ', transform=ax.transAxes, \n                   ha='center', va='center')\n            ax.set_title('í’ˆì§ˆ ì ìˆ˜ ë¶„í¬')\n            return\n        \n        # íˆìŠ¤í† ê·¸ë¨\n        ax.hist(self.stats['quality_scores'], bins=20, color='skyblue', \n               edgecolor='black', alpha=0.7)\n        \n        # í‰ê· ì„ \n        mean_score = np.mean(self.stats['quality_scores'])\n        ax.axvline(x=mean_score, color='red', linestyle='--', \n                  label=f'í‰ê· : {mean_score:.1f}')\n        \n        # í•©ê²©ì„  (70ì )\n        ax.axvline(x=70, color='green', linestyle='--', \n                  label='í•©ê²©ì„ : 70')\n        \n        ax.set_title('í’ˆì§ˆ ì ìˆ˜ ë¶„í¬')\n        ax.set_xlabel('ì ìˆ˜')\n        ax.set_ylabel('ë¹ˆë„')\n        ax.legend()\n    \n    def _plot_question_types(self, ax):\n        \"\"\"ë¬¸ì œ ìœ í˜• ë¶„í¬\"\"\"\n        if not self.stats['question_types']:\n            ax.text(0.5, 0.5, 'ë°ì´í„° ì—†ìŒ', transform=ax.transAxes, \n                   ha='center', va='center')\n            ax.set_title('ë¬¸ì œ ìœ í˜• ë¶„í¬')\n            return\n        \n        # íŒŒì´ ì°¨íŠ¸\n        types = list(self.stats['question_types'].keys())\n        counts = list(self.stats['question_types'].values())\n        \n        colors = plt.cm.Set3(range(len(types)))\n        wedges, texts, autotexts = ax.pie(counts, labels=types, colors=colors,\n                                          autopct='%1.1f%%', startangle=90)\n        \n        ax.set_title('ë¬¸ì œ ìœ í˜• ë¶„í¬')\n    \n    def _plot_generation_rate(self, ax):\n        \"\"\"ìƒì„± ì†ë„\"\"\"\n        if not self.stats['generation_times'] or not self.start_time:\n            ax.text(0.5, 0.5, 'ë°ì´í„° ì—†ìŒ', transform=ax.transAxes, \n                   ha='center', va='center')\n            ax.set_title('ìƒì„± ì†ë„')\n            return\n        \n        # ì‹œê°„ë‹¹ ìƒì„±ëŸ‰ ê³„ì‚°\n        elapsed_time = time.time() - self.start_time\n        if elapsed_time > 0:\n            rate_per_hour = (self.stats['total_generated'] / elapsed_time) * 3600\n            rate_per_minute = (self.stats['total_generated'] / elapsed_time) * 60\n        else:\n            rate_per_hour = 0\n            rate_per_minute = 0\n        \n        # ì˜ˆìƒ ì™„ë£Œ ì‹œê°„\n        if rate_per_minute > 0:\n            remaining = self.stats['total_target'] - self.stats['total_generated']\n            eta_minutes = remaining / rate_per_minute\n            eta_str = f\"{int(eta_minutes)}ë¶„ {int((eta_minutes % 1) * 60)}ì´ˆ\"\n        else:\n            eta_str = \"ê³„ì‚° ì¤‘...\"\n        \n        # ì •ë³´ í‘œì‹œ\n        info_text = f\"\"\"í˜„ì¬ ì†ë„:\n        \n{rate_per_hour:.0f} ê°œ/ì‹œê°„\n{rate_per_minute:.1f} ê°œ/ë¶„\n\ní‰ê·  ìƒì„± ì‹œê°„: {np.mean(self.stats['generation_times']):.1f}ì´ˆ\n\nì˜ˆìƒ ì™„ë£Œ ì‹œê°„: {eta_str}\n        \"\"\"\n        \n        ax.text(0.5, 0.5, info_text, transform=ax.transAxes, \n               ha='center', va='center', fontsize=12,\n               bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n        \n        ax.set_title('ìƒì„± ì†ë„ ë° ì˜ˆìƒ ì‹œê°„')\n        ax.axis('off')\n    \n    def print_summary(self):\n        \"\"\"ìµœì¢… ìš”ì•½ ì¶œë ¥\"\"\"\n        if not self.start_time:\n            return\n        \n        total_time = time.time() - self.start_time\n        \n        print(\"\\n\" + \"=\" * 60)\n        print(\"ğŸ“Š ë°ì´í„° ìƒì„± ì™„ë£Œ ìš”ì•½\")\n        print(\"=\" * 60)\n        print(f\"ì´ ì†Œìš” ì‹œê°„: {int(total_time//60)}ë¶„ {int(total_time%60)}ì´ˆ\")\n        print(f\"ì´ ìƒì„±: {self.stats['total_generated']}ê°œ\")\n        print(f\"í†µê³¼: {self.stats['passed']}ê°œ ({self.stats['current_rate']*100:.1f}%)\")\n        print(f\"ì‹¤íŒ¨: {self.stats['failed']}ê°œ\")\n        \n        if self.stats['quality_scores']:\n            print(f\"\\ní’ˆì§ˆ ì ìˆ˜:\")\n            print(f\"  - í‰ê· : {np.mean(self.stats['quality_scores']):.1f}\")\n            print(f\"  - ìµœê³ : {max(self.stats['quality_scores']):.1f}\")\n            print(f\"  - ìµœì €: {min(self.stats['quality_scores']):.1f}\")\n        \n        print(f\"\\në¬¸ì œ ìœ í˜•ë³„ ë¶„í¬:\")\n        for qtype, count in self.stats['question_types'].items():\n            percentage = count / self.stats['total_generated'] * 100\n            print(f\"  - {qtype}: {count}ê°œ ({percentage:.1f}%)\")\n        \n        print(\"=\" * 60)\n    \n    def save_report(self, file_path: str):\n        \"\"\"\n        ìƒì„¸ ë³´ê³ ì„œ ì €ì¥\n        \n        Args:\n            file_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ\n        \"\"\"\n        report = {\n            'summary': {\n                'total_generated': self.stats['total_generated'],\n                'passed': self.stats['passed'],\n                'failed': self.stats['failed'],\n                'success_rate': self.stats['current_rate'],\n                'total_time_seconds': time.time() - self.start_time if self.start_time else 0\n            },\n            'quality': {\n                'scores': self.stats['quality_scores'],\n                'mean': np.mean(self.stats['quality_scores']) if self.stats['quality_scores'] else 0,\n                'std': np.std(self.stats['quality_scores']) if self.stats['quality_scores'] else 0\n            },\n            'distribution': dict(self.stats['question_types']),\n            'performance': {\n                'generation_times': self.stats['generation_times'],\n                'avg_time_per_item': np.mean(self.stats['generation_times']) if self.stats['generation_times'] else 0\n            },\n            'timestamp': datetime.now().isoformat()\n        }\n        \n        with open(file_path, 'w', encoding='utf-8') as f:\n            json.dump(report, f, ensure_ascii=False, indent=2)\n        \n        print(f\"âœ… ë³´ê³ ì„œ ì €ì¥ë¨: {file_path}\")\n    \n    def close(self):\n        \"\"\"ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ\"\"\"\n        if self.fig:\n            plt.close(self.fig)\n\n\n# ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\nprint(\"âœ… ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ\")\nprint(\"\\nì£¼ìš” ê¸°ëŠ¥:\")\nprint(\"- ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ì¶”ì \")\nprint(\"- í’ˆì§ˆ ì ìˆ˜ ë¶„í¬ ì‹œê°í™”\")\nprint(\"- ë¬¸ì œ ìœ í˜•ë³„ í†µê³„\")\nprint(\"- ì˜ˆìƒ ì™„ë£Œ ì‹œê°„ ê³„ì‚°\")\nprint(\"- ìƒì„¸ ë³´ê³ ì„œ ìƒì„±\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 15. ë°ì´í„° ì €ì¥ ë° ê´€ë¦¬",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class DataManager:\n    \"\"\"\n    ìƒì„±ëœ ë°ì´í„° ì €ì¥ ë° ê´€ë¦¬\n    \n    ê¸°ëŠ¥:\n    - JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥\n    - ë©”íƒ€ë°ì´í„° ê´€ë¦¬\n    - ì¤‘ë³µ ì œê±°\n    - ë°ì´í„° ê²€ì¦\n    \"\"\"\n    \n    def __init__(self, output_dir: Path):\n        \"\"\"\n        ì´ˆê¸°í™”\n        \n        Args:\n            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬\n        \"\"\"\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        \n        # íŒŒì¼ ê²½ë¡œ ì„¤ì •\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        self.data_file = self.output_dir / f\"fsku_data_{timestamp}.jsonl\"\n        self.metadata_file = self.output_dir / f\"fsku_metadata_{timestamp}.json\"\n        \n        # ë°ì´í„° ë²„í¼\n        self.data_buffer = []\n        self.buffer_size = 100  # 100ê°œì”© ë°°ì¹˜ ì €ì¥\n        \n        # ì¤‘ë³µ ì²´í¬ìš©\n        self.question_hashes = set()\n        \n        # í†µê³„\n        self.save_stats = {\n            'total_saved': 0,\n            'duplicates_removed': 0,\n            'batches_written': 0\n        }\n    \n    def add_data(self, qa_data: Dict) -> bool:\n        \"\"\"\n        ë°ì´í„° ì¶”ê°€\n        \n        Args:\n            qa_data: ìƒì„±ëœ QA ë°ì´í„°\n            \n        Returns:\n            ì €ì¥ ì„±ê³µ ì—¬ë¶€\n        \"\"\"\n        # í•„ìˆ˜ í•„ë“œ í™•ì¸\n        required_fields = ['question', 'answer', 'quality_score', 'passed']\n        if not all(field in qa_data for field in required_fields):\n            logger.warning(\"í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ëœ ë°ì´í„°\")\n            return False\n        \n        # í’ˆì§ˆ ì²´í¬\n        if not qa_data.get('passed', False):\n            logger.debug(\"í’ˆì§ˆ ê¸°ì¤€ ë¯¸ë‹¬ ë°ì´í„° ìŠ¤í‚µ\")\n            return False\n        \n        # ì¤‘ë³µ ì²´í¬\n        question_hash = hash(qa_data['question'])\n        if question_hash in self.question_hashes:\n            self.save_stats['duplicates_removed'] += 1\n            logger.debug(\"ì¤‘ë³µ ë¬¸ì œ ë°œê²¬, ìŠ¤í‚µ\")\n            return False\n        \n        # ì €ì¥ìš© í¬ë§·ìœ¼ë¡œ ë³€í™˜\n        save_data = self._format_for_save(qa_data)\n        \n        # ë²„í¼ì— ì¶”ê°€\n        self.data_buffer.append(save_data)\n        self.question_hashes.add(question_hash)\n        \n        # ë²„í¼ê°€ ê°€ë“ ì°¨ë©´ ì €ì¥\n        if len(self.data_buffer) >= self.buffer_size:\n            self._flush_buffer()\n        \n        self.save_stats['total_saved'] += 1\n        return True\n    \n    def _format_for_save(self, qa_data: Dict) -> Dict:\n        \"\"\"\n        ì €ì¥ìš© í¬ë§·ìœ¼ë¡œ ë³€í™˜\n        \n        í•™ìŠµì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n        \"\"\"\n        # ê¸°ë³¸ í•„ë“œ\n        formatted = {\n            'instruction': qa_data['question'],\n            'input': \"\",  # RAG ì»¨í…ìŠ¤íŠ¸ëŠ” ë³„ë„ ê´€ë¦¬\n            'output': qa_data['answer'],\n            'quality_score': qa_data['quality_score'],\n            'question_type': qa_data.get('question_type', 'unknown')\n        }\n        \n        # ë©”íƒ€ë°ì´í„° ì¶”ê°€\n        if 'metadata' in qa_data:\n            formatted['metadata'] = qa_data['metadata']\n        \n        # ìƒì„± ì‹œê°„ ì¶”ê°€\n        formatted['created_at'] = datetime.now().isoformat()\n        \n        return formatted\n    \n    def _flush_buffer(self):\n        \"\"\"ë²„í¼ ë‚´ìš©ì„ íŒŒì¼ì— ì €ì¥\"\"\"\n        if not self.data_buffer:\n            return\n        \n        # JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥ (í•œ ì¤„ì— í•˜ë‚˜ì”©)\n        with open(self.data_file, 'a', encoding='utf-8') as f:\n            for data in self.data_buffer:\n                json_line = json.dumps(data, ensure_ascii=False)\n                f.write(json_line + '\\n')\n        \n        self.save_stats['batches_written'] += 1\n        logger.info(f\"ë°°ì¹˜ {self.save_stats['batches_written']} ì €ì¥ ì™„ë£Œ ({len(self.data_buffer)}ê°œ)\")\n        \n        # ë²„í¼ ì´ˆê¸°í™”\n        self.data_buffer.clear()\n    \n    def save_metadata(self, generation_stats: Dict = None):\n        \"\"\"\n        ë©”íƒ€ë°ì´í„° ì €ì¥\n        \n        Args:\n            generation_stats: ìƒì„± í†µê³„ ì •ë³´\n        \"\"\"\n        metadata = {\n            'file_info': {\n                'data_file': str(self.data_file),\n                'created_at': datetime.now().isoformat(),\n                'format': 'jsonl',\n                'encoding': 'utf-8'\n            },\n            'statistics': {\n                'total_saved': self.save_stats['total_saved'],\n                'duplicates_removed': self.save_stats['duplicates_removed'],\n                'batches_written': self.save_stats['batches_written']\n            },\n            'data_info': {\n                'fields': ['instruction', 'input', 'output', 'quality_score', 'question_type'],\n                'quality_threshold': 70\n            }\n        }\n        \n        # ìƒì„± í†µê³„ ì¶”ê°€\n        if generation_stats:\n            metadata['generation_stats'] = generation_stats\n        \n        # ë©”íƒ€ë°ì´í„° ì €ì¥\n        with open(self.metadata_file, 'w', encoding='utf-8') as f:\n            json.dump(metadata, f, ensure_ascii=False, indent=2)\n        \n        logger.info(f\"ë©”íƒ€ë°ì´í„° ì €ì¥: {self.metadata_file}\")\n    \n    def finalize(self):\n        \"\"\"ìµœì¢… ì €ì¥ ë° ì •ë¦¬\"\"\"\n        # ë‚¨ì€ ë²„í¼ ì €ì¥\n        if self.data_buffer:\n            self._flush_buffer()\n        \n        print(\"\\n\" + \"=\" * 60)\n        print(\"ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ\")\n        print(\"=\" * 60)\n        print(f\"ì €ì¥ ìœ„ì¹˜: {self.data_file}\")\n        print(f\"ì´ ì €ì¥ëœ ë°ì´í„°: {self.save_stats['total_saved']}ê°œ\")\n        print(f\"ì œê±°ëœ ì¤‘ë³µ: {self.save_stats['duplicates_removed']}ê°œ\")\n        print(f\"ë°°ì¹˜ ìˆ˜: {self.save_stats['batches_written']}ê°œ\")\n        print(\"=\" * 60)\n    \n    def validate_data(self) -> Dict:\n        \"\"\"\n        ì €ì¥ëœ ë°ì´í„° ê²€ì¦\n        \n        Returns:\n            ê²€ì¦ ê²°ê³¼\n        \"\"\"\n        if not self.data_file.exists():\n            return {'valid': False, 'error': 'ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'}\n        \n        validation_results = {\n            'valid': True,\n            'total_lines': 0,\n            'valid_lines': 0,\n            'invalid_lines': [],\n            'quality_distribution': defaultdict(int),\n            'type_distribution': defaultdict(int)\n        }\n        \n        with open(self.data_file, 'r', encoding='utf-8') as f:\n            for line_num, line in enumerate(f, 1):\n                validation_results['total_lines'] += 1\n                \n                try:\n                    # JSON íŒŒì‹±\n                    data = json.loads(line.strip())\n                    \n                    # í•„ìˆ˜ í•„ë“œ í™•ì¸\n                    required = ['instruction', 'output', 'quality_score']\n                    if all(field in data for field in required):\n                        validation_results['valid_lines'] += 1\n                        \n                        # í†µê³„ ìˆ˜ì§‘\n                        score_range = int(data['quality_score'] // 10) * 10\n                        validation_results['quality_distribution'][score_range] += 1\n                        validation_results['type_distribution'][data.get('question_type', 'unknown')] += 1\n                    else:\n                        validation_results['invalid_lines'].append(line_num)\n                        \n                except json.JSONDecodeError:\n                    validation_results['invalid_lines'].append(line_num)\n                    validation_results['valid'] = False\n        \n        # ê²€ì¦ ê²°ê³¼ ì¶œë ¥\n        print(\"\\nğŸ“‹ ë°ì´í„° ê²€ì¦ ê²°ê³¼:\")\n        print(f\"ì´ ë¼ì¸ ìˆ˜: {validation_results['total_lines']}\")\n        print(f\"ìœ íš¨í•œ ë¼ì¸: {validation_results['valid_lines']}\")\n        print(f\"ë¬´íš¨í•œ ë¼ì¸: {len(validation_results['invalid_lines'])}\")\n        \n        if validation_results['invalid_lines']:\n            print(f\"ë¬´íš¨í•œ ë¼ì¸ ë²ˆí˜¸: {validation_results['invalid_lines'][:10]}...\")\n        \n        return validation_results\n    \n    def export_for_training(self, output_file: str = None):\n        \"\"\"\n        í•™ìŠµìš© í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°\n        \n        Args:\n            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ\n        \"\"\"\n        if output_file is None:\n            output_file = self.output_dir / \"train_data.jsonl\"\n        \n        # ë°ì´í„° ë¡œë“œ ë° ë³€í™˜\n        training_data = []\n        \n        with open(self.data_file, 'r', encoding='utf-8') as f:\n            for line in f:\n                data = json.loads(line.strip())\n                \n                # í•™ìŠµìš© í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n                training_format = {\n                    'text': f\"### ì§ˆë¬¸: {data['instruction']}\\n\\n### ë‹µë³€: {data['output']}\"\n                }\n                \n                training_data.append(training_format)\n        \n        # ì…”í”Œ\n        random.shuffle(training_data)\n        \n        # ì €ì¥\n        with open(output_file, 'w', encoding='utf-8') as f:\n            for item in training_data:\n                f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n        \n        print(f\"âœ… í•™ìŠµìš© ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {output_file}\")\n        print(f\"   ì´ {len(training_data)}ê°œ ìƒ˜í”Œ\")\n\n\n# ë°ì´í„° ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸\nprint(\"âœ… ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ\")\nprint(\"\\nì£¼ìš” ê¸°ëŠ¥:\")\nprint(\"- JSONL í˜•ì‹ ì €ì¥ (í•™ìŠµ í˜¸í™˜)\")\nprint(\"- ìë™ ì¤‘ë³µ ì œê±°\")\nprint(\"- ë°°ì¹˜ ì €ì¥ìœ¼ë¡œ íš¨ìœ¨ì„± í–¥ìƒ\")\nprint(\"- ë©”íƒ€ë°ì´í„° ê´€ë¦¬\")\nprint(\"- ë°ì´í„° ê²€ì¦ ê¸°ëŠ¥\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 16. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class FSKUDataAugmentation:\n    \"\"\"\n    FSKU ë°ì´í„° ì¦ê°• í†µí•© ì‹¤í–‰ í´ë˜ìŠ¤\n    \n    ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•˜ì—¬ ìë™ ë°ì´í„° ìƒì„±\n    \"\"\"\n    \n    def __init__(self, \n                 model_name: str = \"beomi/llama-2-ko-7b\",\n                 external_dir: Path = None,\n                 output_dir: Path = None):\n        \"\"\"\n        ì´ˆê¸°í™”\n        \n        Args:\n            model_name: ì‚¬ìš©í•  LLM ëª¨ë¸\n            external_dir: ì™¸ë¶€ ë¬¸ì„œ ë””ë ‰í† ë¦¬\n            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬\n        \"\"\"\n        self.model_name = model_name\n        self.external_dir = external_dir or EXTERNAL_DIR\n        self.output_dir = output_dir or OUTPUT_DIR\n        \n        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”\n        self.rag_system = None\n        self.generator = None\n        self.prompt_manager = None\n        self.monitor = None\n        self.data_manager = None\n        \n        # ì„¤ì •\n        self.config = {\n            'use_quantization': True,\n            'batch_size': 4,\n            'target_count': 1000,\n            'max_iterations': 3,\n            'quality_threshold': 70\n        }\n    \n    def initialize(self):\n        \"\"\"ì‹œìŠ¤í…œ ì´ˆê¸°í™”\"\"\"\n        print(\"=\" * 60)\n        print(\"ğŸš€ FSKU ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ ì´ˆê¸°í™”\")\n        print(\"=\" * 60)\n        \n        # 1. RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n        print(\"\\n[1/5] RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”...\")\n        self.rag_system = RAGSystem()\n        self.rag_system.initialize(self.external_dir)\n        \n        if not self.rag_system.is_initialized:\n            raise ValueError(\"RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨. ì™¸ë¶€ ë¬¸ì„œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n        \n        # 2. ì²´ì´ë‹ ìƒì„±ê¸° ì´ˆê¸°í™”\n        print(\"\\n[2/5] ë°ì´í„° ìƒì„±ê¸° ì´ˆê¸°í™”...\")\n        self.generator = ChainingDataGenerator(self.model_name)\n        \n        # 3. í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”\n        print(\"\\n[3/5] í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”...\")\n        self.prompt_manager = PromptTemplateManager()\n        \n        # 4. ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n        print(\"\\n[4/5] ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...\")\n        self.monitor = GenerationMonitor()\n        \n        # 5. ë°ì´í„° ë§¤ë‹ˆì € ì´ˆê¸°í™”\n        print(\"\\n[5/5] ë°ì´í„° ë§¤ë‹ˆì € ì´ˆê¸°í™”...\")\n        self.data_manager = DataManager(self.output_dir)\n        \n        print(\"\\nâœ… ëª¨ë“  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\")\n    \n    def run(self, \n            target_count: int = None,\n            load_model: bool = True,\n            test_mode: bool = False):\n        \"\"\"\n        ë°ì´í„° ì¦ê°• ì‹¤í–‰\n        \n        Args:\n            target_count: ìƒì„±í•  ë¬¸ì œ ìˆ˜\n            load_model: LLM ëª¨ë¸ ë¡œë“œ ì—¬ë¶€\n            test_mode: í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì†ŒëŸ‰ ìƒì„±)\n        \"\"\"\n        if target_count:\n            self.config['target_count'] = target_count\n        \n        if test_mode:\n            self.config['target_count'] = 10\n            self.config['batch_size'] = 2\n            print(\"âš ï¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: 10ê°œë§Œ ìƒì„±í•©ë‹ˆë‹¤.\")\n        \n        try:\n            # ëª¨ë¸ ë¡œë“œ\n            if load_model:\n                print(\"\\nğŸ¤– LLM ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n                self.generator.initialize_model(\n                    use_quantization=self.config['use_quantization']\n                )\n            \n            # ëª¨ë‹ˆí„°ë§ ì‹œì‘\n            self.monitor.start_monitoring(self.config['target_count'])\n            \n            # ë°ì´í„° ìƒì„± ë£¨í”„\n            self._generation_loop()\n            \n            # ì™„ë£Œ ì²˜ë¦¬\n            self._finalize()\n            \n        except KeyboardInterrupt:\n            print(\"\\n\\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨\")\n            self._finalize()\n        except Exception as e:\n            logger.error(f\"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n            raise\n        finally:\n            if self.monitor:\n                self.monitor.close()\n    \n    def _generation_loop(self):\n        \"\"\"ë°ì´í„° ìƒì„± ë©”ì¸ ë£¨í”„\"\"\"\n        print(\"\\n\" + \"=\" * 60)\n        print(\"ğŸ”„ ë°ì´í„° ìƒì„± ì‹œì‘\")\n        print(\"=\" * 60)\n        \n        generated_count = 0\n        attempts = 0\n        \n        # ì§„í–‰ë¥  í‘œì‹œ\n        pbar = tqdm(total=self.config['target_count'], desc=\"ìƒì„± ì§„í–‰\")\n        \n        while generated_count < self.config['target_count']:\n            attempts += 1\n            \n            try:\n                # 1. RAGì—ì„œ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n                if random.random() < 0.7:\n                    # 70% í™•ë¥ ë¡œ ê´€ë ¨ ê²€ìƒ‰\n                    query = self._generate_search_query()\n                    context = self.rag_system.search(query, top_k=3)\n                else:\n                    # 30% í™•ë¥ ë¡œ ëœë¤\n                    context = self.rag_system.get_random_context(n=2)\n                \n                if not context:\n                    logger.warning(\"ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨\")\n                    continue\n                \n                # 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„ íƒ\n                template_name = self.prompt_manager.recommend_template(context)\n                \n                # 3. ë¬¸ì œ ìƒì„±\n                result = self.generator.generate_qa_pair(\n                    context=context,\n                    question_type=self._get_question_type_from_template(template_name),\n                    max_iterations=self.config['max_iterations']\n                )\n                \n                if result and result.get('passed', False):\n                    # 4. ë°ì´í„° ì €ì¥\n                    if self.data_manager.add_data(result):\n                        generated_count += 1\n                        pbar.update(1)\n                    \n                    # 5. ëª¨ë‹ˆí„°ë§ ì—…ë°ì´íŠ¸\n                    self.monitor.update(result)\n                    \n                    # 6. ì§„í–‰ ìƒí™© ì¶œë ¥ (50ê°œë§ˆë‹¤)\n                    if generated_count % 50 == 0:\n                        self._print_progress(generated_count, attempts)\n                \n            except Exception as e:\n                logger.error(f\"ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n                continue\n            \n            # ë„ˆë¬´ ë§ì€ ì‹œë„ ë°©ì§€\n            if attempts > self.config['target_count'] * 3:\n                logger.warning(\"ë„ˆë¬´ ë§ì€ ì‹œë„. í’ˆì§ˆ ê¸°ì¤€ì„ í™•ì¸í•˜ì„¸ìš”.\")\n                break\n        \n        pbar.close()\n    \n    def _generate_search_query(self) -> str:\n        \"\"\"ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±\"\"\"\n        # ê¸ˆìœµ ê´€ë ¨ ì£¼ìš” í† í”½\n        topics = [\n            \"ì „ìê¸ˆìœµê±°ë˜\", \"ê°œì¸ì •ë³´ë³´í˜¸\", \"ê¸ˆìœµë³´ì•ˆ\", \"ìê¸ˆì„¸íƒë°©ì§€\",\n            \"ì‹ ìš©ì •ë³´\", \"ê¸ˆìœµìƒí’ˆ\", \"ë¦¬ìŠ¤í¬ê´€ë¦¬\", \"ë‚´ë¶€í†µì œ\",\n            \"ê¸ˆìœµê·œì œ\", \"í•€í…Œí¬\", \"ë””ì§€í„¸ê¸ˆìœµ\", \"ê¸ˆìœµì†Œë¹„ìë³´í˜¸\",\n            \"KYC\", \"AML\", \"ìì‚°ìš´ìš©\", \"ì¦ê¶Œê±°ë˜\"\n        ]\n        \n        return random.choice(topics)\n    \n    def _get_question_type_from_template(self, template_name: str) -> str:\n        \"\"\"í…œí”Œë¦¿ëª…ì—ì„œ ë¬¸ì œ ìœ í˜• ì¶”ì¶œ\"\"\"\n        if 'ê°ê´€ì‹' in template_name:\n            return 'ê°ê´€ì‹'\n        elif 'ì£¼ê´€ì‹' in template_name:\n            return 'ì£¼ê´€ì‹'\n        elif 'ê³„ì‚°' in template_name:\n            return 'ê³„ì‚°'\n        else:\n            return 'ê¸°íƒ€'\n    \n    def _print_progress(self, generated: int, attempts: int):\n        \"\"\"ì§„í–‰ ìƒí™© ì¶œë ¥\"\"\"\n        success_rate = generated / attempts * 100 if attempts > 0 else 0\n        print(f\"\\nğŸ“Š ì§„í–‰ ìƒí™©: {generated}/{self.config['target_count']} \"\n              f\"(ì„±ê³µë¥ : {success_rate:.1f}%)\")\n    \n    def _finalize(self):\n        \"\"\"ìµœì¢… ì²˜ë¦¬\"\"\"\n        print(\"\\nğŸ ìµœì¢… ì²˜ë¦¬ ì¤‘...\")\n        \n        # ë°ì´í„° ì €ì¥ ì™„ë£Œ\n        if self.data_manager:\n            self.data_manager.finalize()\n            \n            # ë©”íƒ€ë°ì´í„° ì €ì¥\n            if self.generator and self.monitor:\n                generation_stats = {\n                    'generator': self.generator.get_statistics(),\n                    'monitor': self.monitor.stats\n                }\n                self.data_manager.save_metadata(generation_stats)\n            \n            # ë°ì´í„° ê²€ì¦\n            self.data_manager.validate_data()\n        \n        # ëª¨ë‹ˆí„°ë§ ìš”ì•½\n        if self.monitor:\n            self.monitor.print_summary()\n            \n            # ë³´ê³ ì„œ ì €ì¥\n            report_path = self.output_dir / \"generation_report.json\"\n            self.monitor.save_report(str(report_path))\n        \n        print(\"\\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")\n    \n    def update_config(self, **kwargs):\n        \"\"\"ì„¤ì • ì—…ë°ì´íŠ¸\"\"\"\n        self.config.update(kwargs)\n        print(\"ì„¤ì • ì—…ë°ì´íŠ¸ë¨:\")\n        for key, value in kwargs.items():\n            print(f\"  - {key}: {value}\")\n\n\n# í†µí•© ì‹¤í–‰ ì‹œìŠ¤í…œ ìƒì„±\nprint(\"âœ… FSKU ë°ì´í„° ì¦ê°• í†µí•© ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ\")\nprint(\"\\nì‚¬ìš©ë²•:\")\nprint(\"1. augmentation = FSKUDataAugmentation()\")\nprint(\"2. augmentation.initialize()\")\nprint(\"3. augmentation.run(target_count=1000)\")\nprint(\"\\nì„¤ì • ë³€ê²½:\")\nprint(\"augmentation.update_config(batch_size=8, quality_threshold=75)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ¯ ì‹¤í–‰ ì˜ˆì œ\n\nì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ì¦ê°•ì„ ì‹œì‘í•˜ì„¸ìš”.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ì‹¤í–‰ ì˜ˆì œ 1: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (10ê°œë§Œ ìƒì„±)\nprint(\"=\" * 60)\nprint(\"ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜ˆì œ\")\nprint(\"=\" * 60)\nprint(\"\\nì´ ì…€ì„ ì‹¤í–‰í•˜ë©´ 10ê°œì˜ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\")\nprint(\"ì‹¤ì œ ì‹¤í–‰ ì „ì— ì‹œìŠ¤í…œì´ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\nprint(\"\\nì‹¤í–‰í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ì„ ì œê±°í•˜ì„¸ìš”:\")\n\n# # ì‹œìŠ¤í…œ ìƒì„±\n# augmentation = FSKUDataAugmentation(\n#     model_name=\"beomi/llama-2-ko-7b\",\n#     external_dir=EXTERNAL_DIR,\n#     output_dir=OUTPUT_DIR\n# )\n\n# # ì´ˆê¸°í™”\n# augmentation.initialize()\n\n# # í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n# augmentation.run(test_mode=True)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ì‹¤í–‰ ì˜ˆì œ 2: ë³¸ê²© ì‹¤í–‰ (1000ê°œ ìƒì„±)\nprint(\"=\" * 60)\nprint(\"ğŸš€ ë³¸ê²© ì‹¤í–‰ ì˜ˆì œ\")\nprint(\"=\" * 60)\nprint(\"\\nì´ ì…€ì„ ì‹¤í–‰í•˜ë©´ 1000ê°œì˜ ê³ í’ˆì§ˆ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\")\nprint(\"ì˜ˆìƒ ì†Œìš” ì‹œê°„: 2-4ì‹œê°„ (ëª¨ë¸ê³¼ í•˜ë“œì›¨ì–´ì— ë”°ë¼ ë‹¤ë¦„)\")\nprint(\"\\nì‹¤í–‰í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ì„ ì œê±°í•˜ì„¸ìš”:\")\n\n# # ì‹œìŠ¤í…œ ìƒì„± (ë” ì¢‹ì€ ëª¨ë¸ ì‚¬ìš©)\n# augmentation = FSKUDataAugmentation(\n#     model_name=\"upstage/SOLAR-10.7B-v1.0\",  # ë” ì¢‹ì€ í•œêµ­ì–´ ëª¨ë¸\n#     external_dir=EXTERNAL_DIR,\n#     output_dir=OUTPUT_DIR\n# )\n\n# # ì„¤ì • ë³€ê²½ (ì„ íƒì‚¬í•­)\n# augmentation.update_config(\n#     target_count=1000,        # ìƒì„±í•  ë¬¸ì œ ìˆ˜\n#     batch_size=4,             # ë°°ì¹˜ í¬ê¸°\n#     quality_threshold=75,     # í’ˆì§ˆ ê¸°ì¤€ (ë†’ì¼ìˆ˜ë¡ ì—„ê²©)\n#     max_iterations=3          # ê°œì„  ë°˜ë³µ íšŸìˆ˜\n# )\n\n# # ì´ˆê¸°í™”\n# augmentation.initialize()\n\n# # ë³¸ê²© ì‹¤í–‰\n# augmentation.run()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ì‹¤í–‰ ì˜ˆì œ 3: ê²°ê³¼ ë¶„ì„ ë° í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸°\nprint(\"=\" * 60)\nprint(\"ğŸ“Š ê²°ê³¼ ë¶„ì„ ì˜ˆì œ\")\nprint(\"=\" * 60)\nprint(\"\\nìƒì„±ì´ ì™„ë£Œëœ í›„ ì´ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì„¸ìš”.\")\n\n# ìµœì‹  ìƒì„± íŒŒì¼ ì°¾ê¸°\nimport glob\n\n# JSONL íŒŒì¼ ì°¾ê¸°\njsonl_files = sorted(glob.glob(str(OUTPUT_DIR / \"fsku_data_*.jsonl\")))\n\nif jsonl_files:\n    latest_file = jsonl_files[-1]\n    print(f\"\\nìµœì‹  ë°ì´í„° íŒŒì¼: {latest_file}\")\n    \n    # ë°ì´í„° ë§¤ë‹ˆì €ë¡œ ê²€ì¦\n    temp_manager = DataManager(OUTPUT_DIR)\n    temp_manager.data_file = Path(latest_file)\n    \n    # ê²€ì¦ ì‹¤í–‰\n    validation = temp_manager.validate_data()\n    \n    # í•™ìŠµìš© ë°ì´í„°ë¡œ ë‚´ë³´ë‚´ê¸°\n    if validation['valid']:\n        print(\"\\ní•™ìŠµìš© ë°ì´í„°ë¡œ ë‚´ë³´ë‚´ê¸°...\")\n        temp_manager.export_for_training()\n    \n    # ìƒ˜í”Œ ì¶œë ¥\n    print(\"\\nğŸ“ ìƒì„±ëœ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):\")\n    print(\"-\" * 60)\n    \n    with open(latest_file, 'r', encoding='utf-8') as f:\n        for i, line in enumerate(f):\n            if i >= 3:\n                break\n            data = json.loads(line)\n            print(f\"\\n[ìƒ˜í”Œ {i+1}]\")\n            print(f\"ë¬¸ì œ: {data['instruction'][:100]}...\")\n            print(f\"ë‹µë³€: {data['output'][:100]}...\")\n            print(f\"í’ˆì§ˆ: {data['quality_score']}ì \")\n            print(f\"ìœ í˜•: {data['question_type']}\")\nelse:\n    print(\"\\nâš ï¸ ìƒì„±ëœ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n    print(\"ë¨¼ì € ë°ì´í„° ìƒì„±ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ‰ ì™„ë£Œ!\n\n### âœ… êµ¬í˜„ ì™„ë£Œ ì‚¬í•­\n1. **RAG ì‹œìŠ¤í…œ** - ì™¸ë¶€ ë¬¸ì„œ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰\n2. **í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ** - ë‹¤ì°¨ì› í‰ê°€ë¡œ ê³ í’ˆì§ˆ ë³´ì¥\n3. **ì²´ì´ë‹ ìƒì„±ê¸°** - 4ë‹¨ê³„ ê°œì„  í”„ë¡œì„¸ìŠ¤\n4. **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿** - 10ê°€ì§€ ì´ìƒì˜ ë¬¸ì œ ìœ í˜•\n5. **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§** - ì§„í–‰ ìƒí™© ì‹œê°í™”\n6. **ë°ì´í„° ê´€ë¦¬** - JSONL ì €ì¥ ë° ê²€ì¦\n7. **í†µí•© ì‹¤í–‰** - ì›í´ë¦­ ìë™í™”\n\n### ğŸ“‹ ì‚¬ìš© ë°©ë²• ìš”ì•½\n\n1. **ì™¸ë¶€ ë¬¸ì„œ ì¤€ë¹„**\n   ```\n   data/external/ í´ë”ì— PDF, TXT, Excel ë¬¸ì„œ ì¶”ê°€\n   ```\n\n2. **í…ŒìŠ¤íŠ¸ ì‹¤í–‰**\n   ```python\n   augmentation = FSKUDataAugmentation()\n   augmentation.initialize()\n   augmentation.run(test_mode=True)\n   ```\n\n3. **ë³¸ê²© ì‹¤í–‰**\n   ```python\n   augmentation.run(target_count=1000)\n   ```\n\n### ğŸ’¡ Tips\n- GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ: `use_quantization=True` (ê¸°ë³¸ê°’)\n- í’ˆì§ˆ í–¥ìƒ: `quality_threshold=80` ìœ¼ë¡œ ì„¤ì •\n- ì†ë„ í–¥ìƒ: `batch_size` ì¦ê°€\n- ë‹¤ì–‘ì„± í™•ë³´: ì™¸ë¶€ ë¬¸ì„œ ë‹¤ì–‘í•˜ê²Œ ì¶”ê°€\n\n### ğŸ“š ìƒì„±ëœ íŒŒì¼\n- `data/augmented/fsku_data_*.jsonl` - ìƒì„±ëœ ë°ì´í„°\n- `data/augmented/fsku_metadata_*.json` - ë©”íƒ€ë°ì´í„°\n- `data/augmented/generation_report.json` - ìƒì„¸ ë³´ê³ ì„œ\n- `data/augmented/train_data.jsonl` - í•™ìŠµìš© í¬ë§·\n\n### ğŸš€ ë‹¤ìŒ ë‹¨ê³„\n1. ìƒì„±ëœ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ (FSKU_2_í•™ìŠµ.ipynb)\n2. í•™ìŠµëœ ëª¨ë¸ë¡œ ì¶”ë¡  (FSKU_3_ì¶”ë¡ .ipynb)\n\n---\n**Good Luck with FSKU Challenge! ğŸ†**",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}